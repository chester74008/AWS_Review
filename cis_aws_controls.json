[
  {
    "recommendation_number": "1.1",
    "section": 1.0,
    "title": "Maintain current contact details",
    "profile": "Level 1",
    "assessment_status": "Manual",
    "description": "Ensure contact email and telephone details for AWS accounts are current and map to more than one individual in your organization.\n\nAn AWS account supports a number of contact details, and AWS will use these to contact the account owner if activity judged to be in breach of the Acceptable Use Policy or indicative of a likely security compromise is observed by the AWS Abuse team. Contact details should not be for a single individual, as circumstances may arise where that individual is unavailable. Email contact details should point to a mail alias which forwards email to multiple individuals within the organization; where feasible, phone contact details should point to a PABX hunt group or other call-forwarding system.",
    "audit_procedure": "This activity can only be performed via the AWS Console, with a user who has permission to read and write Billing information (aws-portal:\\*Billing).\n\n1. Sign in to the AWS Management Console and open the `Billing and Cost Management` console at https://console.aws.amazon.com/billing/home#/.\n2. On the navigation bar, choose your account name, and then choose `Account`.\n3. On the `Account Settings` page, review and verify the current details.\n4. Under `Contact Information`, review and verify the current details.",
    "remediation_procedure": "This activity can only be performed via the AWS Console, with a user who has permission to read and write Billing information (aws-portal:\\*Billing).\n\n1. Sign in to the AWS Management Console and open the `Billing and Cost Management` console at https://console.aws.amazon.com/billing/home#/.\n2. On the navigation bar, choose your account name, and then choose `Account`.\n3. On the `Account Settings` page, next to `Account Settings`, choose `Edit`.\n4. Next to the field that you need to update, choose `Edit`.\n5. After you have entered your changes, choose `Save changes`.\n6. After you have made your changes, choose `Done`.\n7. To edit your contact information, under `Contact Information`, choose `Edit`.\n8. For the fields that you want to change, type your updated information, and then choose `Update`."
  },
  {
    "recommendation_number": "1.10",
    "section": 1.0,
    "title": "Do not create access keys during initial setup for IAM users with a console password",
    "profile": "Level 1",
    "assessment_status": "Manual",
    "description": "AWS console defaults to no check boxes selected when creating a new IAM user. When creating the IAM User credentials you have to determine what type of access they require. \n\nProgrammatic access: The IAM user might need to make API calls, use the AWS CLI, or use the Tools for Windows PowerShell. In that case, create an access key (access key ID and a secret access key) for that user. \n\nAWS Management Console access: If the user needs to access the AWS Management Console, create a password for the user.",
    "audit_procedure": "Perform the following steps to determine if unused access keys were created upon user creation:\n\n**From Console:**\n\n1. Login to the AWS Management Console\n2. Click `Services` \n3. Click `IAM` \n4. Click on a User where column `Password age` and `Access key age` is not set to `None`\n5. Click on `Security credentials` Tab\n6. Compare the user `Creation time` to the Access Key `Created` date.\n6. For any that match, the key was created during initial user setup.\n\n- Keys that were created at the same time as the user profile and do not have a last used date should be deleted. Refer to the remediation below.\n\n**From Command Line:**\n\n1. Run the following command (OSX/Linux/UNIX) to generate a list of all IAM users along with their access keys utilization:\n```\n aws iam generate-credential-report\n```\n```\n aws iam get-credential-report --query 'Content' --output text | base64 -d | cut -d, -f1,4,9,11,14,16\n```\n2. The output of this command will produce a table similar to the following:\n```\nuser,password_enabled,access_key_1_active,access_key_1_last_used_date,access_key_2_active,access_key_2_last_used_date\n elise,false,true,2015-04-16T15:14:00+00:00,false,N/A\n brandon,true,true,N/A,false,N/A\n rakesh,false,false,N/A,false,N/A\n helene,false,true,2015-11-18T17:47:00+00:00,false,N/A\n paras,true,true,2016-08-28T12:04:00+00:00,true,2016-03-04T10:11:00+00:00\n anitha,true,true,2016-06-08T11:43:00+00:00,true,N/A \n```\n3. For any user having `password_enabled` set to `true` AND `access_key_last_used_date` set to `N/A` refer to the remediation below.",
    "remediation_procedure": "Perform the following to delete access keys that do not pass the audit:\n\n**From Console:**\n\n1. Login to the AWS Management Console:\n2. Click `Services` \n3. Click `IAM` \n4. Click on `Users` \n5. Click on `Security Credentials` \n6. As an Administrator \n - Click on the X `(Delete)` for keys that were created at the same time as the user profile but have not been used.\n7. As an IAM User\n - Click on the X `(Delete)` for keys that were created at the same time as the user profile but have not been used.\n\n**From Command Line:**\n```\naws iam delete-access-key --access-key-id <access-key-id-listed> --user-name <users-name>\n```"
  },
  {
    "recommendation_number": "1.11",
    "section": 1.0,
    "title": "Ensure credentials unused for 45 days or more are disabled",
    "profile": "Level 1",
    "assessment_status": "Automated",
    "description": "AWS IAM users can access AWS resources using different types of credentials, such as passwords or access keys. It is recommended that all credentials that have been unused for 45 days or more be deactivated or removed.",
    "audit_procedure": "Perform the following to determine if unused credentials exist:\n\n**From Console:**\n\n1. Login to the AWS Management Console\n2. Click `Services` \n3. Click `IAM`\n4. Click on `Users`\n5. Click the `Settings` (gear) icon.\n6. Select `Console last sign-in`, `Access key last used`, and `Access Key Id`\n7. Click on `Close` \n8. Check and ensure that `Console last sign-in` is less than 45 days ago.\n\n**Note** - `Never` means the user has never logged in.\n\n9. Check and ensure that `Access key age` is less than 45 days and that `Access key last used` does not say `None`\n\nIf the user hasn't signed into the Console in the last 45 days or Access keys are over 45 days old refer to the remediation.\n\n**From Command Line:**\n\n**Download Credential Report:**\n\n1. Run the following commands:\n```\n aws iam generate-credential-report\n\n aws iam get-credential-report --query 'Content' --output text | base64 -d | cut -d, -f1,4,5,6,9,10,11,14,15,16 | grep -v '^<root_account>'\n```\n\n**Ensure unused credentials do not exist:**\n\n2. For each user having `password_enabled` set to `TRUE` , ensure `password_last_used_date` is less than `45` days ago.\n\n- When `password_enabled` is set to `TRUE` and `password_last_used` is set to `No_Information` , ensure `password_last_changed` is less than 45 days ago.\n\n3. For each user having an `access_key_1_active` or `access_key_2_active` to `TRUE` , ensure the corresponding `access_key_n_last_used_date` is less than `45` days ago.\n\n- When a user having an `access_key_x_active` (where x is 1 or 2) to `TRUE` and corresponding access_key_x_last_used_date is set to `N/A`, ensure `access_key_x_last_rotated` is less than 45 days ago.",
    "remediation_procedure": "**From Console:**\n\nPerform the following to manage Unused Password (IAM user console access)\n\n1. Login to the AWS Management Console:\n2. Click `Services` \n3. Click `IAM` \n4. Click on `Users` \n5. Click on `Security Credentials` \n6. Select user whose `Console last sign-in` is greater than 45 days\n7. Click `Security credentials`\n8. In section `Sign-in credentials`, `Console password` click `Manage` \n9. Under Console Access select `Disable`\n10. Click `Apply`\n\nPerform the following to deactivate Access Keys:\n\n1. Login to the AWS Management Console:\n2. Click `Services` \n3. Click `IAM` \n4. Click on `Users` \n5. Click on `Security Credentials` \n6. Select any access keys that are over 45 days old and that have been used and \n - Click on `Make Inactive`\n7. Select any access keys that are over 45 days old and that have not been used and \n - Click the X to `Delete`"
  },
  {
    "recommendation_number": "1.12",
    "section": 1.0,
    "title": "Ensure there is only one active access key for any single IAM user",
    "profile": "Level 1",
    "assessment_status": "Automated",
    "description": "Access keys are long-term credentials for an IAM user or the AWS account 'root' user. You can use access keys to sign programmatic requests to the AWS CLI or AWS API (directly or using the AWS SDK)",
    "audit_procedure": "**From Console:**\n\n1. Sign in to the AWS Management Console and navigate to IAM dashboard at `https://console.aws.amazon.com/iam/`.\n2. In the left navigation panel, choose `Users`.\n3. Click on the IAM user name that you want to examine.\n4. On the IAM user configuration page, select `Security Credentials` tab.\n5. Under `Access Keys` section, in the Status column, check the current status for each access key associated with the IAM user. If the selected IAM user has more than one access key activated, then the user's access configuration does not adhere to security best practices, and the risk of accidental exposures increases.\n- Repeat steps 3-5 for each IAM user in your AWS account.\n\n**From Command Line:**\n\n1. Run `list-users` command to list all IAM users within your account:\n```\naws iam list-users --query \"Users[*].UserName\"\n```\nThe command output should return an array that contains all your IAM user names.\n\n2. Run `list-access-keys` command using the IAM user name list to return the current status of each access key associated with the selected IAM user:\n```\naws iam list-access-keys --user-name <user-name>\n```\nThe command output should expose the metadata `(\"Username\", \"AccessKeyId\", \"Status\", \"CreateDate\")` for each access key on that user account.\n\n3. Check the `Status` property value for each key returned to determine each key's current state. If the `Status` property value for more than one IAM access key is set to `Active`, the user access configuration does not adhere to this recommendation; refer to the remediation below.\n\n- Repeat steps 2 and 3 for each IAM user in your AWS account.",
    "remediation_procedure": "**From Console:**\n\n1. Sign in to the AWS Management Console and navigate to IAM dashboard at `https://console.aws.amazon.com/iam/`.\n2. In the left navigation panel, choose `Users`.\n3. Click on the IAM user name that you want to examine.\n4. On the IAM user configuration page, select `Security Credentials` tab.\n5. In `Access Keys` section, choose one access key that is less than 90 days old. This should be the only active key used by this IAM user to access AWS resources programmatically. Test your application(s) to make sure that the chosen access key is working.\n6. In the same `Access Keys` section, identify your non-operational access keys (other than the chosen one) and deactivate it by clicking the `Make Inactive` link.\n7. If you receive the `Change Key Status` confirmation box, click `Deactivate` to switch off the selected key.\n8. Repeat steps 3-7 for each IAM user in your AWS account.\n\n**From Command Line:**\n\n1. Using the IAM user and access key information provided in the `Audit CLI`, choose one access key that is less than 90 days old. This should be the only active key used by this IAM user to access AWS resources programmatically. Test your application(s) to make sure that the chosen access key is working.\n\n2. Run the `update-access-key` command below using the IAM user name and the non-operational access key IDs to deactivate the unnecessary key(s). Refer to the Audit section to identify the unnecessary access key ID for the selected IAM user\n\n**Note** - the command does not return any output:\n```\naws iam update-access-key --access-key-id <access-key-id> --status Inactive --user-name <user-name>\n```\n3. To confirm that the selected access key pair has been successfully `deactivated` run the `list-access-keys` audit command again for that IAM User:\n```\naws iam list-access-keys --user-name <user-name>\n```\n- The command output should expose the metadata for each access key associated with the IAM user. If the non-operational key pair(s) `Status` is set to `Inactive`, the key has been successfully deactivated and the IAM user access configuration adheres now to this recommendation.\n\n4. Repeat steps 1-3 for each IAM user in your AWS account."
  },
  {
    "recommendation_number": "1.13",
    "section": 1.0,
    "title": "Ensure access keys are rotated every 90 days or less",
    "profile": "Level 1",
    "assessment_status": "Automated",
    "description": "Access keys consist of an access key ID and secret access key, which are used to sign programmatic requests that you make to AWS. AWS users need their own access keys to make programmatic calls to AWS from the AWS Command Line Interface (AWS CLI), Tools for Windows PowerShell, the AWS SDKs, or direct HTTP calls using the APIs for individual AWS services. It is recommended that all access keys be rotated regularly.",
    "audit_procedure": "Perform the following to determine if access keys are rotated as prescribed:\n\n**From Console:**\n\n1. Go to the Management Console (https://console.aws.amazon.com/iam)\n2. Click on `Users`\n3. For each user, go to `Security Credentials`\n4. Review each key under `Access Keys`\n5. For each key that shows `Active` for status, ensure that `Created` is less than or equal to `90 days ago`.\n\n**From Command Line:**\n\n```\naws iam generate-credential-report\naws iam get-credential-report --query 'Content' --output text | base64 -d\n```\nThe `access_key_1_last_rotated` and the `access_key_2_last_rotated` fields in this file notes the date and time, in ISO 8601 date-time format, when the user's access key was created or last changed. If the user does not have an active access key, the value in this field is N/A (not applicable).",
    "remediation_procedure": "Perform the following to rotate access keys:\n\n**From Console:**\n\n1. Go to the Management Console (https://console.aws.amazon.com/iam)\n2. Click on `Users`\n3. Click on `Security Credentials` \n4. As an Administrator \n - Click on `Make Inactive` for keys that have not been rotated in `90` Days\n5. As an IAM User\n - Click on `Make Inactive` or `Delete` for keys which have not been rotated or used in `90` Days\n6. Click on `Create Access Key` \n7. Update programmatic calls with new Access Key credentials\n\n**From Command Line:**\n\n1. While the first access key is still active, create a second access key, which is active by default. Run the following command:\n```\naws iam create-access-key\n```\n\nAt this point, the user has two active access keys.\n\n2. Update all applications and tools to use the new access key.\n3. Determine whether the first access key is still in use by using this command:\n```\naws iam get-access-key-last-used\n```\n4. One approach is to wait several days and then check the old access key for any use before proceeding.\n\nEven if step 3 indicates no use of the old key, it is recommended that you do not immediately delete the first access key. Instead, change the state of the first access key to Inactive using this command:\n```\naws iam update-access-key\n```\n5. Use only the new access key to confirm that your applications are working. Any applications and tools that still use the original access key will stop working at this point because they no longer have access to AWS resources. If you find such an application or tool, you can switch its state back to Active to reenable the first access key. Then return to step 2 and update this application to use the new key.\n\n6. After you wait some period of time to ensure that all applications and tools have been updated, you can delete the first access key with this command:\n```\naws iam delete-access-key\n```"
  },
  {
    "recommendation_number": "1.14",
    "section": 1.0,
    "title": "Ensure IAM users receive permissions only through groups",
    "profile": "Level 1",
    "assessment_status": "Automated",
    "description": "IAM users are granted access to services, functions, and data through IAM policies. There are four ways to define policies for a user: 1) Edit the user policy directly, also known as an inline or user policy; 2) attach a policy directly to a user; 3) add the user to an IAM group that has an attached policy; 4) add the user to an IAM group that has an inline policy.\n\nOnly the third implementation is recommended.",
    "audit_procedure": "Perform the following to determine if an inline policy is set or a policy is directly attached to users:\n\n1. Run the following to get a list of IAM users:\n```\n aws iam list-users --query 'Users[*].UserName' --output text \n```\n2. For each user returned, run the following command to determine if any policies are attached to them:\n```\n aws iam list-attached-user-policies --user-name <iam_user>\n aws iam list-user-policies --user-name <iam_user> \n```\n3. If any policies are returned, the user has an inline policy or direct policy attachment.",
    "remediation_procedure": "Perform the following to create an IAM group and assign a policy to it:\n\n1. Sign in to the AWS Management Console and open the IAM console at [https://console.aws.amazon.com/iam/](https://console.aws.amazon.com/iam/).\n2. In the navigation pane, click `Groups` and then click `Create New Group`.\n3. In the `Group Name` box, type the name of the group and then click `Next Step`.\n4. In the list of policies, select the check box for each policy that you want to apply to all members of the group. Then click `Next Step`.\n5. Click `Create Group`.\n\nPerform the following to add a user to a given group:\n\n1. Sign in to the AWS Management Console and open the IAM console at [https://console.aws.amazon.com/iam/](https://console.aws.amazon.com/iam/).\n2. In the navigation pane, click `Groups`.\n3. Select the group to add a user to.\n4. Click `Add Users To Group`.\n5. Select the users to be added to the group.\n6. Click `Add Users`.\n\nPerform the following to remove a direct association between a user and policy:\n\n1. Sign in to the AWS Management Console and open the IAM console at [https://console.aws.amazon.com/iam/](https://console.aws.amazon.com/iam/).\n2. In the left navigation pane, click on Users.\n3. For each user:\n - Select the user\n - Click on the `Permissions` tab\n - Expand `Permissions policies` \n - Click `X` for each policy; then click Detach or Remove (depending on policy type)"
  },
  {
    "recommendation_number": "1.15",
    "section": 1.0,
    "title": "Ensure IAM policies that allow full \"*:*\" administrative privileges are not attached",
    "profile": "Level 1",
    "assessment_status": "Automated",
    "description": "IAM policies are the means by which privileges are granted to users, groups, or roles. It is recommended and considered standard security advice to grant least privilegeâ€”that is, granting only the permissions required to perform a task. Determine what users need to do, and then craft policies for them that allow the users to perform only those tasks, instead of granting full administrative privileges.",
    "audit_procedure": "Perform the following to determine existing policies:\n\n**From Command Line:**\n\n1. Run the following to get a list of IAM policies:\n```\n aws iam list-policies --only-attached --output text\n```\n2. For each policy returned, run the following command to determine if any policy is allowing full administrative privileges on the account:\n```\n aws iam get-policy-version --policy-arn <policy_arn> --version-id <version>\n```\n3. In the output, the policy should not contain any Statement block with `\"Effect\": \"Allow\"` and `Action` set to `\"*\"` and `Resource` set to `\"*\"`.",
    "remediation_procedure": "**From Console:**\n\nPerform the following to detach the policy that has full administrative privileges:\n\n1. Sign in to the AWS Management Console and open the IAM console at [https://console.aws.amazon.com/iam/](https://console.aws.amazon.com/iam/).\n2. In the navigation pane, click Policies and then search for the policy name found in the audit step.\n3. Select the policy that needs to be deleted.\n4. In the policy action menu, select `Detach`. \n5. Select all Users, Groups, Roles that have this policy attached.\n6. Click `Detach Policy`.\n7. Select the newly detached policy and select `Delete`.\n\n**From Command Line:**\n\nPerform the following to detach the policy that has full administrative privileges as found in the audit step:\n\n1. Lists all IAM users, groups, and roles that the specified managed policy is attached to.\n\n```\n aws iam list-entities-for-policy --policy-arn <policy_arn>\n```\n2. Detach the policy from all IAM Users:\n```\n aws iam detach-user-policy --user-name <iam_user> --policy-arn <policy_arn>\n```\n3. Detach the policy from all IAM Groups:\n```\n aws iam detach-group-policy --group-name <iam_group> --policy-arn <policy_arn>\n```\n4. Detach the policy from all IAM Roles:\n```\n aws iam detach-role-policy --role-name <iam_role> --policy-arn <policy_arn>\n```"
  },
  {
    "recommendation_number": "1.16",
    "section": 1.0,
    "title": "Ensure a support role has been created to manage incidents with AWS Support",
    "profile": "Level 1",
    "assessment_status": "Automated",
    "description": "AWS provides a support center that can be used for incident notification and response, as well as technical support and customer services. Create an IAM Role, with the appropriate policy assigned, to allow authorized users to manage incidents with AWS Support.",
    "audit_procedure": "**From Command Line:**\n\n1. List IAM policies, filter for the 'AWSSupportAccess' managed policy, and note the \"Arn\" element value:\n```\naws iam list-policies --query \"Policies[?PolicyName == 'AWSSupportAccess']\"\n```\n2. Check if the 'AWSSupportAccess' policy is attached to any role:\n\n```\naws iam list-entities-for-policy --policy-arn arn:aws:iam::aws:policy/AWSSupportAccess\n```\n\n3. In the output, ensure `PolicyRoles` does not return empty. 'Example: Example: PolicyRoles: [ ]'\n\nIf it returns empty refer to the remediation below.",
    "remediation_procedure": "**From Command Line:**\n\n1. Create an IAM role for managing incidents with AWS:\n - Create a trust relationship policy document that allows <iam_user> to manage AWS incidents, and save it locally as /tmp/TrustPolicy.json:\n```\n {\n \"Version\": \"2012-10-17\",\n \"Statement\": [\n {\n \"Effect\": \"Allow\",\n \"Principal\": {\n \"AWS\": \"<iam_user>\"\n },\n \"Action\": \"sts:AssumeRole\"\n }\n ]\n }\n```\n2. Create the IAM role using the above trust policy:\n```\naws iam create-role --role-name <aws_support_iam_role> --assume-role-policy-document file:///tmp/TrustPolicy.json\n```\n3. Attach 'AWSSupportAccess' managed policy to the created IAM role:\n```\naws iam attach-role-policy --policy-arn arn:aws:iam::aws:policy/AWSSupportAccess --role-name <aws_support_iam_role>\n```"
  },
  {
    "recommendation_number": "1.17",
    "section": 1.0,
    "title": "Ensure IAM instance roles are used for AWS resource access from instances",
    "profile": "Level 2",
    "assessment_status": "Automated",
    "description": "AWS access from within AWS instances can be done by either encoding AWS keys into AWS API calls or by assigning the instance to a role which has an appropriate permissions policy for the required access. \"AWS Access\" means accessing the APIs of AWS in order to access AWS resources or manage AWS account resources.",
    "audit_procedure": "First, check if the instance has any API secrets stored using Secret Scanning. Currently, AWS does not have a solution for this. You can use open-source tools like TruffleHog to scan for secrets in the EC2 instance. If a secret is found, then assign the role to the instance.\n\n**From Console:**\n\n1. Sign in to the AWS Management Console and navigate to the EC2 dashboard at `https://console.aws.amazon.com/ec2/`.\n2. In the left navigation panel, choose `Instances`.\n3. Select the EC2 instance you want to examine.\n4. Select `Actions`.\n5. Select `View details`.\n6. Select `Security` in the lower panel.\n - If the value for **Instance profile arn** is an instance profile ARN, then an instance profile (that contains an IAM role) is attached.\n - If the value for **IAM Role** is blank, no role is attached.\n - If the value for **IAM Role** contains a role, a role is attached.\n - If the value for **IAM Role** is \"No roles attached to instance profile: <Instance-Profile-Name>\", then an instance profile is attached to the instance, but it does not contain an IAM role.\n7. Repeat steps 3 to 6 for each EC2 instance in your AWS account.\n\n**From Command Line:**\n\n1. Run the `describe-instances` command to list all EC2 instance IDs in the selected AWS region:\n\n```\naws ec2 describe-instances --region <region-name> --query 'Reservations[*].Instances[*].InstanceId'\n```\n\n2. Run the `describe-instances` command again for each EC2 instance using the `IamInstanceProfile` identifier in the query filter to check if an IAM role is attached:\n\n```\naws ec2 describe-instances --region <region-name> --instance-id <Instance-ID> --query 'Reservations[*].Instances[*].IamInstanceProfile'\n```\n\n3. If an IAM role is attached, the command output will show the IAM instance profile ARN and ID. \n4. Repeat steps 2 and 3 for each EC2 instance in your AWS account.",
    "remediation_procedure": "**From Console:**\n\n1. Sign in to the AWS Management Console and navigate to the EC2 dashboard at `https://console.aws.amazon.com/ec2/`.\n2. In the left navigation panel, choose `Instances`.\n3. Select the EC2 instance you want to modify.\n4. Click `Actions`.\n5. Click `Security`.\n6. Click `Modify IAM role`.\n7. Click `Create new IAM role` if a new IAM role is required.\n8. Select the IAM role you want to attach to your instance in the `IAM role` dropdown.\n9. Click `Update IAM role`.\n10. Repeat steps 3 to 9 for each EC2 instance in your AWS account that requires an IAM role to be attached.\n\n**From Command Line:**\n\n1. Run the `describe-instances` command to list all EC2 instance IDs in the selected AWS region:\n\n```\naws ec2 describe-instances --region <region-name> --query 'Reservations[*].Instances[*].InstanceId'\n```\n\n2. Run the `associate-iam-instance-profile` command to attach an instance profile (which is attached to an IAM role) to the EC2 instance:\n\n```\naws ec2 associate-iam-instance-profile --region <region-name> --instance-id <Instance-ID> --iam-instance-profile Name=\"Instance-Profile-Name\"\n```\n\n3. Run the `describe-instances` command again for the recently modified EC2 instance. The command output should return the instance profile ARN and ID:\n\n```\naws ec2 describe-instances --region <region-name> --instance-id <Instance-ID> --query 'Reservations[*].Instances[*].IamInstanceProfile'\n```\n\n4. Repeat steps 2 and 3 for each EC2 instance in your AWS account that requires an IAM role to be attached."
  },
  {
    "recommendation_number": "1.18",
    "section": 1.0,
    "title": "Ensure that all expired SSL/TLS certificates stored in AWS IAM are removed",
    "profile": "Level 1",
    "assessment_status": "Automated",
    "description": "To enable HTTPS connections to your website or application in AWS, you need an SSL/TLS server certificate. You can use AWS Certificate Manager (ACM) or IAM to store and deploy server certificates. \nUse IAM as a certificate manager only when you must support HTTPS connections in a region that is not supported by ACM. IAM securely encrypts your private keys and stores the encrypted version in IAM SSL certificate storage. IAM supports deploying server certificates in all regions, but you must obtain your certificate from an external provider for use with AWS. You cannot upload an ACM certificate to IAM. Additionally, you cannot manage your certificates from the IAM Console.",
    "audit_procedure": "**From Console:**\n\nGetting the certificate expiration information via the AWS Management Console is not currently supported. To request information about the SSL/TLS certificates stored in IAM through the AWS API, use the Command Line Interface (CLI).\n\n**From Command Line:**\n\nRun the `list-server-certificates` command to list all the IAM-stored server certificates:\n\n```\naws iam list-server-certificates\n```\n\nThe command output should return an array that contains all the SSL/TLS certificates currently stored in IAM and their metadata (name, ID, expiration date, etc):\n\n```\n{\n \"ServerCertificateMetadataList\": [\n {\n \"ServerCertificateId\": \"EHDGFRW7EJFYTE88D\",\n \"ServerCertificateName\": \"MyServerCertificate\",\n \"Expiration\": \"2018-07-10T23:59:59Z\",\n \"Path\": \"/\",\n \"Arn\": \"arn:aws:iam::012345678910:server-certificate/MySSLCertificate\",\n \"UploadDate\": \"2018-06-10T11:56:08Z\"\n }\n ]\n}\n```\n\nVerify the `ServerCertificateName` and `Expiration` parameter value (expiration date) for each SSL/TLS certificate returned by the list-server-certificates command and determine if there are any expired server certificates currently stored in AWS IAM. If so, use the AWS API to remove them.\n\nIf this command returns:\n\n```\n{ { \"ServerCertificateMetadataList\": [] }\n```\n\nThis means that there are no expired certificates; it **does not** mean that no certificates exist.",
    "remediation_procedure": "**From Console:**\n\nRemoving expired certificates via AWS Management Console is not currently supported. To delete SSL/TLS certificates stored in IAM through the AWS API, use the Command Line Interface (CLI).\n\n**From Command Line:**\n\nTo delete an expired certificate, run the following command by replacing <CERTIFICATE_NAME> with the name of the certificate to delete:\n\n```\naws iam delete-server-certificate --server-certificate-name <CERTIFICATE_NAME>\n```\n\nWhen the preceding command is successful, it does not return any output."
  },
  {
    "recommendation_number": "1.19",
    "section": 1.0,
    "title": "Ensure that IAM External Access Analyzer is enabled for all regions",
    "profile": "Level 1",
    "assessment_status": "Automated",
    "description": "Enable the IAM External Access Analyzer regarding all resources in each active AWS region.\n\nIAM Access Analyzer is a technology introduced at AWS reinvent 2019. After the Analyzer is enabled in IAM, scan results are displayed on the console showing the accessible resources. Scans show resources that other accounts and federated users can access, such as KMS keys and IAM roles. The results allow you to determine whether an unintended user is permitted, making it easier for administrators to monitor least privilege access. Access Analyzer analyzes only the policies that are applied to resources in the same AWS Region.",
    "audit_procedure": "**From Console:**\n\n1. Open the IAM console at `https://console.aws.amazon.com/iam/`\n2. Under `Access analyzer` choose `External Access`\n3. Ensure that at least one analyzer is present\n4. Ensure that the `STATUS` is set to `Active`\n5. Repeat these steps for each active region\n\n**From Command Line:**\n\n1. Run the following command:\n```\naws accessanalyzer list-analyzers type --<Account|Organization> | grep status\n```\n2. Ensure that at least one Analyzer's `status` is set to `ACTIVE`.\n\n3. Repeat the steps above for each active region.\n\nIf an Access Analyzer is not listed for each region or the status is not set to active refer to the remediation procedure below.",
    "remediation_procedure": "**From Console:**\n\nPerform the following to enable IAM Access Analyzer for IAM policies:\n\n1. Open the IAM console at `https://console.aws.amazon.com/iam/.`\n2. Choose `Access analyzer`.\n3. Choose `Create external access analyzer`.\n4. On the `Create analyzer` page, confirm that the `Region` displayed is the Region where you want to enable Access Analyzer.\n5. Optionally enter a name for the analyzer.\n6. Optionally add any tags that you want to apply to the analyzer. \n7. Choose `Create Analyzer`.\n8. Repeat these step for each active region.\n\n**From Command Line:**\n\nRun the following command:\n```\naws accessanalyzer create-analyzer --analyzer-name <NAME> --type <ACCOUNT|ORGANIZATION>\n```\nRepeat this command for each active region.\n\n**Note:** The IAM Access Analyzer is successfully configured only when the account you use has the necessary permissions."
  },
  {
    "recommendation_number": "1.2",
    "section": 1.0,
    "title": "Ensure security contact information is registered",
    "profile": "Level 1",
    "assessment_status": "Manual",
    "description": "AWS provides customers with the option of specifying the contact information for account's security team. It is recommended that this information be provided.",
    "audit_procedure": "Perform the following to determine if security contact information is present:\n\n**From Console:**\n\n1. Click on your account name at the top right corner of the console\n2. From the drop-down menu Click `My Account` \n3. Scroll down to the `Alternate Contacts` section\n4. Ensure contact information is specified in the `Security` section\n\n**From Command Line:**\n\n1. Run the following command:\n\n``` \naws account get-alternate-contact --alternate-contact-type SECURITY\n```\n2. Ensure proper contact information is specified for the `Security` contact.",
    "remediation_procedure": "Perform the following to establish security contact information:\n\n**From Console:**\n\n1. Click on your account name at the top right corner of the console.\n2. From the drop-down menu Click `My Account` \n3. Scroll down to the `Alternate Contacts` section\n4. Enter contact information in the `Security` section\n\n**From Command Line:**\n\nRun the following command with the following input parameters:\n--email-address, --name, and --phone-number.\n\n```\naws account put-alternate-contact --alternate-contact-type SECURITY \n``` \n\n**Note:** Consider specifying an internal email distribution list to ensure emails are regularly monitored by more than one individual."
  },
  {
    "recommendation_number": "1.20",
    "section": 1.0,
    "title": "Ensure IAM users are managed centrally via identity federation or AWS Organizations for multi-account environments",
    "profile": "Level 2",
    "assessment_status": "Manual",
    "description": "In multi-account environments, IAM user centralization facilitates greater user control. User access beyond the initial account is then provided via role assumption. Centralization of users can be accomplished through federation with an external identity provider or through the use of AWS Organizations.",
    "audit_procedure": "For multi-account AWS environments with an external identity provider:\n\n1. Determine the master account for identity federation or IAM user management\n2. Login to that account through the AWS Management Console\n3. Click `Services` \n4. Click `IAM` \n5. Click `Identity providers`\n6. Verify the configuration\n\nFor multi-account AWS environments with an external identity provider, as well as for those implementing AWS Organizations without an external identity provider:\n\n1. Determine all accounts that should not have local users present\n2. Log into the AWS Management Console\n3. Switch role into each identified account\n4. Click `Services` \n5. Click `IAM` \n6. Click `Users`\n7. Confirm that no IAM users representing individuals are present",
    "remediation_procedure": "The remediation procedure will vary based on each individual organization's implementation of identity federation and/or AWS Organizations, with the acceptance criteria that no non-service IAM users and non-root accounts are present outside the account providing centralized IAM user management."
  },
  {
    "recommendation_number": "1.21",
    "section": 1.0,
    "title": "Ensure access to AWSCloudShellFullAccess is restricted",
    "profile": "Level 1",
    "assessment_status": "Manual",
    "description": "AWS CloudShell is a convenient way of running CLI commands against AWS services; a managed IAM policy ('AWSCloudShellFullAccess') provides full access to CloudShell, which allows file upload and download capability between a user's local system and the CloudShell environment. Within the CloudShell environment, a user has sudo permissions and can access the internet. Therefore, it is feasible to install file transfer software, for example, and move data from CloudShell to external internet servers.",
    "audit_procedure": "**From Console**\n1. Open the IAM console at https://console.aws.amazon.com/iam/\n2. In the left pane, select Policies\n3. Search for and select AWSCloudShellFullAccess\n4. On the Entities attached tab, ensure that there are no entities using this policy\n\n**From Command Line**\n1. List IAM policies, filter for the 'AWSCloudShellFullAccess' managed policy, and note the \"Arn\" element value:\n```\naws iam list-policies --query \"Policies[?PolicyName == 'AWSCloudShellFullAccess']\"\n```\n2. Check if the 'AWSCloudShellFullAccess' policy is attached to any role:\n```\naws iam list-entities-for-policy --policy-arn arn:aws:iam::aws:policy/AWSCloudShellFullAccess\n```\n3. In the output, ensure PolicyRoles returns empty. 'Example: Example: PolicyRoles: [ ]'\n\nIf it does not return empty, refer to the remediation below.\n\n**Note:** Keep in mind that other policies may grant access.",
    "remediation_procedure": "**From Console**\n1. Open the IAM console at https://console.aws.amazon.com/iam/\n2. In the left pane, select Policies\n3. Search for and select AWSCloudShellFullAccess\n4. On the Entities attached tab, for each item, check the box and select Detach"
  },
  {
    "recommendation_number": "1.3",
    "section": 1.0,
    "title": "Ensure no 'root' user account access key exists",
    "profile": "Level 1",
    "assessment_status": "Automated",
    "description": "The 'root' user account is the most privileged user in an AWS account. AWS Access Keys provide programmatic access to a given AWS account. It is recommended that all access keys associated with the 'root' user account be deleted.",
    "audit_procedure": "Perform the following to determine if the 'root' user account has access keys:\n\n**From Console:**\n\n1. Login to the AWS Management Console.\n2. Click `Services`.\n3. Click `IAM`.\n4. Click on `Credential Report`.\n5. This will download a `.csv` file which contains credential usage for all IAM users within an AWS Account - open this file.\n6. For the `<root_account>` user, ensure the `access_key_1_active` and `access_key_2_active` fields are set to `FALSE`.\n\n**From Command Line:**\n\nRun the following command:\n```\naws iam get-account-summary | grep \"AccountAccessKeysPresent\" \n```\nIf no 'root' access keys exist the output will show `\"AccountAccessKeysPresent\": 0,`. \n\nIf the output shows a \"1\", then 'root' keys exist and should be deleted.",
    "remediation_procedure": "Perform the following to delete active 'root' user access keys.\n\n**From Console:**\n\n1. Sign in to the AWS Management Console as 'root' and open the IAM console at [https://console.aws.amazon.com/iam/](https://console.aws.amazon.com/iam/).\n2. Click on `<root_account>` at the top right and select `My Security Credentials` from the drop down list.\n3. On the pop out screen Click on `Continue to Security Credentials`.\n4. Click on `Access Keys` (Access Key ID and Secret Access Key).\n5. If there are active keys, under `Status`, click `Delete` (Note: Deleted keys cannot be recovered).\n\nNote: While a key can be made inactive, this inactive key will still show up in the CLI command from the audit procedure, and may lead to the root user being falsely flagged as being non-compliant."
  },
  {
    "recommendation_number": "1.4",
    "section": 1.0,
    "title": "Ensure MFA is enabled for the 'root' user account",
    "profile": "Level 1",
    "assessment_status": "Automated",
    "description": "The 'root' user account is the most privileged user in an AWS account. Multi-factor Authentication (MFA) adds an extra layer of protection on top of a username and password. With MFA enabled, when a user signs in to an AWS website, they will be prompted for their username and password as well as for an authentication code from their AWS MFA device.\n\n**Note:** When virtual MFA is used for 'root' accounts, it is recommended that the device used is NOT a personal device, but rather a dedicated mobile device (tablet or phone) that is kept charged and secured, independent of any individual personal devices (\"non-personal virtual MFA\"). This lessens the risks of losing access to the MFA due to device loss, device trade-in, or if the individual owning the device is no longer employed at the company.\n\nWhere an AWS Organization is using centralized root access, root credentials can be removed from member accounts. In that case it is neither possible nor necessary to configure root MFA in the member account.",
    "audit_procedure": "Perform the following to determine if the 'root' user account is enabled and has MFA setup:\n\n**From Console:**\n\n1. Login to the AWS Management Console\n2. Click `Services` \n3. Click `IAM` \n4. Click on `Credential Report` \n5. This will download a `.csv` file which contains credential usage for all IAM users within an AWS Account - open this file\n6. For the `<root_account>` user, ensure the `mfa_active` field is set to `TRUE` or the `password_enabled` field is set to `FALSE`\n\n**From Command Line:**\n\n1. Run the following command:\n```\n aws iam get-account-summary | grep \"AccountMFAEnabled\"\n aws iam get-account-summary | grep \"AccountPasswordPresent\"\n```\n2. Ensure the AccountMFAEnabled property is set to 1 or the AccountPasswordPresent property is set to 0",
    "remediation_procedure": "**Note:** To manage MFA devices for the 'root' AWS account, you must use your 'root' account credentials to sign in to AWS. You cannot manage MFA devices for the 'root' account using other credentials.\n\nPerform the following to establish MFA for the 'root' user account:\n\n1. Sign in to the AWS Management Console and open the IAM console at [https://console.aws.amazon.com/iam/](https://console.aws.amazon.com/iam/).\n2. Choose `Dashboard` , and under `Security Status` , expand `Activate MFA` on your root account.\n3. Choose `Activate MFA` \n4. In the wizard, choose `A virtual MFA` device and then choose `Next Step` .\n5. IAM generates and displays configuration information for the virtual MFA device, including a QR code graphic. The graphic is a representation of the 'secret configuration key' that is available for manual entry on devices that do not support QR codes.\n6. Open your virtual MFA application. (For a list of apps that you can use for hosting virtual MFA devices, see [Virtual MFA Applications](http://aws.amazon.com/iam/details/mfa/#Virtual_MFA_Applications).) If the virtual MFA application supports multiple accounts (multiple virtual MFA devices), choose the option to create a new account (a new virtual MFA device).\n7. Determine whether the MFA app supports QR codes, and then do one of the following:\n\n - Use the app to scan the QR code. For example, you might choose the camera icon or choose an option similar to Scan code, and then use the device's camera to scan the code.\n - In the Manage MFA Device wizard, choose Show secret key for manual configuration, and then type the secret configuration key into your MFA application.\n\nWhen you are finished, the virtual MFA device starts generating one-time passwords.\n\nIn the Manage MFA Device wizard, in the Authentication Code 1 box, type the one-time password that currently appears in the virtual MFA device. Wait up to 30 seconds for the device to generate a new one-time password. Then type the second one-time password into the Authentication Code 2 box. Choose Assign Virtual MFA."
  },
  {
    "recommendation_number": "1.5",
    "section": 1.0,
    "title": "Ensure hardware MFA is enabled for the 'root' user account",
    "profile": "Level 2",
    "assessment_status": "Manual",
    "description": "The 'root' user account is the most privileged user in an AWS account. MFA adds an extra layer of protection on top of a user name and password. With MFA enabled, when a user signs in to an AWS website, they will be prompted for their user name and password as well as for an authentication code from their AWS MFA device. For Level 2, it is recommended that the 'root' user account be protected with a hardware MFA.\n\nWhere an AWS Organization is using centralized root access, root credentials can be removed from member accounts. In that case it is neither possible nor necessary to configure root MFA in the member account.",
    "audit_procedure": "Perform the following to determine if the 'root' user account has a hardware MFA setup:\n\n1. Run the following command to determine if the 'root' account has MFA setup:\n```\n aws iam get-account-summary | grep \"AccountMFAEnabled\"\n aws iam get-account-summary | grep \"AccountPasswordPresent\"\n```\n\nThe `AccountMFAEnabled` property is set to `1` will ensure that the 'root' user account has MFA (Virtual or Hardware) Enabled. `AccountPasswordPresent` set to `0` indicates that the `root` console credential has been removed.\nIf `AccountMFAEnabled` property is set to `0` and `AccountPasswordPresent` is set to `1` the account is not compliant with this recommendation.\n\n2. If `AccountMFAEnabled` property is set to `1`, determine 'root' account has Hardware MFA enabled.\nRun the following command to list all virtual MFA devices:\n```\n aws iam list-virtual-mfa-devices \n```\nIf the output contains one MFA with the following Serial Number, it means the MFA is virtual, not hardware and the account is not compliant with this recommendation:\n\n `\"SerialNumber\": \"arn:aws:iam::_<aws_account_number>_:mfa/root-account-mfa-device\"`",
    "remediation_procedure": "**Note:** To manage MFA devices for the AWS 'root' user account, you must use your 'root' account credentials to sign in to AWS. You cannot manage MFA devices for the 'root' account using other credentials.\n\nPerform the following to establish a hardware MFA for the 'root' user account:\n\n1. Sign in to the AWS Management Console and open the IAM console at [https://console.aws.amazon.com/iam/](https://console.aws.amazon.com/iam/).\n2. Choose `Dashboard`, and under `Security Status`, expand `Activate MFA` on your root account.\n3. Choose `Activate MFA`.\n4. In the wizard, choose `A hardware MFA` device and then choose `Next Step`.\n5. In the `Serial Number` box, enter the serial number that is found on the back of the MFA device.\n6. In the `Authentication Code 1` box, enter the six-digit number displayed by the MFA device. You might need to press the button on the front of the device to display the number.\n7. Wait 30 seconds while the device refreshes the code, and then enter the next six-digit number into the `Authentication Code 2` box. You might need to press the button on the front of the device again to display the second number.\n8. Choose `Next Step`. The MFA device is now associated with the AWS account. The next time you use your AWS account credentials to sign in, you must type a code from the hardware MFA device.\n\nRemediation for this recommendation is not available through AWS CLI."
  },
  {
    "recommendation_number": "1.6",
    "section": 1.0,
    "title": "Eliminate use of the 'root' user for administrative and daily tasks",
    "profile": "Level 1",
    "assessment_status": "Manual",
    "description": "With the creation of an AWS account, a 'root user' is created that cannot be disabled or deleted. That user has unrestricted access to and control over all resources in the AWS account. It is highly recommended that the use of this account be avoided for everyday tasks.",
    "audit_procedure": "**From Console:**\n\n1. Login to the AWS Management Console at `https://console.aws.amazon.com/iam/`.\n2. In the left pane, click `Credential Report`.\n3. Click on `Download Report`.\n4. Open or Save the file locally.\n5. Locate the `<root account>` under the user column.\n6. Review `password_last_used, access_key_1_last_used_date, access_key_2_last_used_date` to determine when the 'root user' was last used.\n\n**From Command Line:**\n\nRun the following CLI commands to provide a credential report for determining the last time the 'root user' was used:\n```\naws iam generate-credential-report\n```\n```\naws iam get-credential-report --query 'Content' --output text | base64 -d | cut -d, -f1,5,11,16 | grep -B1 '<root_account>'\n```\n\nReview `password_last_used`, `access_key_1_last_used_date`, `access_key_2_last_used_date` to determine when the _root user_ was last used.\n\n**Note:** There are a few conditions under which the use of the 'root' user account is required. Please see the reference links for all of the tasks that require use of the 'root' user.",
    "remediation_procedure": "If you find that the 'root' user account is being used for daily activities, including administrative tasks that do not require the 'root' user:\n\n1. Change the 'root' user password.\n2. Deactivate or delete any access keys associated with the 'root' user.\n\nRemember, anyone who has 'root' user credentials for your AWS account has unrestricted access to and control of all the resources in your account, including billing information."
  },
  {
    "recommendation_number": "1.7",
    "section": 1.0,
    "title": "Ensure IAM password policy requires minimum length of 14 or greater",
    "profile": "Level 1",
    "assessment_status": "Automated",
    "description": "Password policies are, in part, used to enforce password complexity requirements. IAM password policies can be used to ensure passwords are at least a given length. It is recommended that the password policy require a minimum password length 14.",
    "audit_procedure": "Perform the following to ensure the password policy is configured as prescribed:\n\n**From Console:**\n\n1. Login to AWS Console (with appropriate permissions to View Identity Access Management Account Settings)\n2. Go to IAM Service on the AWS Console\n3. Click on Account Settings on the Left Pane\n4. Ensure \"Minimum password length\" is set to 14 or greater.\n\n**From Command Line:**\n```\naws iam get-account-password-policy\n```\nEnsure the output of the above command includes \"MinimumPasswordLength\": 14 (or higher)",
    "remediation_procedure": "Perform the following to set the password policy as prescribed:\n\n**From Console:**\n\n1. Login to AWS Console (with appropriate permissions to View Identity Access Management Account Settings)\n2. Go to IAM Service on the AWS Console\n3. Click on Account Settings on the Left Pane\n4. Set \"Minimum password length\" to `14` or greater.\n5. Click \"Apply password policy\"\n\n**From Command Line:**\n```\n aws iam update-account-password-policy --minimum-password-length 14\n```\nNote: All commands starting with \"aws iam update-account-password-policy\" can be combined into a single command."
  },
  {
    "recommendation_number": "1.8",
    "section": 1.0,
    "title": "Ensure IAM password policy prevents password reuse",
    "profile": "Level 1",
    "assessment_status": "Automated",
    "description": "IAM password policies can prevent the reuse of a given password by the same user. It is recommended that the password policy prevent the reuse of passwords.",
    "audit_procedure": "Perform the following to ensure the password policy is configured as prescribed:\n\n**From Console:**\n\n1. Login to AWS Console (with appropriate permissions to View Identity Access Management Account Settings)\n2. Go to IAM Service on the AWS Console\n3. Click on Account Settings on the Left Pane\n4. Ensure \"Prevent password reuse\" is checked\n5. Ensure \"Number of passwords to remember\" is set to 24\n\n**From Command Line:**\n```\naws iam get-account-password-policy \n```\nEnsure the output of the above command includes \"PasswordReusePrevention\": 24",
    "remediation_procedure": "Perform the following to set the password policy as prescribed:\n\n**From Console:**\n\n1. Login to AWS Console (with appropriate permissions to View Identity Access Management Account Settings)\n2. Go to IAM Service on the AWS Console\n3. Click on Account Settings on the Left Pane\n4. Check \"Prevent password reuse\"\n5. Set \"Number of passwords to remember\" is set to `24` \n\n**From Command Line:**\n```\n aws iam update-account-password-policy --password-reuse-prevention 24\n```\nNote: All commands starting with \"aws iam update-account-password-policy\" can be combined into a single command."
  },
  {
    "recommendation_number": "1.9",
    "section": 1.0,
    "title": "Ensure multi-factor authentication (MFA) is enabled for all IAM users that have a console password",
    "profile": "Level 1",
    "assessment_status": "Automated",
    "description": "Multi-Factor Authentication (MFA) adds an extra layer of authentication assurance beyond traditional credentials. With MFA enabled, when a user signs in to the AWS Console, they will be prompted for their user name and password as well as for an authentication code from their physical or virtual MFA token. It is recommended that MFA be enabled for all accounts that have a console password.",
    "audit_procedure": "Perform the following to determine if a MFA device is enabled for all IAM users having a console password:\n\n**From Console:**\n\n1. Open the IAM console at [https://console.aws.amazon.com/iam/](https://console.aws.amazon.com/iam/).\n2. In the left pane, select `Users` \n3. If the `MFA` or `Password age` columns are not visible in the table, click the gear icon at the upper right corner of the table and ensure a checkmark is next to both, then click `Close`.\n4. Ensure that for each user where the `Password age` column shows a password age, the `MFA` column shows `Virtual`, `U2F Security Key`, or `Hardware`.\n\n**From Command Line:**\n\n1. Run the following command (OSX/Linux/UNIX) to generate a list of all IAM users along with their password and MFA status:\n```\n aws iam generate-credential-report\n```\n```\n aws iam get-credential-report --query 'Content' --output text | base64 -d | cut -d, -f1,4,8 \n```\n2. The output of this command will produce a table similar to the following:\n```\n user,password_enabled,mfa_active\n elise,false,false\n brandon,true,true\n rakesh,false,false\n helene,false,false\n paras,true,true\n anitha,false,false \n```\n3. For any column having `password_enabled` set to `true` , ensure `mfa_active` is also set to `true.`",
    "remediation_procedure": "Perform the following to enable MFA:\n\n**From Console:**\n\n1. Sign in to the AWS Management Console and open the IAM console at 'https://console.aws.amazon.com/iam/'\n2. In the left pane, select `Users`.\n3. In the `User Name` list, choose the name of the intended MFA user.\n4. Choose the `Security Credentials` tab, and then choose `Manage MFA Device`.\n5. In the `Manage MFA Device wizard`, choose `Virtual MFA` device, and then choose `Continue`.\n\n IAM generates and displays configuration information for the virtual MFA device, including a QR code graphic. The graphic is a representation of the 'secret configuration key' that is available for manual entry on devices that do not support QR codes.\n\n6. Open your virtual MFA application. (For a list of apps that you can use for hosting virtual MFA devices, see Virtual MFA Applications at https://aws.amazon.com/iam/details/mfa/#Virtual_MFA_Applications). If the virtual MFA application supports multiple accounts (multiple virtual MFA devices), choose the option to create a new account (a new virtual MFA device).\n7. Determine whether the MFA app supports QR codes, and then do one of the following:\n\n - Use the app to scan the QR code. For example, you might choose the camera icon or choose an option similar to Scan code, and then use the device's camera to scan the code.\n - In the Manage MFA Device wizard, choose Show secret key for manual configuration, and then type the secret configuration key into your MFA application.\n\n When you are finished, the virtual MFA device starts generating one-time passwords.\n\n8. In the `Manage MFA Device wizard`, in the `MFA Code 1 box`, type the `one-time password` that currently appears in the virtual MFA device. Wait up to 30 seconds for the device to generate a new one-time password. Then type the second `one-time password` into the `MFA Code 2 box`.\n\n9. Click `Assign MFA`."
  },
  {
    "recommendation_number": "2.1.1",
    "section": 2.1,
    "title": "Ensure S3 Bucket Policy is set to deny HTTP requests",
    "profile": "Level 2",
    "assessment_status": "Automated",
    "description": "At the Amazon S3 bucket level, you can configure permissions through a bucket policy, making the objects accessible only through HTTPS.",
    "audit_procedure": "To allow access to HTTPS, you can use a bucket policy with the effect `allow` and a condition that checks for the key `\"aws:SecureTransport\": \"true\"`. This means that HTTPS requests are allowed, but it does not deny HTTP requests. To explicitly deny HTTP access, ensure that there is also a bucket policy with the effect `deny` that contains the key `\"aws:SecureTransport\": \"false\"`. You may also require TLS by setting a policy to deny any version lower than the one you wish to require, using the condition `NumericLessThan` and the key `\"s3:TlsVersion\": \"1.2\"`.\n\n**From Console:**\n\n1. Login to the AWS Management Console and open the Amazon S3 console using https://console.aws.amazon.com/s3/.\n2. Select the check box next to the Bucket.\n3. Click on 'Permissions', then click on `Bucket Policy`.\n4. Ensure that a policy is listed that matches either:\n```\n{\n \"Sid\": <optional>,\n \"Effect\": \"Deny\",\n \"Principal\": \"*\",\n \"Action\": \"s3:*\",\n \"Resource\": \"arn:aws:s3:::<bucket_name>/*\",\n \"Condition\": {\n \"Bool\": {\n \"aws:SecureTransport\": \"false\"\n }\n }\n}\n```\nor\n```\n{\n \"Sid\": \"<optional>\",\n \"Effect\": \"Deny\",\n \"Principal\": \"*\",\n \"Action\": \"s3:*\",\n \"Resource\": [\n \"arn:aws:s3:::<bucket_name>\",\n \"arn:aws:s3:::<bucket_name>/*\"\n ],\n \"Condition\": {\n \"NumericLessThan\": {\n \"s3:TlsVersion\": \"1.2\"\n }\n }\n}\n```\n\n`<optional>` and `<bucket_name>` will be specific to your account, and TLS version will be site/policy specific to your organisation.\n\n5. Repeat for all the buckets in your AWS account.\n\n**From Command Line:**\n\n1. List all of the S3 Buckets \n```\naws s3 ls\n```\n2. Using the list of buckets, run this command on each of them:\n```\naws s3api get-bucket-policy --bucket <bucket_name> | grep aws:SecureTransport\n```\nor\n```\naws s3api get-bucket-policy --bucket <bucket_name> | grep s3:TlsVersion\n```\nNOTE : If an error is thrown by the CLI, it means no policy has been configured for the specified S3 bucket, and that by default it is allowing both HTTP and HTTPS requests.\n\n3. Confirm that `aws:SecureTransport` is set to false (such as `aws:SecureTransport:false`) or that `s3:TlsVersion` has a site-specific value.\n4. Confirm that the policy line has Effect set to Deny 'Effect:Deny'",
    "remediation_procedure": "**From Console:**\n\n1. Login to the AWS Management Console and open the Amazon S3 console using https://console.aws.amazon.com/s3/.\n2. Select the check box next to the Bucket.\n3. Click on 'Permissions'.\n4. Click 'Bucket Policy'.\n5. Add either of the following to the existing policy, filling in the required information:\n```\n{\n \"Sid\": <optional>,\n \"Effect\": \"Deny\",\n \"Principal\": \"*\",\n \"Action\": \"s3:*\",\n \"Resource\": \"arn:aws:s3:::<bucket_name>/*\",\n \"Condition\": {\n \"Bool\": {\n \"aws:SecureTransport\": \"false\"\n }\n }\n}\n```\nor\n```\n{\n \"Sid\": \"<optional>\",\n \"Effect\": \"Deny\",\n \"Principal\": \"*\",\n \"Action\": \"s3:*\",\n \"Resource\": [\n \"arn:aws:s3:::<bucket_name>\",\n \"arn:aws:s3:::<bucket_name>/*\"\n ],\n \"Condition\": {\n \"NumericLessThan\": {\n \"s3:TlsVersion\": \"1.2\"\n }\n }\n}\n```\n6. Save\n7. Repeat for all the buckets in your AWS account that contain sensitive data.\n\n**From Console** \n\nUsing AWS Policy Generator:\n\n1. Repeat steps 1-4 above.\n2. Click on `Policy Generator` at the bottom of the Bucket Policy Editor.\n3. Select Policy Type `S3 Bucket Policy`.\n4. Add Statements:\n- `Effect` = Deny\n- `Principal` = *\n- `AWS Service` = Amazon S3\n- `Actions` = *\n- `Amazon Resource Name` = <ARN of the S3 Bucket>\n5. Generate Policy.\n6. Copy the text and add it to the Bucket Policy.\n\n**From Command Line:**\n\n1. Export the bucket policy to a json file:\n```\naws s3api get-bucket-policy --bucket <bucket_name> --query Policy --output text > policy.json\n```\n\n2. Modify the policy.json file by adding either of the following:\n```\n{\n \"Sid\": <optional>,\n \"Effect\": \"Deny\",\n \"Principal\": \"*\",\n \"Action\": \"s3:*\",\n \"Resource\": \"arn:aws:s3:::<bucket_name>/*\",\n \"Condition\": {\n \"Bool\": {\n \"aws:SecureTransport\": \"false\"\n }\n }\n}\n```\nor\n```\n{\n \"Sid\": \"<optional>\",\n \"Effect\": \"Deny\",\n \"Principal\": \"*\",\n \"Action\": \"s3:*\",\n \"Resource\": [\n \"arn:aws:s3:::<bucket_name>\",\n \"arn:aws:s3:::<bucket_name>/*\"\n ],\n \"Condition\": {\n \"NumericLessThan\": {\n \"s3:TlsVersion\": \"1.2\"\n }\n }\n}\n```\n3. Apply this modified policy back to the S3 bucket:\n```\naws s3api put-bucket-policy --bucket <bucket_name> --policy file://policy.json\n```"
  },
  {
    "recommendation_number": "2.1.2",
    "section": 2.1,
    "title": "Ensure MFA Delete is enabled on S3 buckets",
    "profile": "Level 2",
    "assessment_status": "Manual",
    "description": "Once MFA Delete is enabled on your sensitive and classified S3 bucket, it requires the user to provide two forms of authentication.",
    "audit_procedure": "Perform the steps below to confirm that MFA delete is configured on an S3 bucket:\n\n**From Console:**\n\n1. Login to the S3 console at `https://console.aws.amazon.com/s3/`.\n\n2. Click the `check` box next to the name of the bucket you want to confirm.\n\n3. In the window under `Properties`:\n- Confirm that Versioning is `Enabled`\n- Confirm that MFA Delete is `Enabled`\n\n**From Command Line:**\n\n1. Run the `get-bucket-versioning` command:\n```\naws s3api get-bucket-versioning --bucket my-bucket\n```\n\nExample output:\n```\n<VersioningConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n <Status>Enabled</Status>\n <MfaDelete>Enabled</MfaDelete> \n</VersioningConfiguration>\n```\n\nIf the console or CLI output does not show that Versioning and MFA Delete are `enabled`, please refer to the remediation below.",
    "remediation_procedure": "Perform the steps below to enable MFA delete on an S3 bucket:\n\n**Note:**\n\n- You cannot enable MFA Delete using the AWS Management Console; you must use the AWS CLI or API.\n\n- You must use your 'root' account to enable MFA Delete on S3 buckets.\n\n**From Command line:**\n\n1. Run the s3api `put-bucket-versioning` command:\n\n```\naws s3api put-bucket-versioning --profile my-root-profile --bucket Bucket_Name --versioning-configuration Status=Enabled,MFADelete=Enabled --mfa â€œarn:aws:iam::aws_account_id:mfa/root-account-mfa-device passcodeâ€\n```"
  },
  {
    "recommendation_number": "2.1.3",
    "section": 2.1,
    "title": "Ensure all data in Amazon S3 has been discovered, classified, and secured when necessary",
    "profile": "Level 2",
    "assessment_status": "Manual",
    "description": "Amazon S3 buckets can contain sensitive data that, for security purposes, should be discovered, monitored, classified, and protected. Macie, along with other third-party tools, can automatically provide an inventory of Amazon S3 buckets.",
    "audit_procedure": "Perform the following steps to determine if Macie is running:\n\n**From Console:**\n\n1. Login to the Macie console at https://console.aws.amazon.com/macie/.\n\n2. In the left hand pane, click on `By job` under findings.\n\n3. Confirm that you have a job set up for your S3 buckets.\n\nWhen you log into the Macie console, if you are not taken to the summary page and do not have a job set up and running, then refer to the remediation procedure below.\n\nIf you are using a third-party tool to manage and protect your S3 data, you meet this recommendation.",
    "remediation_procedure": "Perform the steps below to enable and configure Amazon Macie:\n\n**From Console:**\n\n1. Log on to the Macie console at `https://console.aws.amazon.com/macie/`.\n\n2. Click `Get started`.\n\n3. Click `Enable Macie`.\n\nSet up a repository for sensitive data discovery results:\n\n1. In the left pane, under Settings, click `Discovery results`.\n\n2. Make sure `Create bucket` is selected.\n\n3. Create a bucket and enter a name for it. The name must be unique across all S3 buckets, and it must start with a lowercase letter or a number.\n\n4. Click `Advanced`.\n\n5. For block all public access, make sure `Yes` is selected.\n\n6. For KMS encryption, specify the AWS KMS key that you want to use to encrypt the results. The key must be a symmetric customer master key (CMK) that is in the same region as the S3 bucket.\n\n7. Click `Save`.\n\nCreate a job to discover sensitive data:\n\n1. In the left pane, click `S3 buckets`. Macie displays a list of all the S3 buckets for your account.\n\n2. Check the box for each bucket that you want Macie to analyze as part of the job.\n\n3. Click `Create job`.\n\n4. Click `Quick create`.\n\n5. For the Name and Description step, enter a name and, optionally, a description of the job.\n\n6. Click `Next`.\n\n7. For the Review and create step, click `Submit`.\n\nReview your findings:\n\n1. In the left pane, click `Findings`.\n\n2. To view the details of a specific finding, choose any field other than the check box for the finding.\n\nIf you are using a third-party tool to manage and protect your S3 data, follow the vendor documentation for implementing and configuring that tool."
  },
  {
    "recommendation_number": "2.1.4",
    "section": 2.1,
    "title": "Ensure that S3 is configured with 'Block Public Access' enabled",
    "profile": "Level 1",
    "assessment_status": "Automated",
    "description": "Amazon S3 provides `Block public access (bucket settings)` and `Block public access (account settings)` to help you manage public access to Amazon S3 resources. By default, S3 buckets and objects are created with public access disabled. However, an IAM principal with sufficient S3 permissions can enable public access at the bucket and/or object level. While enabled, `Block public access (bucket settings)` prevents an individual bucket and its contained objects from becoming publicly accessible. Similarly, `Block public access (account settings)` prevents all buckets and their contained objects from becoming publicly accessible across the entire account.",
    "audit_procedure": "**If utilizing Block Public Access (bucket settings)**\n\n**From Console:**\n\n1. Login to the AWS Management Console and open the Amazon S3 console using https://console.aws.amazon.com/s3/.\n2. Select the check box next to a bucket.\n3. Click on 'Edit public access settings'.\n4. Ensure that the block public access settings are configured appropriately for this bucket.\n5. Repeat for all the buckets in your AWS account.\n\n**From Command Line:**\n\n1. List all of the S3 buckets:\n```\naws s3 ls\n```\n2. Find the public access settings for a specific bucket:\n```\naws s3api get-public-access-block --bucket <bucket-name>\n```\nOutput if Block Public Access is enabled:\n\n```\n{\n \"PublicAccessBlockConfiguration\": {\n \"BlockPublicAcls\": true,\n \"IgnorePublicAcls\": true,\n \"BlockPublicPolicy\": true,\n \"RestrictPublicBuckets\": true\n }\n}\n```\n\nIf the output reads `false` for the separate configuration settings, then proceed with the remediation.\n\n**If utilizing Block Public Access (account settings)**\n\n**From Console:**\n\n1. Login to the AWS Management Console and open the Amazon S3 console using https://console.aws.amazon.com/s3/.\n2. Choose `Block public access (account settings)`.\n3. Ensure that the block public access settings are configured appropriately for your AWS account.\n\n**From Command Line:**\n\nTo check the block public access settings for this account, run the following command:\n`aws s3control get-public-access-block --account-id <account-id> --region <region-name>`\n\nOutput if Block Public Access is enabled:\n\n```\n{\n \"PublicAccessBlockConfiguration\": {\n \"IgnorePublicAcls\": true, \n \"BlockPublicPolicy\": true, \n \"BlockPublicAcls\": true, \n \"RestrictPublicBuckets\": true\n }\n}\n```\n\nIf the output reads `false` for the separate configuration settings, then proceed with the remediation.",
    "remediation_procedure": "**If utilizing Block Public Access (bucket settings)**\n\n**From Console:**\n\n1. Login to the AWS Management Console and open the Amazon S3 console using https://console.aws.amazon.com/s3/. \n2. Select the check box next to a bucket.\n3. Click 'Edit public access settings'.\n4. Click 'Block all public access'\n5. Repeat for all the buckets in your AWS account that contain sensitive data.\n\n**From Command Line:**\n\n1. List all of the S3 buckets:\n```\naws s3 ls\n```\n2. Enable Block Public Access on a specific bucket:\n```\naws s3api put-public-access-block --bucket <bucket-name> --public-access-block-configuration \"BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true\"\n```\n\n**If utilizing Block Public Access (account settings)**\n\n**From Console:**\n\nIf the output reads `true` for the separate configuration settings, then Block Public Access is enabled on the account.\n\n1. Login to the AWS Management Console and open the Amazon S3 console using https://console.aws.amazon.com/s3/.\n2. Click `Block Public Access (account settings)`.\n3. Click `Edit` to change the block public access settings for all the buckets in your AWS account.\n4. Update the settings and click `Save`. For details about each setting, pause on the `i` icons.\n5. When you're asked for confirmation, enter `confirm`. Then click `Confirm` to save your changes.\n\n**From Command Line:**\n\nTo enable Block Public Access for this account, run the following command:\n```\naws s3control put-public-access-block\n--public-access-block-configuration BlockPublicAcls=true, IgnorePublicAcls=true, BlockPublicPolicy=true, RestrictPublicBuckets=true\n--account-id <account-id>\n```"
  },
  {
    "recommendation_number": "2.2.1",
    "section": 2.2,
    "title": "Ensure that encryption-at-rest is enabled for RDS instances",
    "profile": "Level 1",
    "assessment_status": "Automated",
    "description": "Amazon RDS encrypted DB instances use the industry-standard AES-256 encryption algorithm to encrypt your data on the server that hosts your Amazon RDS DB instances. After your data is encrypted, Amazon RDS handles the authentication of access and the decryption of your data transparently, with minimal impact on performance.",
    "audit_procedure": "**From Console:**\n\n1. Login to the AWS Management Console and open the RDS dashboard at https://console.aws.amazon.com/rds/.\n2. In the navigation pane, under RDS dashboard, click `Databases`.\n3. Select the RDS instance that you want to examine.\n4. Click `Instance Name` to see details, then select the `Configuration` tab.\n5. Under Configuration Details, in the Storage pane, search for the `Encryption Enabled` status.\n6. If the current status is set to `Disabled`, encryption is not enabled for the selected RDS database instance.\n7. Repeat steps 2 to 6 to verify the encryption status of other RDS instances in the same region.\n8. Change the region from the top of the navigation bar, and repeat the audit steps for other regions.\n\n**From Command Line:**\n\n1. Run the `describe-db-instances` command to list all the RDS database instance names available in the selected AWS region. The output will return each database instance identifier (name):\n ```\naws rds describe-db-instances --region <region-name> --query 'DBInstances[*].DBInstanceIdentifier'\n```\n2. Run the `describe-db-instances` command again, using an RDS instance identifier returned from step 1, to determine if the selected database instance is encrypted. The output should return the encryption status `True` or `False`:\n```\naws rds describe-db-instances --region <region-name> --db-instance-identifier <db-name> --query 'DBInstances[*].StorageEncrypted'\n```\n3. If the StorageEncrypted parameter value is `False`, encryption is not enabled for the selected RDS database instance.\n4. Repeat steps 1 to 3 to audit each RDS instance, and change the region to verify RDS instances in other regions.",
    "remediation_procedure": "**From Console:**\n\n1. Login to the AWS Management Console and open the RDS dashboard at https://console.aws.amazon.com/rds/.\n2. In the left navigation panel, click on `Databases`.\n3. Select the Database instance that needs to be encrypted.\n4. Click the `Actions` button placed at the top right and select `Take Snapshot`.\n5. On the Take Snapshot page, enter the name of the database for which you want to take a snapshot in the `Snapshot Name` field and click on `Take Snapshot`.\n6. Select the newly created snapshot, click the `Action` button placed at the top right, and select `Copy snapshot` from the Action menu.\n7. On the Make Copy of DB Snapshot page, perform the following:\n- In the `New DB Snapshot Identifier` field, enter a name for the new snapshot.\n- Check `Copy Tags`. The new snapshot must have the same tags as the source snapshot.\n- Select `Yes` from the `Enable Encryption` dropdown list to enable encryption. You can choose to use the AWS default encryption key or a custom key from the Master Key dropdown list.\n8. Click `Copy Snapshot` to create an encrypted copy of the selected instance's snapshot.\n9. Select the new Snapshot Encrypted Copy and click the `Action` button located at the top right. Then, select the `Restore Snapshot` option from the Action menu. This will restore the encrypted snapshot to a new database instance.\n10. On the Restore DB Instance page, enter a unique name for the new database instance in the DB Instance Identifier field.\n11. Review the instance configuration details and click `Restore DB Instance`.\n12. As the new instance provisioning process is completed, you can update the application configuration to refer to the endpoint of the new encrypted database instance. Once the database endpoint is changed at the application level, you can remove the unencrypted instance.\n\n**From Command Line:**\n\n1. Run the `describe-db-instances` command to list the names of all RDS database instances in the selected AWS region. The command output should return database instance identifiers:\n```\naws rds describe-db-instances --region <region-name> --query 'DBInstances[*].DBInstanceIdentifier'\n```\n2. Run the `create-db-snapshot` command to create a snapshot for a selected database instance. The command output will return the `new snapshot` with name DB Snapshot Name:\n```\naws rds create-db-snapshot --region <region-name> --db-snapshot-identifier <db-snapshot-name> --db-instance-identifier <db-name>\n```\n3. Now run the `list-aliases` command to list the KMS key aliases available in a specified region. The command output should return each `key alias currently available`. For our RDS encryption activation process, locate the ID of the AWS default KMS key:\n```\naws kms list-aliases --region <region-name>\n```\n4. Run the `copy-db-snapshot` command using the default KMS key ID for the RDS instances returned earlier to create an encrypted copy of the database instance snapshot. The command output will return the `encrypted instance snapshot configuration`:\n```\naws rds copy-db-snapshot --region <region-name> --source-db-snapshot-identifier <db-snapshot-name> --target-db-snapshot-identifier <db-snapshot-name-encrypted> --copy-tags --kms-key-id <kms-id-for-rds>\n```\n5. Run the `restore-db-instance-from-db-snapshot` command to restore the encrypted snapshot created in the previous step to a new database instance. If successful, the command output should return the configuration of the new encrypted database instance:\n```\naws rds restore-db-instance-from-db-snapshot --region <region-name> --db-instance-identifier <db-name-encrypted> --db-snapshot-identifier <db-snapshot-name-encrypted>\n```\n6. Run the `describe-db-instances` command to list all RDS database names available in the selected AWS region. The output will return the database instance identifier names. Select the encrypted database name that we just created, `db-name-encrypted`:\n```\naws rds describe-db-instances --region <region-name> --query 'DBInstances[*].DBInstanceIdentifier'\n```\n7. Run the `describe-db-instances` command again using the RDS instance identifier returned earlier to determine if the selected database instance is encrypted. The command output should indicate that the encryption status is `True`:\n```\naws rds describe-db-instances --region <region-name> --db-instance-identifier <db-name-encrypted> --query 'DBInstances[*].StorageEncrypted'\n```"
  },
  {
    "recommendation_number": "2.2.2",
    "section": 2.2,
    "title": "Ensure the Auto Minor Version Upgrade feature is enabled for RDS instances",
    "profile": "Level 1",
    "assessment_status": "Automated",
    "description": "Ensure that RDS database instances have the Auto Minor Version Upgrade flag enabled to automatically receive minor engine upgrades during the specified maintenance window. This way, RDS instances can obtain new features, bug fixes, and security patches for their database engines.",
    "audit_procedure": "**From Console:**\n\n1. Log in to the AWS management console and navigate to the RDS dashboard at https://console.aws.amazon.com/rds/.\n2. In the left navigation panel, click `Databases`.\n3. Select the RDS instance that you want to examine.\n4. Click on the `Maintenance and backups` panel.\n5. Under the `Maintenance` section, search for the Auto Minor Version Upgrade status.\n- If the current status is `Disabled`, it means that the feature is not enabled, and the minor engine upgrades released will not be applied to the selected RDS instance.\n\n**From Command Line:**\n\n1. Run the `describe-db-instances` command to list all RDS database names available in the selected AWS region:\n```\naws rds describe-db-instances --region <region-name> --query 'DBInstances[*].DBInstanceIdentifier'\n```\n2. The command output should return each database instance identifier.\n3. Run the `describe-db-instances` command again using a RDS instance identifier returned earlier to determine the Auto Minor Version Upgrade status for the selected instance:\n```\naws rds describe-db-instances --region <region-name> --db-instance-identifier <db-instance-identifier> --query 'DBInstances[*].AutoMinorVersionUpgrade'\n```\n4. The command output should return the current status of the feature. If the current status is set to `true`, the feature is enabled and the minor engine upgrades will be applied to the selected RDS instance.",
    "remediation_procedure": "**From Console:**\n\n1. Log in to the AWS management console and navigate to the RDS dashboard at https://console.aws.amazon.com/rds/.\n2. In the left navigation panel, click `Databases`.\n3. Select the RDS instance that you want to update.\n4. Click on the `Modify` button located at the top right side.\n5. On the `Modify DB Instance: <instance identifier>` page, In the `Maintenance` section, select `Auto minor version upgrade` and click the `Yes` radio button.\n6. At the bottom of the page, click `Continue`, and check `Apply Immediately` to apply the changes immediately, or select `Apply during the next scheduled maintenance window` to avoid any downtime.\n7. Review the changes and click `Modify DB Instance`. The instance status should change from available to modifying and back to available. Once the feature is enabled, the `Auto Minor Version Upgrade` status should change to `Yes`.\n\n**From Command Line:**\n\n1. Run the `describe-db-instances` command to list all RDS database instance names available in the selected AWS region:\n```\naws rds describe-db-instances --region <region-name> --query 'DBInstances[*].DBInstanceIdentifier'\n```\n2. The command output should return each database instance identifier.\n3. Run the `modify-db-instance` command to modify the configuration of a selected RDS instance. This command will apply the changes immediately. Remove `--apply-immediately` to apply changes during the next scheduled maintenance window and avoid any downtime:\n```\naws rds modify-db-instance --region <region-name> --db-instance-identifier <db-instance-identifier> --auto-minor-version-upgrade --apply-immediately\n```\n4. The command output should reveal the new configuration metadata for the RDS instance, including the `AutoMinorVersionUpgrade` parameter value.\n5. Run the `describe-db-instances` command to check if the Auto Minor Version Upgrade feature has been successfully enabled:\n```\naws rds describe-db-instances --region <region-name> --db-instance-identifier <db-instance-identifier> --query 'DBInstances[*].AutoMinorVersionUpgrade'\n```\n6. The command output should return the feature's current status set to `true`, indicating that the feature is `enabled`, and that the minor engine upgrades will be applied to the selected RDS instance."
  },
  {
    "recommendation_number": "2.2.3",
    "section": 2.2,
    "title": "Ensure that RDS instances are not publicly accessible",
    "profile": "Level 1",
    "assessment_status": "Automated",
    "description": "Ensure and verify that the RDS database instances provisioned in your AWS account restrict unauthorized access in order to minimize security risks. To restrict access to any RDS database instance, you must disable the Publicly Accessible flag for the database and update the VPC security group associated with the instance.",
    "audit_procedure": "**From Console:**\n\n1. Log in to the AWS management console and navigate to the RDS dashboard at https://console.aws.amazon.com/rds/.\n2. Under the navigation panel, on the RDS dashboard, click `Databases`.\n3. Select the RDS instance that you want to examine.\n4. Click `Instance Name` from the dashboard, under `Connectivity and Security`.\n5. In the `Security` section, check if the Publicly Accessible flag status is set to `Yes`.\n6. Follow the steps below to check database subnet access:\n- In the `networking` section, click the subnet link under `Subnets`.\n- The link will redirect you to the VPC Subnets page.\n- Select the subnet listed on the page and click the `Route Table` tab from the dashboard bottom panel.\n- If the route table contains any entries with the destination CIDR block set to `0.0.0.0/0` and an `Internet Gateway` attached, the selected RDS database instance was provisioned inside a public subnet; therefore, it is not running within a logically isolated environment and can be accessed from the Internet.\n7. Repeat steps 3-6 to determine the configuration of other RDS database instances provisioned in the current region.\n8. Change the AWS region from the navigation bar and repeat the audit process for other regions.\n\n**From Command Line:**\n\n1. Run the `describe-db-instances` command to list all available RDS database names in the selected AWS region:\n```\naws rds describe-db-instances --region <region-name> --query 'DBInstances[*].DBInstanceIdentifier'\n```\n2. The command output should return each database instance `identifier`.\n3. Run the `describe-db-instances` command again, using the `PubliclyAccessible` parameter as a query filter to reveal the status of the database instance's Publicly Accessible flag:\n```\naws rds describe-db-instances --region <region-name> --db-instance-identifier <db-instance-name> --query 'DBInstances[*].PubliclyAccessible'\n```\n4. Check the Publicly Accessible parameter status. If the Publicly Accessible flag is set to `Yes`, then the selected RDS database instance is publicly accessible and insecure. Follow the steps mentioned below to check database subnet access.\n5. Run the `describe-db-instances` command again using the RDS database instance identifier that you want to check, along with the appropriate filtering to describe the VPC subnet(s) associated with the selected instance:\n```\naws rds describe-db-instances --region <region-name> --db-instance-identifier <db-instance-name> --query 'DBInstances[*].DBSubnetGroup.Subnets[]'\n```\n- The command output should list the subnets available in the selected database subnet group.\n6. Run the `describe-route-tables` command using the ID of the subnet returned in the previous step to describe the routes of the VPC route table associated with the selected subnet:\n```\naws ec2 describe-route-tables --region <region-name> --filters \"Name=association.subnet-id,Values=<subnet-id>\" --query 'RouteTables[*].Routes[]'\n```\n- If the command returns the route table associated with the database instance subnet ID, check the values of the `GatewayId` and `DestinationCidrBlock` attributes returned in the output. If the route table contains any entries with the `GatewayId` value set to `igw-xxxxxxxx` and the `DestinationCidrBlock` value set to `0.0.0.0/0`, the selected RDS database instance was provisioned within a public subnet.\n- Or, if the command returns empty results, the route table is implicitly associated with the subnet; therefore, the audit process continues with the next step.\n7. Run the `describe-db-instances` command again using the RDS database instance identifier that you want to check, along with the appropriate filtering to describe the VPC ID associated with the selected instance:\n```\naws rds describe-db-instances --region <region-name> --db-instance-identifier <db-instance-name> --query 'DBInstances[*].DBSubnetGroup.VpcId'\n```\n- The command output should show the VPC ID in the selected database subnet group.\n8. Now run the `describe-route-tables` command using the ID of the VPC returned in the previous step to describe the routes of the VPC's main route table that is implicitly associated with the selected subnet:\n```\naws ec2 describe-route-tables --region <region-name> --filters \"Name=vpc-id,Values=<vpc-id>\" \"Name=association.main,Values=true\" --query 'RouteTables[*].Routes[]'\n```\n- The command output returns the VPC main route table implicitly associated with the database instance subnet ID. Check the values of the `GatewayId` and `DestinationCidrBlock` attributes returned in the output. If the route table contains any entries with the `GatewayId` value set to `igw-xxxxxxxx` and the `DestinationCidrBlock` value set to `0.0.0.0/0`, the selected RDS database instance was provisioned inside a public subnet; therefore, it is not running within a logically isolated environment and does not adhere to AWS security best practices.",
    "remediation_procedure": "**From Console:**\n\n1. Log in to the AWS management console and navigate to the RDS dashboard at https://console.aws.amazon.com/rds/.\n2. Under the navigation panel, on the RDS dashboard, click `Databases`.\n3. Select the RDS instance that you want to update.\n4. Click `Modify` from the dashboard top menu.\n5. On the Modify DB Instance panel, under the `Connectivity` section, click on `Additional connectivity configuration` and update the value for `Publicly Accessible` to `Not publicly accessible` to restrict public access.\n6. Follow the below steps to update subnet configurations:\n- Select the `Connectivity and security` tab, and click the VPC attribute value inside the `Networking` section.\n- Select the `Details` tab from the VPC dashboard's bottom panel and click the Route table configuration attribute value.\n- On the Route table details page, select the Routes tab from the dashboard's bottom panel and click `Edit routes`.\n- On the Edit routes page, update the Destination of Target which is set to `igw-xxxxx` and click `Save` routes.\n7. On the Modify DB Instance panel, click `Continue`, and in the Scheduling of modifications section, perform one of the following actions based on your requirements:\n- Select `Apply during the next scheduled maintenance window` to apply the changes automatically during the next scheduled maintenance window.\n- Select `Apply immediately` to apply the changes right away. With this option, any pending modifications will be asynchronously applied as soon as possible, regardless of the maintenance window setting for this RDS database instance. Note that any changes available in the pending modifications queue are also applied. If any of the pending modifications require downtime, choosing this option can cause unexpected downtime for the application.\n8. Repeat steps 3-7 for each RDS instance in the current region.\n9. Change the AWS region from the navigation bar to repeat the process for other regions.\n\n**From Command Line:**\n\n1. Run the `describe-db-instances` command to list all available RDS database identifiers in the selected AWS region:\n```\naws rds describe-db-instances --region <region-name> --query 'DBInstances[*].DBInstanceIdentifier'\n```\n2. The command output should return each database instance identifier.\n3. Run the `modify-db-instance` command to modify the configuration of a selected RDS instance, disabling the `Publicly Accessible` flag for that instance. This command uses the `apply-immediately` flag. If you want to avoid any downtime, the `--no-apply-immediately` flag can be used:\n```\naws rds modify-db-instance --region <region-name> --db-instance-identifier <db-instance-name> --no-publicly-accessible --apply-immediately\n```\n4. The command output should reveal the `PubliclyAccessible` configuration under pending values, to be applied at the specified time.\n5. Updating the Internet Gateway destination via the AWS CLI is not currently supported. To update information about the Internet Gateway, please use the AWS Console procedure.\n6. Repeat steps 1-5 for each RDS instance provisioned in the current region.\n7. Change the AWS region by using the --region filter to repeat the process for other regions."
  },
  {
    "recommendation_number": "2.2.4",
    "section": 2.2,
    "title": "Ensure Multi-AZ deployments are used for enhanced availability in Amazon RDS",
    "profile": "Level 1",
    "assessment_status": "Manual",
    "description": "Amazon RDS offers Multi-AZ deployments that provide enhanced availability and durability for your databases, using synchronous replication to replicate data to a standby instance in a different Availability Zone (AZ). In the event of an infrastructure failure, Amazon RDS automatically fails over to the standby to minimize downtime and ensure business continuity.",
    "audit_procedure": "**From Console:**\n\n1. Login to the AWS Management Console and open the RDS dashboard at [AWS RDS Console](https://console.aws.amazon.com/rds/).\n2. In the navigation pane, under `Databases`, select the RDS instance you want to examine.\n3. Click the `Instance Name` to see details, then navigate to the `Configuration` tab.\n4. Under the `Availability & Durability` section, check the `Multi-AZ` status.\n - If Multi-AZ deployment is enabled, it will display `Yes`.\n - If it is disabled, the status will display `No`.\n5. Repeat steps 2-4 to verify the Multi-AZ status of other RDS instances in the same region.\n6. Change the region from the top of the navigation bar and repeat the audit for other regions.\n\n**From Command Line:**\n\n1. Run the following command to list all RDS instances in the selected AWS region:\n ```\n aws rds describe-db-instances --region <region-name> --query 'DBInstances[*].DBInstanceIdentifier'\n ```\n2. Run the following command using the instance identifier returned earlier to check the Multi-AZ status:\n ```\n aws rds describe-db-instances --region <region-name> --db-instance-identifier <db-name> --query 'DBInstances[*].MultiAZ'\n ```\n - If the output is `True`, Multi-AZ is enabled.\n - If the output is `False`, Multi-AZ is not enabled.\n3. Repeat steps 1 and 2 to audit each RDS instance, and change regions to verify in other regions.",
    "remediation_procedure": "**From Console:**\n\n1. Login to the AWS Management Console and open the RDS dashboard at [AWS RDS Console](https://console.aws.amazon.com/rds/).\n2. In the left navigation pane, click on `Databases`.\n3. Select the database instance that needs Multi-AZ deployment to be enabled.\n4. Click the `Modify` button at the top right.\n5. Scroll down to the `Availability & Durability` section.\n6. Under `Multi-AZ deployment`, select `Yes` to enable.\n7. Review the changes and click `Continue`.\n8. On the `Review` page, choose `Apply immediately` to make the change without waiting for the next maintenance window, or `Apply during the next scheduled maintenance window`.\n9. Click `Modify DB Instance` to apply the changes.\n\n**From Command Line:**\n\n1. Run the following command to modify the RDS instance and enable Multi-AZ:\n ```\n aws rds modify-db-instance --region <region-name> --db-instance-identifier <db-name> --multi-az --apply-immediately\n ```\n2. Confirm that the Multi-AZ deployment is enabled by running the following command:\n ```\n aws rds describe-db-instances --region <region-name> --db-instance-identifier <db-name> --query 'DBInstances[*].MultiAZ'\n ```\n - The output should return `True`, indicating that Multi-AZ is enabled.\n\n3. Repeat the procedure for other instances as necessary."
  },
  {
    "recommendation_number": "2.3.1",
    "section": 2.3,
    "title": "Ensure that encryption is enabled for EFS file systems",
    "profile": "Level 1",
    "assessment_status": "Automated",
    "description": "EFS data should be encrypted at rest using AWS KMS (Key Management Service).",
    "audit_procedure": "**From Console:**\n1. Login to the AWS Management Console and Navigate to the Elastic File System (EFS) dashboard.\n2. Select `File Systems` from the left navigation panel.\n3. Each item on the list has a visible Encrypted field that displays data at rest encryption status.\n4. Validate that this field reads `Encrypted` for all EFS file systems in all AWS regions.\n\n**From CLI:**\n1. Run the `describe-file-systems` command using custom query filters to list the identifiers of all AWS EFS file systems currently available within the selected region:\n```\naws efs describe-file-systems --region <region> --output table --query 'FileSystems[*].FileSystemId'\n```\n2. The command output should return a table with the requested file system IDs.\n3. Run the `describe-file-systems` command using the ID of the file system that you want to examine as `file-system-id` and the necessary query filters:\n```\naws efs describe-file-systems --region <region> --file-system-id <file-system-id> --query 'FileSystems[*].Encrypted'\n```\n4. The command output should return the file system encryption status as `true` or `false`. If the returned value is `false`, the selected AWS EFS file system is not encrypted and if the returned value is `true`, the selected AWS EFS file system is encrypted.",
    "remediation_procedure": "**It is important to note that EFS file system data-at-rest encryption must be turned on when creating the file system. If an EFS file system has been created without data-at-rest encryption enabled, then you must create another EFS file system with the correct configuration and transfer the data.**\n\n**Steps to create an EFS file system with data encrypted at rest:**\n\n**From Console:**\n1. Login to the AWS Management Console and Navigate to the `Elastic File System (EFS)` dashboard.\n2. Select `File Systems` from the left navigation panel.\n3. Click the `Create File System` button from the dashboard top menu to start the file system setup process.\n4. On the `Configure file system access` configuration page, perform the following actions:\n- Choose an appropriate VPC from the VPC dropdown list.\n- Within the `Create mount targets` section, check the boxes for all of the Availability Zones (AZs) within the selected VPC. These will be your mount targets.\n- Click `Next step` to continue.\n5. Perform the following on the `Configure optional settings` page:\n- Create `tags` to describe your new file system.\n- Choose `performance mode` based on your requirements.\n- Check the `Enable encryption` box and choose `aws/elasticfilesystem` from the `Select KMS master key` dropdown list to enable encryption for the new file system, using the default master key provided and managed by AWS KMS.\n- Click `Next step` to continue.\n6. Review the file system configuration details on the `review and create` page and then click `Create File System` to create your new AWS EFS file system.\n7. Copy the data from the old unencrypted EFS file system onto the newly created encrypted file system.\n8. Remove the unencrypted file system as soon as your data migration to the newly created encrypted file system is completed.\n9. Change the AWS region from the navigation bar and repeat the entire process for the other AWS regions.\n\n**From CLI:**\n1. Run the `describe-file-systems` command to view the configuration information for the selected unencrypted file system identified in the Audit steps:\n```\naws efs describe-file-systems --region <region> --file-system-id <file-system-id>\n```\n2. The command output should return the configuration information.\n3. To provision a new AWS EFS file system, you need to generate a universally unique identifier (UUID) to create the token required by the `create-file-system` command. To create the required token, you can use a randomly generated UUID from \"https://www.uuidgenerator.net\".\n4. Run the `create-file-system` command using the unique token created at the previous step:\n```\naws efs create-file-system --region <region> --creation-token <uuid> --performance-mode generalPurpose --encrypted\n```\n5. The command output should return the new file system configuration metadata.\n6. Run the `create-mount-target` command using the EFS file system ID returned from step 4 as the identifier and the ID of the Availability Zone (AZ) that will represent the mount target:\n```\naws efs create-mount-target --region <region> --file-system-id <file-system-id> --subnet-id <subnet-id>\n```\n7. The command output should return the new mount target metadata.\n8. Now you can mount your file system from an EC2 instance.\n9. Copy the data from the old unencrypted EFS file system to the newly created encrypted file system.\n10. Remove the unencrypted file system as soon as your data migration to the newly created encrypted file system is completed:\n```\naws efs delete-file-system --region <region> --file-system-id <unencrypted-file-system-id>\n```\n11. Change the AWS region by updating the --region and repeat the entire process for the other AWS regions."
  },
  {
    "recommendation_number": "3.1",
    "section": 3.0,
    "title": "Ensure CloudTrail is enabled in all regions",
    "profile": "Level 1",
    "assessment_status": "Manual",
    "description": "AWS CloudTrail is a web service that records AWS API calls for your account and delivers log files to you. The recorded information includes the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by the AWS service. CloudTrail provides a history of AWS API calls for an account, including API calls made via the Management Console, SDKs, command line tools, and higher-level AWS services (such as CloudFormation).",
    "audit_procedure": "Perform the following to determine if CloudTrail is enabled for all regions:\n\n**From Console:**\n\n1. Sign in to the AWS Management Console and open the CloudTrail console at [https://console.aws.amazon.com/cloudtrail](https://console.aws.amazon.com/cloudtrail)\n2. Click on `Trails` in the left navigation pane\n - You will be presented with a list of trails across all regions\n3. Ensure that at least one Trail has `Yes` specified in the `Multi-region trail` column\n4. Click on a trail via the link in the `Name` column\n5. Ensure `Logging` is set to `ON` \n6. Ensure `Multi-region trail` is set to `Yes`\n7. In the section `Management Events`, ensure that `API activity` set to `ALL`\n\n**From Command Line:**\n1. List all trails:\n```\n aws cloudtrail describe-trails\n```\n2. Ensure `IsMultiRegionTrail` is set to `true`:\n```\naws cloudtrail get-trail-status --name <trail-name>\n```\n3. Ensure `IsLogging` is set to `true`:\n```\naws cloudtrail get-event-selectors --trail-name <trail-name>\n```\n4. Ensure there is at least one `fieldSelector` for a trail that equals `Management`:\n\n- This should NOT output any results for Field: \"readOnly\". If either `true` or `false` is returned, one of the checkboxes (`read` or `write`) is not selected.\n\nExample of correct output:\n```\n\"TrailARN\": \"<your_trail_ARN>\",\n \"AdvancedEventSelectors\": [\n {\n \"Name\": \"Management events selector\",\n \"FieldSelectors\": [\n {\n \"Field\": \"eventCategory\",\n \"Equals\": [\n \"Management\"\n ]\n ```",
    "remediation_procedure": "Perform the following to enable global (Multi-region) CloudTrail logging:\n\n**From Console:**\n\n1. Sign in to the AWS Management Console and open the IAM console at [https://console.aws.amazon.com/cloudtrail](https://console.aws.amazon.com/cloudtrail).\n2. Click on `Trails` in the left navigation pane.\n3. Click `Get Started Now` if it is presented, then:\n - Click `Add new trail`.\n - Enter a trail name in the `Trail name` box.\n - A trail created in the console is a multi-region trail by default.\n - Specify an S3 bucket name in the `S3 bucket` box.\n - Specify the AWS KMS alias under the `Log file SSE-KMS encryption` section, or create a new key.\n - Click `Next`.\n4. Ensure the `Management events` check box is selected.\n5. Ensure both `Read` and `Write` are checked under API activity.\n6. Click `Next`.\n7. Review your trail settings and click `Create trail`.\n\n**From Command Line:**\n\nCreate a multi-region trail:\n```\naws cloudtrail create-trail --name <trail-name> --bucket-name <s3-bucket-for-cloudtrail> --is-multi-region-trail \n```\nEnable multi-region on an existing trail:\n```\naws cloudtrail update-trail --name <trail-name> --is-multi-region-trail\n```\n\n**Note:** Creating a CloudTrail trail via the CLI without providing any overriding options configures all `read` and `write` `Management Events` to be logged by default."
  },
  {
    "recommendation_number": "3.2",
    "section": 3.0,
    "title": "Ensure CloudTrail log file validation is enabled",
    "profile": "Level 2",
    "assessment_status": "Automated",
    "description": "CloudTrail log file validation creates a digitally signed digest file containing a hash of each log that CloudTrail writes to S3. These digest files can be used to determine whether a log file was changed, deleted, or remained unchanged after CloudTrail delivered the log. It is recommended that file validation be enabled for all CloudTrails.",
    "audit_procedure": "Perform the following on each trail to determine if log file validation is enabled:\n\n**From Console:**\n\n1. Sign in to the AWS Management Console and open the IAM console at [https://console.aws.amazon.com/cloudtrail](https://console.aws.amazon.com/cloudtrail).\n2. Click on `Trails` in the left navigation pane.\n3. For every trail:\n- Click on a trail via the link in the `Name` column.\n- Under the `General details` section, ensure `Log file validation` is set to `Enabled`.\n\n**From Command Line:**\n\nList all trails:\n```\naws cloudtrail describe-trails\n```\nEnsure `LogFileValidationEnabled` is set to `true` for each trail.",
    "remediation_procedure": "Perform the following to enable log file validation on a given trail:\n\n**From Console:**\n\n1. Sign in to the AWS Management Console and open the IAM console at [https://console.aws.amazon.com/cloudtrail](https://console.aws.amazon.com/cloudtrail).\n2. Click on `Trails` in the left navigation pane.\n3. Click on the target trail.\n4. Within the `General details` section, click `edit`.\n5. Under `Advanced settings`, check the `enable` box under `Log file validation`.\n6. Click `Save changes`. \n\n**From Command Line:**\n\nEnable log file validation on a trail:\n\n```\naws cloudtrail update-trail --name <trail_name> --enable-log-file-validation\n```\n\nNote that periodic validation of logs using these digests can be carried out by running the following command:\n\n```\naws cloudtrail validate-logs --trail-arn <trail_arn> --start-time <start_time> --end-time <end_time>\n```"
  },
  {
    "recommendation_number": "3.3",
    "section": 3.0,
    "title": "Ensure AWS Config is enabled in all regions",
    "profile": "Level 2",
    "assessment_status": "Automated",
    "description": "AWS Config is a web service that performs configuration management of supported AWS resources within your account and delivers log files to you. The recorded information includes the configuration items (AWS resources), relationships between configuration items (AWS resources), and any configuration changes between resources. It is recommended that AWS Config be enabled in all regions.",
    "audit_procedure": "Process to evaluate AWS Config configuration per region:\n\n**From Console:**\n\n1. Sign in to the AWS Management Console and open the AWS Config console at [https://console.aws.amazon.com/config/](https://console.aws.amazon.com/config/).\n1. On the top right of the console select the target region.\n1. If a Config Recorder is enabled in this region, you should navigate to the Settings page from the navigation menu on the left-hand side. If a Config Recorder is not yet enabled in this region, proceed to the remediation steps.\n1. Ensure \"Record all resources supported in this region\" is checked.\n1. Ensure \"Include global resources (e.g., AWS IAM resources)\" is checked, unless it is enabled in another region (this is only required in one region).\n1. Ensure the correct S3 bucket has been defined.\n1. Ensure the correct SNS topic has been defined.\n1. Repeat steps 2 to 7 for each region.\n\n**From Command Line:**\n\n1. Run this command to show all AWS Config Recorders and their properties:\n```\naws configservice describe-configuration-recorders\n```\n2. Evaluate the output to ensure that all recorders have a `recordingGroup` object which includes `\"allSupported\": true`. Additionally, ensure that at least one recorder has `\"includeGlobalResourceTypes\": true`.\n\n**Note:** There is one more parameter, \"ResourceTypes,\" in the recordingGroup object. We don't need to check it, as whenever we set \"allSupported\" to true, AWS enforces the resource types to be empty (\"ResourceTypes\": []).\n\nSample output:\n\n```\n{\n \"ConfigurationRecorders\": [\n {\n \"recordingGroup\": {\n \"allSupported\": true,\n \"resourceTypes\": [],\n \"includeGlobalResourceTypes\": true\n },\n \"roleARN\": \"arn:aws:iam::<AWS_Account_ID>:role/service-role/<config-role-name>\",\n \"name\": \"default\"\n }\n ]\n}\n```\n\n3. Run this command to show the status for all AWS Config Recorders:\n```\naws configservice describe-configuration-recorder-status\n```\n4. In the output, find recorders with `name` key matching the recorders that were evaluated in step 2. Ensure that they include `\"recording\": true` and `\"lastStatus\": \"SUCCESS\"`.",
    "remediation_procedure": "To implement AWS Config configuration:\n\n**From Console:**\n\n1. Select the region you want to focus on in the top right of the console.\n2. Click `Services`.\n3. Click `Config`.\n4. If a Config Recorder is enabled in this region, navigate to the Settings page from the navigation menu on the left-hand side. If a Config Recorder is not yet enabled in this region, select \"Get Started\".\n5. Select \"Record all resources supported in this region\".\n6. Choose to include global resources (IAM resources).\n7. Specify an S3 bucket in the same account or in another managed AWS account.\n8. Create an SNS Topic from the same AWS account or another managed AWS account.\n\n**From Command Line:**\n\n1. Ensure there is an appropriate S3 bucket, SNS topic, and IAM role per the [AWS Config Service prerequisites](http://docs.aws.amazon.com/config/latest/developerguide/gs-cli-prereq.html).\n2. Run this command to create a new configuration recorder:\n```\naws configservice put-configuration-recorder --configuration-recorder name=<config-recorder-name>,roleARN=arn:aws:iam::<account-id>:role/<iam-role> --recording-group allSupported=true,includeGlobalResourceTypes=true\n```\n3. Create a delivery channel configuration file locally which specifies the channel attributes, populated from the prerequisites set up previously:\n```\n{\n \"name\": \"<delivery-channel-name>\",\n \"s3BucketName\": \"<bucket-name>\",\n \"snsTopicARN\": \"arn:aws:sns:<region>:<account-id>:<sns-topic>\",\n \"configSnapshotDeliveryProperties\": {\n \"deliveryFrequency\": \"Twelve_Hours\"\n }\n}\n```\n4. Run this command to create a new delivery channel, referencing the json configuration file made in the previous step:\n```\naws configservice put-delivery-channel --delivery-channel file://<delivery-channel-file>.json\n```\n5. Start the configuration recorder by running the following command:\n```\naws configservice start-configuration-recorder --configuration-recorder-name <config-recorder-name>\n```"
  },
  {
    "recommendation_number": "3.4",
    "section": 3.0,
    "title": "Ensure that server access logging is enabled on the CloudTrail S3 bucket",
    "profile": "Level 1",
    "assessment_status": "Manual",
    "description": "Server access logging generates a log that contains access records for each request made to your S3 bucket. An access log record contains details about the request, such as the request type, the resources specified in the request worked, and the time and date the request was processed. It is recommended that server access logging be enabled on the CloudTrail S3 bucket.",
    "audit_procedure": "Perform the following ensure that the CloudTrail S3 bucket has access logging is enabled:\n\n**From Console:**\n\n1. Go to the Amazon CloudTrail console at [https://console.aws.amazon.com/cloudtrail/home](https://console.aws.amazon.com/cloudtrail/home).\n2. In the API activity history pane on the left, click `Trails`.\n3. In the Trails pane, note the bucket names in the S3 bucket column.\n4. Sign in to the AWS Management Console and open the S3 console at [https://console.aws.amazon.com/s3](https://console.aws.amazon.com/s3).\n5. Under `All Buckets` click on a target S3 bucket.\n6. Click on `Properties` in the top right of the console.\n7. Under `Bucket: <bucket-name>`, click `Logging`.\n8. Ensure `Enabled` is checked.\n\n**From Command Line:**\n\n1. Get the name of the S3 bucket that CloudTrail is logging to:\n``` \naws cloudtrail describe-trails --query 'trailList[*].S3BucketName' \n```\n2. Ensure logging is enabled on the bucket:\n```\naws s3api get-bucket-logging --bucket <s3-bucket-for-cloudtrail>\n```\nEnsure the command does not return an empty output.\n\nSample output for a bucket with logging enabled:\n\n```\n{\n \"LoggingEnabled\": {\n \"TargetPrefix\": \"<log-file-prefix>\",\n \"TargetBucket\": \"<logging-bucket>\"\n }\n}\n```",
    "remediation_procedure": "Perform the following to enable server access logging:\n\n**From Console:**\n\n1. Sign in to the AWS Management Console and open the S3 console at [https://console.aws.amazon.com/s3](https://console.aws.amazon.com/s3).\n2. Under `All Buckets` click on the target S3 bucket.\n3. Click on `Properties` in the top right of the console.\n4. Under `Bucket: <bucket-name>`, click `Logging`. \n5. Configure bucket logging:\n - Check the `Enabled` box.\n - Select a Target Bucket from the list.\n - Enter a Target Prefix.\n6. Click `Save`.\n\n**From Command Line:**\n\n1. Get the name of the S3 bucket that CloudTrail is logging to:\n```\naws cloudtrail describe-trails --region <region-name> --query trailList[*].S3BucketName\n```\n2. Copy and add the target bucket name at `<bucket-name>`, the prefix for the log file at `<log-file-prefix>`, and optionally add an email address in the following template, then save it as `<file-name>.json`:\n```\n{\n \"LoggingEnabled\": {\n \"TargetBucket\": \"<bucket-name>\",\n \"TargetPrefix\": \"<log-file-prefix>\",\n \"TargetGrants\": [\n {\n \"Grantee\": {\n \"Type\": \"AmazonCustomerByEmail\",\n \"EmailAddress\": \"<email-address>\"\n },\n \"Permission\": \"FULL_CONTROL\"\n }\n ]\n } \n}\n```\n3. Run the `put-bucket-logging` command with bucket name and `<file-name>.json` as input; for more information, refer to [put-bucket-logging](https://docs.aws.amazon.com/cli/latest/reference/s3api/put-bucket-logging.html):\n```\naws s3api put-bucket-logging --bucket <bucket-name> --bucket-logging-status file://<file-name>.json\n```"
  },
  {
    "recommendation_number": "3.5",
    "section": 3.0,
    "title": "Ensure CloudTrail logs are encrypted at rest using KMS CMKs",
    "profile": "Level 2",
    "assessment_status": "Automated",
    "description": "AWS CloudTrail is a web service that records AWS API calls for an account and makes those logs available to users and resources in accordance with IAM policies. AWS Key Management Service (KMS) is a managed service that helps create and control the encryption keys used to encrypt account data, and uses Hardware Security Modules (HSMs) to protect the security of encryption keys. CloudTrail logs can be configured to leverage server side encryption (SSE) and KMS customer-created master keys (CMK) to further protect CloudTrail logs. It is recommended that CloudTrail be configured to use SSE-KMS.",
    "audit_procedure": "Perform the following to determine if CloudTrail is configured to use SSE-KMS:\n\n**From Console:**\n\n1. Sign in to the AWS Management Console and open the CloudTrail console at [https://console.aws.amazon.com/cloudtrail](https://console.aws.amazon.com/cloudtrail).\n2. In the left navigation pane, choose `Trails`.\n3. Select a trail.\n4. In the `General details` section, select `Edit` to edit the trail configuration.\n5. Ensure the box at `Log file SSE-KMS encryption` is checked and that a valid `AWS KMS alias` of a KMS key is entered in the respective text box.\n\n**From Command Line:**\n\n1. Run the following command:\n```\n aws cloudtrail describe-trails \n```\n2. For each trail listed, SSE-KMS is enabled if the trail has a `KmsKeyId` property defined.",
    "remediation_procedure": "Perform the following to configure CloudTrail to use SSE-KMS:\n\n**From Console:**\n\n1. Sign in to the AWS Management Console and open the CloudTrail console at [https://console.aws.amazon.com/cloudtrail](https://console.aws.amazon.com/cloudtrail).\n2. In the left navigation pane, choose `Trails`.\n3. Click on a trail.\n4. Under the `S3` section, click the edit button (pencil icon).\n5. Click `Advanced`.\n6. Select an existing CMK from the `KMS key Id` drop-down menu.\n - **Note:** Ensure the CMK is located in the same region as the S3 bucket.\n - **Note:** You will need to apply a KMS key policy on the selected CMK in order for CloudTrail, as a service, to encrypt and decrypt log files using the CMK provided. View the AWS documentation for [editing the selected CMK Key policy](https://docs.aws.amazon.com/awscloudtrail/latest/userguide/create-kms-key-policy-for-cloudtrail.html).\n7. Click `Save`.\n8. You will see a notification message stating that you need to have decryption permissions on the specified KMS key to decrypt log files.\n9. Click `Yes`.\n\n**From Command Line:**\n\nRun the following command to specify a KMS key ID to use with a trail:\n```\naws cloudtrail update-trail --name <trail-name> --kms-id <cloudtrail-kms-key>\n```\nRun the following command to attach a key policy to a specified KMS key:\n```\naws kms put-key-policy --key-id <cloudtrail-kms-key> --policy <cloudtrail-kms-key-policy>\n```"
  },
  {
    "recommendation_number": "3.6",
    "section": 3.0,
    "title": "Ensure rotation for customer-created symmetric CMKs is enabled",
    "profile": "Level 2",
    "assessment_status": "Automated",
    "description": "AWS Key Management Service (KMS) allows customers to rotate the backing key, which is key material stored within the KMS that is tied to the key ID of the customer-created customer master key (CMK). The backing key is used to perform cryptographic operations such as encryption and decryption. Automated key rotation currently retains all prior backing keys so that decryption of encrypted data can occur transparently. It is recommended that CMK key rotation be enabled for symmetric keys. Key rotation cannot be enabled for any asymmetric CMK.",
    "audit_procedure": "**From Console:**\n\n1. Sign in to the AWS Management Console and open the KMS console at: [https://console.aws.amazon.com/kms](https://console.aws.amazon.com/kms).\n2. In the left navigation pane, click `Customer-managed keys`.\n3. Select a customer-managed CMK where `Key spec = SYMMETRIC_DEFAULT`.\n4. Select the `Key rotation` tab.\n5. Ensure the `Automatically rotate this KMS key every year` box is checked.\n6. Repeat steps 3â€“5 for all customer-managed CMKs where `Key spec = SYMMETRIC_DEFAULT`.\n\n**From Command Line:**\n\n1. Run the following command to get a list of all keys and their associated `KeyIds`:\n\n```\n aws kms list-keys\n```\n\n2. For each key, note the KeyId and run the following command:\n\n```\ndescribe-key --key-id <kms-key-id>\n```\n\n3. If the response contains `\"KeySpec = SYMMETRIC_DEFAULT\"`, run the following command:\n\n```\n aws kms get-key-rotation-status --key-id <kms-key-id>\n```\n\n4. Ensure `KeyRotationEnabled` is set to `true`.\n5. Repeat steps 2â€“4 for all remaining CMKs.",
    "remediation_procedure": "**From Console:**\n\n1. Sign in to the AWS Management Console and open the KMS console at: [https://console.aws.amazon.com/kms](https://console.aws.amazon.com/kms).\n2. In the left navigation pane, click `Customer-managed keys`.\n3. Select a key with `Key spec = SYMMETRIC_DEFAULT` that does not have automatic rotation enabled.\n4. Select the `Key rotation` tab.\n5. Check the `Automatically rotate this KMS key every year` box.\n6. Click `Save`.\n7. Repeat steps 3â€“6 for all customer-managed CMKs that do not have automatic rotation enabled.\n\n**From Command Line:**\n\n1. Run the following command to enable key rotation:\n\n```\n aws kms enable-key-rotation --key-id <kms-key-id>\n```"
  },
  {
    "recommendation_number": "3.7",
    "section": 3.0,
    "title": "Ensure VPC flow logging is enabled in all VPCs",
    "profile": "Level 2",
    "assessment_status": "Automated",
    "description": "VPC Flow Logs is a feature that enables you to capture information about the IP traffic going to and from network interfaces in your VPC. After you've created a flow log, you can view and retrieve its data in Amazon CloudWatch Logs. It is recommended that VPC Flow Logs be enabled for packet \"Rejects\" for VPCs.",
    "audit_procedure": "Perform the following to determine if VPC Flow logs are enabled:\n\n**From Console:**\n\n1. Sign into the management console.\n2. Select `Services`, then select `VPC`.\n3. In the left navigation pane, select `Your VPCs`.\n4. Select a VPC.\n5. In the right pane, select the `Flow Logs` tab.\n6. Ensure a Log Flow exists that has `Active` in the `Status` column.\n\n**From Command Line:**\n\n1. Run the `describe-vpcs` command (OSX/Linux/UNIX) to list the VPC networks available in the current AWS region:\n```\naws ec2 describe-vpcs --region <region> --query Vpcs[].VpcId\n```\n2. The command output returns the `VpcId` of VPCs available in the selected region.\n3. Run the `describe-flow-logs` command (OSX/Linux/UNIX) using the VPC ID to determine if the selected virtual network has the Flow Logs feature enabled:\n```\naws ec2 describe-flow-logs --filter \"Name=resource-id,Values=<vpc-id>\"\n```\n- If there are no Flow Logs created for the selected VPC, the command output will return an empty list `[]`.\n4. Repeat step 3 for other VPCs in the same region.\n5. Change the region by updating `--region`, and repeat steps 1-4 for each region.",
    "remediation_procedure": "Perform the following to enable VPC Flow Logs:\n\n**From Console:**\n\n1. Sign into the management console.\n2. Select `Services`, then select `VPC`.\n3. In the left navigation pane, select `Your VPCs`.\n4. Select a VPC.\n5. In the right pane, select the `Flow Logs` tab.\n6. If no Flow Log exists, click `Create Flow Log`.\n7. For Filter, select `Reject`.\n8. Enter a `Role` and `Destination Log Group`.\n9. Click `Create Log Flow`.\n10. Click on `CloudWatch Logs Group`.\n\n**Note:** Setting the filter to \"Reject\" will dramatically reduce the accumulation of logging data for this recommendation and provide sufficient information for the purposes of breach detection, research, and remediation. However, during periods of least privilege security group engineering, setting the filter to \"All\" can be very helpful in discovering existing traffic flows required for the proper operation of an already running environment.\n\n**From Command Line:**\n\n1. Create a policy document, name it `role_policy_document.json`, and paste the following content:\n```\n{\n \"Version\": \"2012-10-17\",\n \"Statement\": [\n {\n \"Sid\": \"test\",\n \"Effect\": \"Allow\",\n \"Principal\": {\n \"Service\": \"ec2.amazonaws.com\"\n },\n \"Action\": \"sts:AssumeRole\"\n }\n ]\n}\n```\n2. Create another policy document, name it `iam_policy.json`, and paste the following content:\n```\n{\n \"Version\": \"2012-10-17\",\n \"Statement\": [\n {\n \"Effect\": \"Allow\",\n \"Action\":[\n \"logs:CreateLogGroup\",\n \"logs:CreateLogStream\",\n \"logs:DescribeLogGroups\",\n \"logs:DescribeLogStreams\",\n \"logs:PutLogEvents\",\n \"logs:GetLogEvents\",\n \"logs:FilterLogEvents\"\n ],\n \"Resource\": \"*\"\n }\n ]\n}\n```\n3. Run the following command to create an IAM role:\n```\naws iam create-role --role-name <aws-support-iam-role> --assume-role-policy-document file://<file-path>role_policy_document.json \n```\n4. Run the following command to create an IAM policy:\n```\naws iam create-policy --policy-name <iam-policy-name> --policy-document file://<file-path>iam-policy.json\n```\n5. Run the `attach-group-policy` command, using the IAM policy ARN returned from the previous step to attach the policy to the IAM role:\n```\naws iam attach-group-policy --policy-arn arn:aws:iam::<aws-account-id>:policy/<iam-policy-name> --group-name <group-name>\n```\n- If the command succeeds, no output is returned.\n6. Run the `describe-vpcs` command to get a list of VPCs in the selected region:\n```\naws ec2 describe-vpcs --region <region>\n```\n- The command output should return a list of VPCs in the selected region.\n7. Run the `create-flow-logs` command to create a flow log for a VPC:\n```\naws ec2 create-flow-logs --resource-type VPC --resource-ids <vpc-id> --traffic-type REJECT --log-group-name <log-group-name> --deliver-logs-permission-arn <iam-role-arn>\n```\n8. Repeat step 7 for other VPCs in the selected region.\n9. Change the region by updating --region, and repeat the remediation procedure for each region."
  },
  {
    "recommendation_number": "3.8",
    "section": 3.0,
    "title": "Ensure that object-level logging for write events is enabled for S3 buckets",
    "profile": "Level 2",
    "assessment_status": "Automated",
    "description": "S3 object-level API operations, such as GetObject, DeleteObject, and PutObject, are referred to as data events. By default, CloudTrail trails do not log data events, so it is recommended to enable object-level logging for S3 buckets.",
    "audit_procedure": "**From Console:**\n\n1. Login to the AWS Management Console and navigate to the CloudTrail dashboard at `https://console.aws.amazon.com/cloudtrail/`.\n2. In the left panel, click `Trails`, and then click the name of the trail that you want to examine.\n3. Review `General details`.\n4. Confirm that `Multi-region trail` is set to `Yes`.\n5. Scroll down to `Data events` and confirm the configuration:\n- If `advanced event selectors` is being used, it should read:\n```\nData Events: S3\nLog selector template\nLog all events\n```\n- If `basic event selectors` is being used, it should read:\n```\nData events: S3\nBucket Name: All current and future S3 buckets\nWrite: Enabled\n```\n6. Repeat steps 2-5 to verify that each trail has multi-region enabled and is configured to log data events. If a trail does not have multi-region enabled and data event logging configured, refer to the remediation steps.\n\n**From Command Line:**\n\n1. Run the `list-trails` command to list all trails:\n```\naws cloudtrail list-trails\n```\n2. The command output will be a list of trails:\n```\n\"TrailARN\": \"arn:aws:cloudtrail:<region>:<account#>:trail/<trail-name>\",\n\"Name\": \"<trail-name>\",\n\"HomeRegion\": \"<region>\"\n```\n3. Run the `get-trail` command to determine whether a trail is a multi-region trail:\n```\naws cloudtrail get-trail --name <trail-name> --region <region-name>\n```\n4. The command output should include: `\"IsMultiRegionTrail\": true`.\n5. Run the `get-event-selectors` command, using the `Name` of the trail and the `region` returned in step 2, to determine if data event logging is configured:\n```\naws cloudtrail get-event-selectors --region <home-region> --trail-name <trail-name> --query EventSelectors[*].DataResources[]\n```\n6. The command output should be an array that includes the S3 bucket defined for data event logging:\n```\n\"Type\": \"AWS::S3::Object\",\n \"Values\": [\n \"arn:aws:s3\"\n```\n7. If the `get-event-selectors` command returns an empty array, data events are not included in the trail's logging configuration; therefore, object-level API operations performed on S3 buckets within your AWS account are not being recorded.\n8. Repeat steps 1-7 to verify that each trail has multi-region enabled and is configured to log data events. If a trail does not have multi-region enabled and data event logging configured, refer to the remediation steps.",
    "remediation_procedure": "**From Console:**\n\n1. Login to the AWS Management Console and navigate to the S3 dashboard at `https://console.aws.amazon.com/s3/`.\n2. In the left navigation panel, click `buckets`, and then click the name of the S3 bucket you want to examine.\n3. Click the `Properties` tab to see the bucket configuration in detail.\n4. In the `AWS CloudTrail data events` section, select the trail name for recording activity. You can choose an existing trail or create a new one by clicking the `Configure in CloudTrail` button or navigating to the [CloudTrail console](https://console.aws.amazon.com/cloudtrail/).\n5. Once the trail is selected, select the `Data Events` check box.\n6. Select `S3` from the `Data event type` drop-down.\n7. Select `Log all events` from the `Log selector template` drop-down.\n8. Repeat steps 2-7 to enable object-level logging of write events for other S3 buckets.\n\n**From Command Line:**\n\n1. To enable `object-level` data events logging for S3 buckets within your AWS account, run the `put-event-selectors` command using the name of the trail that you want to reconfigure as identifier:\n```\naws cloudtrail put-event-selectors --region <region-name> --trail-name <trail-name> --event-selectors '[{ \"ReadWriteType\": \"WriteOnly\", \"IncludeManagementEvents\":true, \"DataResources\": [{ \"Type\": \"AWS::S3::Object\", \"Values\": [\"arn:aws:s3:::<s3-bucket-name>/\"] }] }]'\n```\n2. The command output will be `object-level` event trail configuration.\n3. If you want to enable it for all buckets at once, change the Values parameter to `[\"arn:aws:s3\"]` in the previous command.\n4. Repeat step 1 for each s3 bucket to update `object-level` logging of write events.\n5. Change the AWS region by updating the `--region` command parameter, and perform the process for the other regions."
  },
  {
    "recommendation_number": "3.9",
    "section": 3.0,
    "title": "Ensure that object-level logging for read events is enabled for S3 buckets",
    "profile": "Level 2",
    "assessment_status": "Automated",
    "description": "S3 object-level API operations, such as GetObject, DeleteObject, and PutObject, are referred to as data events. By default, CloudTrail trails do not log data events, so it is recommended to enable object-level logging for S3 buckets.",
    "audit_procedure": "**From Console:**\n\n1. Login to the AWS Management Console and navigate to the CloudTrail dashboard at `https://console.aws.amazon.com/cloudtrail/`.\n2. In the left panel, click `Trails`, and then click the name of the trail that you want to examine.\n3. Review `General details`.\n4. Confirm that `Multi-region trail` is set to `Yes`\n5. Scroll down to `Data events`\n5. Scroll down to `Data events` and confirm the configuration:\n- If `advanced event selectors` is being used, it should read:\n```\nData Events: S3\nLog selector template\nLog all events\n```\n- If `basic event selectors` is being used, it should read:\n```\nData events: S3\nBucket Name: All current and future S3 buckets\nRead: Enabled\n```\n6. Repeat steps 2-5 to verify that each trail has multi-region enabled and is configured to log data events. If a trail does not have multi-region enabled and data event logging configured, refer to the remediation steps.\n\n**From Command Line:**\n\n1. Run the `describe-trails` command to list all trail names:\n```\naws cloudtrail describe-trails --region <region-name> --output table --query trailList[*].Name\n```\n2. The command output will be table of the trail names.\n3. Run the `get-event-selectors` command using the name of a trail returned at the previous step and custom query filters to determine if data event logging is configured:\n```\naws cloudtrail get-event-selectors --region <region-name> --trail-name <trail-name> --query EventSelectors[*].DataResources[]\n```\n4. The command output should be an array that includes the S3 bucket defined for data event logging.\n5. If the `get-event-selectors` command returns an empty array, data events are not included in the trail's logging configuration; therefore, object-level API operations performed on S3 buckets within your AWS account are not being recorded.\n6. Repeat steps 1-5 to verify the configuration of each trail.\n7. Change the AWS region by updating the `--region` command parameter, and perform the audit process for other regions.",
    "remediation_procedure": "**From Console:**\n\n1. Login to the AWS Management Console and navigate to S3 dashboard at `https://console.aws.amazon.com/s3/`.\n2. In the left navigation panel, click `buckets` and then click the name of the S3 bucket that you want to examine.\n3. Click the `Properties` tab to see the bucket configuration in detail.\n4. In the `AWS Cloud Trail data events` section, select the trail name for recording activity. You can choose an existing trail or create a new one by clicking the `Configure in CloudTrail` button or navigating to the [CloudTrail console](https://console.aws.amazon.com/cloudtrail/).\n5. Once the trail is selected, select the `Data Events` check box.\n6. Select `S3` from the `Data event type` drop-down.\n7. Select `Log all events` from the `Log selector template` drop-down.\n8. Repeat steps 2-7 to enable object-level logging of read events for other S3 buckets.\n\n**From Command Line:**\n\n1. To enable `object-level` data events logging for S3 buckets within your AWS account, run the `put-event-selectors` command using the name of the trail that you want to reconfigure as identifier:\n```\naws cloudtrail put-event-selectors --region <region-name> --trail-name <trail-name> --event-selectors '[{ \"ReadWriteType\": \"ReadOnly\", \"IncludeManagementEvents\":true, \"DataResources\": [{ \"Type\": \"AWS::S3::Object\", \"Values\": [\"arn:aws:s3:::<s3-bucket-name>/\"] }] }]'\n```\n2. The command output will be `object-level` event trail configuration.\n3. If you want to enable it for all buckets at once, change the Values parameter to `[\"arn:aws:s3\"]` in the previous command.\n4. Repeat step 1 for each s3 bucket to update `object-level` logging of read events.\n5. Change the AWS region by updating the `--region` command parameter, and perform the process for the other regions."
  },
  {
    "recommendation_number": "4.1",
    "section": 4.0,
    "title": "Ensure unauthorized API calls are monitored",
    "profile": "Level 2",
    "assessment_status": "Manual",
    "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs or an external Security Information and Event Management (SIEM) environment, and establishing corresponding metric filters and alarms. \n\nIt is recommended that a metric filter and alarm be established for unauthorized API calls.",
    "audit_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following to ensure that there is at least one active multi-region CloudTrail trail with the prescribed metric filters and alarms configured:\n\n1. Identify the log group name that is configured for use with the active multi-region CloudTrail trail:\n\n- List all CloudTrail trails: `aws cloudtrail describe-trails`\n\n- Identify multi-region CloudTrail trails: `Trails with \"IsMultiRegionTrail\" set to true`\n\n- Note the value associated with \"Name\":`<trail-name>`\n\n- Note the `<trail-log-group-name>` within the value associated with \"CloudWatchLogsLogGroupArn\"\n\n - Example: `arn:aws:logs:<region>:<account-id>:log-group:<trail-log-group-name>:*`\n\n- Ensure the identified multi-region CloudTrail trail is active:\n\n - `aws cloudtrail get-trail-status --name <trail-name>`\n\n - Ensure `IsLogging` is set to `TRUE`\n\n- Ensure the identified multi-region CloudTrail trail captures all management events:\n\n - `aws cloudtrail get-event-selectors --trail-name <trail-name>`\n\n - Ensure there is at least one `event selector` for a trail with `IncludeManagementEvents` set to `true` and `ReadWriteType` set to `All`\n\n2. Get a list of all associated metric filters for the `<trail-log-group-name>` captured in step 1:\n\n ```\n aws logs describe-metric-filters --log-group-name <trail-log-group-name>\n ```\n\n3. Ensure the output from the above command contains the following:\n\n ```\n \"filterPattern\": \"{ ($.errorCode =\"*UnauthorizedOperation\") || ($.errorCode =\"AccessDenied*\") && ($.sourceIPAddress!=\"delivery.logs.amazonaws.com\") && ($.eventName!=\"HeadBucket\") }\",\n ```\n\n4. Note the `<unauthorized-api-calls-metric>` value associated with the `filterPattern` from step 3.\n\n5. Get a list of CloudWatch alarms, and filter on the `<unauthorized-api-calls-metric>` captured in step 4:\n\n ```\n aws cloudwatch describe-alarms --query \"MetricAlarms[?MetricName == <unauthorized-api-calls-metric>]\"\n ```\n\n6. Note the `AlarmActions` value; this will provide the SNS topic ARN value.\n\n7. Ensure there is at least one active subscriber to the SNS topic:\n\n ```\n aws sns list-subscriptions-by-topic --topic-arn <sns-topic-arn> \n ```\n\n- At least one subscription should have \"SubscriptionArn\" with a valid AWS ARN.\n\n - Example of valid \"SubscriptionArn\": `arn:aws:sns:<region>:<account-id>:<sns-topic-name>:<subscription-id>`",
    "remediation_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following steps to set up the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on the provided filter pattern that checks for unauthorized API calls and uses the `<trail-log-group-name>` taken from audit step 1:\n\n ```\n aws logs put-metric-filter --log-group-name <trail-log-group-name> --filter-name <unauthorized-api-calls-metric> --metric-transformations metricName=unauthorized_api_calls_metric,metricNamespace=CISBenchmark,metricValue=1 --filter-pattern \"{ ($.errorCode =\"*UnauthorizedOperation\") || ($.errorCode =\"AccessDenied*\") && ($.sourceIPAddress!=\"delivery.logs.amazonaws.com\") && ($.eventName!=\"HeadBucket\") }\"\n ```\n\n **Note**: You can choose your own `metricName` and `metricNamespace` strings. Using the same `metricNamespace` for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify:\n\n ```\n aws sns create-topic --name <sns-topic-name>\n ```\n\n **Note**: You can execute this command once and then reuse the same topic for all monitoring alarms.\n\n **Note**: Capture the `TopicArn` that is displayed when creating the SNS topic in step 2.\n\n3. Create an SNS subscription for the topic created in step 2:\n\n ```\n aws sns subscribe --topic-arn <sns-topic-arn> --protocol <sns-protocol> --notification-endpoint <sns-subscription-endpoints>\n ```\n\n **Note**: You can execute this command once and then reuse the same subscription for all monitoring alarms.\n\n4. Create an alarm that is associated with the CloudWatch Logs metric filter created in step 1 and the SNS topic created in step 2:\n\n ```\n aws cloudwatch put-metric-alarm --alarm-name \"unauthorized_api_calls_alarm\" --metric-name \"unauthorized_api_calls_metric\" --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace \"CISBenchmark\" --alarm-actions <sns-topic-arn>\n ```"
  },
  {
    "recommendation_number": "4.10",
    "section": 4.0,
    "title": "Ensure security group changes are monitored",
    "profile": "Level 2",
    "assessment_status": "Manual",
    "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs or an external Security Information and Event Management (SIEM) environment, and establishing corresponding metric filters and alarms. \n\nSecurity groups are stateful packet filters that control ingress and egress traffic within a VPC.\n\nIt is recommended that a metric filter and alarm be established to detect changes to security groups.",
    "audit_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following to ensure that there is at least one active multi-region CloudTrail trail with the prescribed metric filters and alarms configured:\n\n1. Identify the log group name that is configured for use with the active multi-region CloudTrail trail:\n\n- List all CloudTrail trails: `aws cloudtrail describe-trails`\n\n- Identify multi-region CloudTrail trails: `Trails with \"IsMultiRegionTrail\" set to true`\n\n- Note the value associated with \"Name\":`<trail-name>`\n\n- Note the `<trail-log-group-name>` within the value associated with \"CloudWatchLogsLogGroupArn\"\n\n - Example: `arn:aws:logs:<region>:<account-id>:log-group:<trail-log-group-name>:*`\n\n- Ensure the identified multi-region CloudTrail trail is active:\n\n - `aws cloudtrail get-trail-status --name <trail-name>`\n\n - Ensure `IsLogging` is set to `TRUE`\n\n- Ensure the identified multi-region CloudTrail trail captures all management events:\n\n - `aws cloudtrail get-event-selectors --trail-name <trail-name>`\n\n - Ensure there is at least one `event selector` for a trail with `IncludeManagementEvents` set to `true` and `ReadWriteType` set to `All`\n\n2. Get a list of all associated metric filters for the `<trail-log-group-name>` captured in step 1:\n\n ```\n aws logs describe-metric-filters --log-group-name <trail-log-group-name>\n ```\n\n3. Ensure the output from the above command contains the following:\n\n ```\n \"filterPattern\": \"{ ($.eventName = AuthorizeSecurityGroupIngress) || ($.eventName = AuthorizeSecurityGroupEgress) || ($.eventName = RevokeSecurityGroupIngress) || ($.eventName = RevokeSecurityGroupEgress) || ($.eventName = CreateSecurityGroup) || ($.eventName = DeleteSecurityGroup) || ($.eventName = ModifySecurityGroupRules) }\"\n ```\n\n4. Note the `<security-group-changes-metric>` value associated with the `filterPattern` from step 3.\n\n5. Get a list of CloudWatch alarms, and filter on the `<security-group-changes-metric>` captured in step 4:\n\n ```\n aws cloudwatch describe-alarms --query \"MetricAlarms[?MetricName==<security-group-changes-metric>]\"\n ```\n\n6. Note the `AlarmActions` value; this will provide the SNS topic ARN value.\n\n7. Ensure there is at least one active subscriber to the SNS topic:\n\n ```\n aws sns list-subscriptions-by-topic --topic-arn <sns-topic-arn> \n ```\n\n- At least one subscription should have \"SubscriptionArn\" with a valid AWS ARN.\n\n - Example of valid \"SubscriptionArn\": `arn:aws:sns:<region>:<account-id>:<sns-topic-name>:<subscription-id>`",
    "remediation_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following steps to set up the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on the provided filter pattern that checks for security groups changes and uses the `<trail-log-group-name>` taken from audit step 1:\n\n ```\n aws logs put-metric-filter --log-group-name <trail-log-group-name> --filter-name <security-group-changes-metric> --metric-transformations metricName=<security-group-changes-metric>,metricNamespace=\"CISBenchmark\",metricValue=1 --filter-pattern \"{ ($.eventName = AuthorizeSecurityGroupIngress) || ($.eventName = AuthorizeSecurityGroupEgress) || ($.eventName = RevokeSecurityGroupIngress) || ($.eventName = RevokeSecurityGroupEgress) || ($.eventName = CreateSecurityGroup) || ($.eventName = DeleteSecurityGroup) || ($.eventName = ModifySecurityGroupRules) }\"\n ```\n\n **Note**: You can choose your own `metricName` and `metricNamespace` strings. Using the same `metricNamespace` for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify:\n\n ```\n aws sns create-topic --name <sns-topic-name>\n ```\n\n **Note**: You can execute this command once and then reuse the same topic for all monitoring alarms.\n\n **Note**: Capture the `TopicArn` that is displayed when creating the SNS topic in step 2.\n\n3. Create an SNS subscription for the topic created in step 2:\n\n ```\n aws sns subscribe --topic-arn <sns-topic-arn> --protocol <sns-protocol> --notification-endpoint <sns-subscription-endpoints>\n ```\n\n **Note**: You can execute this command once and then reuse the same subscription for all monitoring alarms.\n\n4. Create an alarm that is associated with the CloudWatch Logs metric filter created in step 1 and the SNS topic created in step 2:\n\n ```\n aws cloudwatch put-metric-alarm --alarm-name <security-group-changes-alarm> --metric-name <security-group-changes-metric> --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace \"CISBenchmark\" --alarm-actions <sns-topic-arn>\n ```"
  },
  {
    "recommendation_number": "4.11",
    "section": 4.0,
    "title": "Ensure Network Access Control List (NACL) changes are monitored",
    "profile": "Level 2",
    "assessment_status": "Manual",
    "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs or an external Security Information and Event Management (SIEM) environment, and establishing corresponding metric filters and alarms. \n\nNACLs are used as a stateless packet filter to control ingress and egress traffic for subnets within a VPC. It is recommended that a metric filter and alarm be established for any changes made to NACLs.",
    "audit_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following to ensure that there is at least one active multi-region CloudTrail trail with the prescribed metric filters and alarms configured:\n\n1. Identify the log group name that is configured for use with the active multi-region CloudTrail trail:\n\n- List all CloudTrail trails: `aws cloudtrail describe-trails`\n\n- Identify multi-region CloudTrail trails: `Trails with \"IsMultiRegionTrail\" set to true`\n\n- Note the value associated with \"Name\":`<trail-name>`\n\n- Note the `<trail-log-group-name>` within the value associated with \"CloudWatchLogsLogGroupArn\"\n\n - Example: `arn:aws:logs:<region>:<account-id>:log-group:<trail-log-group-name>:*`\n\n- Ensure the identified multi-region CloudTrail trail is active:\n\n - `aws cloudtrail get-trail-status --name <trail-name>`\n\n - Ensure `IsLogging` is set to `TRUE`\n\n- Ensure the identified multi-region CloudTrail trail captures all management events:\n\n - `aws cloudtrail get-event-selectors --trail-name <trail-name>`\n\n - Ensure there is at least one `event selector` for a trail with `IncludeManagementEvents` set to `true` and `ReadWriteType` set to `All`\n\n2. Get a list of all associated metric filters for the `<trail-log-group-name>` captured in step 1:\n\n ```\n aws logs describe-metric-filters --log-group-name <trail-log-group-name>\n ```\n\n3. Ensure the output from the above command contains the following:\n\n ```\n \"filterPattern\": \"{ ($.eventName = CreateNetworkAcl) || ($.eventName = CreateNetworkAclEntry) || ($.eventName = DeleteNetworkAcl) || ($.eventName = DeleteNetworkAclEntry) || ($.eventName = ReplaceNetworkAclEntry) || ($.eventName = ReplaceNetworkAclAssociation) }\"\n ```\n\n4. Note the `<nacl-changes-metric>` value associated with the `filterPattern` from step 3.\n\n5. Get a list of CloudWatch alarms, and filter on the `<nacl-changes-metric>` captured in step 4:\n\n ```\n aws cloudwatch describe-alarms --query 'MetricAlarms[?MetricName==<nacl-changes-metric>]'\n ```\n\n6. Note the `AlarmActions` value; this will provide the SNS topic ARN value.\n\n7. Ensure there is at least one active subscriber to the SNS topic:\n\n ```\n aws sns list-subscriptions-by-topic --topic-arn <sns-topic-arn> \n ```\n\n- At least one subscription should have \"SubscriptionArn\" with a valid AWS ARN.\n\n - Example of valid \"SubscriptionArn\": `arn:aws:sns:<region>:<account-id>:<sns-topic-name>:<subscription-id>`",
    "remediation_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following steps to set up the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on the provided filter pattern that checks for NACL changes and uses the `<trail-log-group-name>` taken from audit step 1:\n\n ```\n aws logs put-metric-filter --log-group-name <trail-log-group-name> --filter-name <nacl-changes-metric> --metric-transformations metricName=<nacl-changes-metric>,metricNamespace='CISBenchmark',metricValue=1 --filter-pattern '{ ($.eventName = CreateNetworkAcl) || ($.eventName = CreateNetworkAclEntry) || ($.eventName = DeleteNetworkAcl) || ($.eventName = DeleteNetworkAclEntry) || ($.eventName = ReplaceNetworkAclEntry) || ($.eventName = ReplaceNetworkAclAssociation) }'\n ```\n\n **Note**: You can choose your own `metricName` and `metricNamespace` strings. Using the same `metricNamespace` for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify:\n\n ```\n aws sns create-topic --name <sns-topic-name>\n ```\n\n **Note**: You can execute this command once and then reuse the same topic for all monitoring alarms.\n\n **Note**: Capture the `TopicArn` that is displayed when creating the SNS topic in step 2.\n\n3. Create an SNS subscription for the topic created in step 2:\n\n ```\n aws sns subscribe --topic-arn <sns-topic-arn> --protocol <sns-protocol> --notification-endpoint <sns-subscription-endpoints>\n ```\n\n **Note**: You can execute this command once and then reuse the same subscription for all monitoring alarms.\n\n4. Create an alarm that is associated with the CloudWatch Logs metric filter created in step 1 and the SNS topic created in step 2:\n\n ```\n aws cloudwatch put-metric-alarm --alarm-name <nacl-changes-alarm> --metric-name <nacl-changes-metric> --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace 'CISBenchmark' --alarm-actions <sns-topic-arn>\n ```"
  },
  {
    "recommendation_number": "4.12",
    "section": 4.0,
    "title": "Ensure changes to network gateways are monitored",
    "profile": "Level 1",
    "assessment_status": "Manual",
    "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs or an external Security Information and Event Management (SIEM) environment, and establishing corresponding metric filters and alarms. \n\nNetwork gateways are required to send and receive traffic to a destination outside of a VPC. It is recommended that a metric filter and alarm be established for changes to network gateways.",
    "audit_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following to ensure that there is at least one active multi-region CloudTrail trail with the prescribed metric filters and alarms configured:\n\n1. Identify the log group name that is configured for use with the active multi-region CloudTrail trail:\n\n- List all CloudTrail trails: `aws cloudtrail describe-trails`\n\n- Identify multi-region CloudTrail trails: `Trails with \"IsMultiRegionTrail\" set to true`\n\n- Note the value associated with \"Name\":`<trail-name>`\n\n- Note the `<trail-log-group-name>` within the value associated with \"CloudWatchLogsLogGroupArn\"\n\n - Example: `arn:aws:logs:<region>:<account-id>:log-group:<trail-log-group-name>:*`\n\n- Ensure the identified multi-region CloudTrail trail is active:\n\n - `aws cloudtrail get-trail-status --name <trail-name>`\n\n - Ensure `IsLogging` is set to `TRUE`\n\n- Ensure the identified multi-region CloudTrail trail captures all management events:\n\n - `aws cloudtrail get-event-selectors --trail-name <trail-name>`\n\n - Ensure there is at least one `event selector` for a trail with `IncludeManagementEvents` set to `true` and `ReadWriteType` set to `All`\n\n2. Get a list of all associated metric filters for the `<trail-log-group-name>` captured in step 1:\n\n ```\n aws logs describe-metric-filters --log-group-name <trail-log-group-name>\n ```\n\n3. Ensure the output from the above command contains the following:\n\n ```\n \"filterPattern\": \"{ ($.eventName = CreateCustomerGateway) || ($.eventName = DeleteCustomerGateway) || ($.eventName = AttachInternetGateway) || ($.eventName = CreateInternetGateway) || ($.eventName = DeleteInternetGateway) || ($.eventName = DetachInternetGateway) }\"\n ```\n\n4. Note the `<network-gw-changes-metric>` value associated with the `filterPattern` from step 3.\n\n5. Get a list of CloudWatch alarms, and filter on the `<network-gw-changes-metric>` captured in step 4:\n\n ```\n aws cloudwatch describe-alarms --query 'MetricAlarms[?MetricName==<network-gw-changes-metric>]'\n ```\n\n6. Note the `AlarmActions` value; this will provide the SNS topic ARN value.\n\n7. Ensure there is at least one active subscriber to the SNS topic:\n\n ```\n aws sns list-subscriptions-by-topic --topic-arn <sns-topic-arn> \n ```\n\n- At least one subscription should have \"SubscriptionArn\" with a valid AWS ARN.\n\n - Example of valid \"SubscriptionArn\": `arn:aws:sns:<region>:<account-id>:<sns-topic-name>:<subscription-id>`\n\n8. Ensure automated monitoring is enabled:\n\n ```\n aws cloudwatch put-metric-alarm --alarm-name NetworkGatewayChanges --metric-name GatewayChanges --namespace AWS/EC2 --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --alarm-actions <sns-topic-arn>\n ```",
    "remediation_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following steps to set up the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on the provided filter pattern that checks for network gateways changes and uses the `<trail-log-group-name>` taken from audit step 1:\n\n ```\n aws logs put-metric-filter --log-group-name <trail-log-group-name> --filter-name <network-gw-changes-metric> --metric-transformations metricName=<network-gw-changes-metric>,metricNamespace='CISBenchmark',metricValue=1 --filter-pattern '{ ($.eventName = CreateCustomerGateway) || ($.eventName = DeleteCustomerGateway) || ($.eventName = AttachInternetGateway) || ($.eventName = CreateInternetGateway) || ($.eventName = DeleteInternetGateway) || ($.eventName = DetachInternetGateway) }'\n ```\n\n **Note**: You can choose your own `metricName` and `metricNamespace` strings. Using the same `metricNamespace` for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify:\n\n ```\n aws sns create-topic --name <sns-topic-name>\n ```\n\n **Note**: You can execute this command once and then reuse the same topic for all monitoring alarms.\n\n **Note**: Capture the `TopicArn` that is displayed when creating the SNS topic in step 2.\n\n3. Create an SNS subscription for the topic created in step 2:\n\n ```\n aws sns subscribe --topic-arn <sns-topic-arn> --protocol <sns-protocol> --notification-endpoint <sns-subscription-endpoints>\n ```\n\n **Note**: You can execute this command once and then reuse the same subscription for all monitoring alarms.\n\n4. Create an alarm that is associated with the CloudWatch Logs metric filter created in step 1 and the SNS topic created in step 2:\n\n ```\n aws cloudwatch put-metric-alarm --alarm-name <network-gw-changes-alarm> --metric-name <network-gw-changes-metric> --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace 'CISBenchmark' --alarm-actions <sns-topic-arn>\n ```\n\n5. Implement logging and alerting mechanisms:\n\n ```\n aws sns create-topic --name NetworkGatewayChangesAlerts\n ````\n\n ```\n aws sns subscribe --topic-arn <sns-topic-arn> --protocol email --notification-endpoint <email-address>\n ```\n\n ```\n aws cloudwatch put-metric-alarm --alarm-name NetworkGatewayChangesAlarm --metric-name GatewayChanges --namespace AWS/EC2 --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --alarm-actions <sns-topic-arn>\n ```"
  },
  {
    "recommendation_number": "4.13",
    "section": 4.0,
    "title": "Ensure route table changes are monitored",
    "profile": "Level 1",
    "assessment_status": "Manual",
    "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs or an external Security Information and Event Management (SIEM) environment, and establishing corresponding metric filters and alarms. \n\nRouting tables are used to route network traffic between subnets and to network gateways.\n\nIt is recommended that a metric filter and alarm be established for changes to route tables.",
    "audit_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following to ensure that there is at least one active multi-region CloudTrail trail with the prescribed metric filters and alarms configured:\n\n1. Identify the log group name that is configured for use with the active multi-region CloudTrail trail:\n\n- List all CloudTrail trails: `aws cloudtrail describe-trails`\n\n- Identify multi-region CloudTrail trails: `Trails with \"IsMultiRegionTrail\" set to true`\n\n- Note the value associated with \"Name\":`<trail-name>`\n\n- Note the `<trail-log-group-name>` within the value associated with \"CloudWatchLogsLogGroupArn\"\n\n - Example: `arn:aws:logs:<region>:<account-id>:log-group:<trail-log-group-name>:*`\n\n- Ensure the identified multi-region CloudTrail trail is active:\n\n - `aws cloudtrail get-trail-status --name <trail-name>`\n\n - Ensure `IsLogging` is set to `TRUE`\n\n- Ensure the identified multi-region CloudTrail trail captures all management events:\n\n - `aws cloudtrail get-event-selectors --trail-name <trail-name>`\n\n - Ensure there is at least one `event selector` for a trail with `IncludeManagementEvents` set to `true` and `ReadWriteType` set to `All`\n\n2. Get a list of all associated metric filters for the `<trail-log-group-name>` captured in step 1:\n\n ```\n aws logs describe-metric-filters --log-group-name <trail-log-group-name>\n ```\n\n3. Ensure the output from the above command contains the following:\n\n ```\n \"filterPattern\": \"{($.eventSource = ec2.amazonaws.com) && ($.eventName = CreateRoute) || ($.eventName = CreateRouteTable) || ($.eventName = ReplaceRoute) || ($.eventName = ReplaceRouteTableAssociation) || ($.eventName = DeleteRouteTable) || ($.eventName = DeleteRoute) || ($.eventName = DisassociateRouteTable) }\"\n ```\n\n4. Note the `<route-table-changes-metric>` value associated with the `filterPattern` from step 3.\n\n5. Get a list of CloudWatch alarms, and filter on the `<route-table-changes-metric>` captured in step 4:\n\n ```\n aws cloudwatch describe-alarms --query 'MetricAlarms[?MetricName==<route-table-changes-metric>]'\n ```\n\n6. Note the `AlarmActions` value; this will provide the SNS topic ARN value.\n\n7. Ensure there is at least one active subscriber to the SNS topic:\n\n ```\n aws sns list-subscriptions-by-topic --topic-arn <sns-topic-arn> \n ```\n\n- At least one subscription should have \"SubscriptionArn\" with a valid AWS ARN.\n\n - Example of valid \"SubscriptionArn\": `arn:aws:sns:<region>:<account-id>:<sns-topic-name>:<subscription-id>`",
    "remediation_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following steps to set up the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on the provided filter pattern that checks for route table changes and uses the `<trail-log-group-name>` taken from audit step 1:\n\n ```\n aws logs put-metric-filter --log-group-name <trail-log-group-name> --filter-pattern '{ ($.eventName = CreateRoute) || ($.eventName = CreateRouteTable) || ($.eventName = ReplaceRoute) || ($.eventName = ReplaceRouteTableAssociation) || ($.eventName = DeleteRouteTable) || ($.eventName = DeleteRoute) || ($.eventName = DisassociateRouteTable) }'\n ```\n\n **Note**: You can choose your own `metricName` and `metricNamespace` strings. Using the same `metricNamespace` for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify:\n\n ```\n aws sns create-topic --name <sns-topic-name>\n ```\n\n **Note**: You can execute this command once and then reuse the same topic for all monitoring alarms.\n\n **Note**: Capture the `TopicArn` that is displayed when creating the SNS topic in step 2.\n\n3. Create an SNS subscription for the topic created in step 2:\n\n ```\n aws sns subscribe --topic-arn <sns-topic-arn> --protocol <sns-protocol> --notification-endpoint <sns-subscription-endpoints>\n ```\n\n **Note**: You can execute this command once and then reuse the same subscription for all monitoring alarms.\n\n4. Create an alarm that is associated with the CloudWatch Logs metric filter created in step 1 and the SNS topic created in step 2:\n\n ```\n aws cloudwatch put-metric-alarm --alarm-name <route-table-changes-alarm> --metric-name <route-table-changes-metric> --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace 'CISBenchmark' --alarm-actions <sns-topic-arn>\n ```"
  },
  {
    "recommendation_number": "4.14",
    "section": 4.0,
    "title": "Ensure VPC changes are monitored",
    "profile": "Level 1",
    "assessment_status": "Manual",
    "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs or an external Security Information and Event Management (SIEM) environment, and establishing corresponding metric filters and alarms. \n\nIt is possible to have more than one VPC within an account; additionally, it is also possible to create a peer connection between two VPCs, enabling network traffic to route between them.\n\nIt is recommended that a metric filter and alarm be established for changes made to VPCs.",
    "audit_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following to ensure that there is at least one active multi-region CloudTrail trail with the prescribed metric filters and alarms configured:\n\n1. Identify the log group name that is configured for use with the active multi-region CloudTrail trail:\n\n- List all CloudTrail trails: `aws cloudtrail describe-trails`\n\n- Identify multi-region CloudTrail trails: `Trails with \"IsMultiRegionTrail\" set to true`\n\n- Note the value associated with \"Name\":`<trail-name>`\n\n- Note the `<trail-log-group-name>` within the value associated with \"CloudWatchLogsLogGroupArn\"\n\n - Example: `arn:aws:logs:<region>:<account-id>:log-group:<trail-log-group-name>:*`\n\n- Ensure the identified multi-region CloudTrail trail is active:\n\n - `aws cloudtrail get-trail-status --name <trail-name>`\n\n - Ensure `IsLogging` is set to `TRUE`\n\n- Ensure the identified multi-region CloudTrail trail captures all management events:\n\n - `aws cloudtrail get-event-selectors --trail-name <trail-name>`\n\n - Ensure there is at least one `event selector` for a trail with `IncludeManagementEvents` set to `true` and `ReadWriteType` set to `All`\n\n2. Get a list of all associated metric filters for the `<trail-log-group-name>` captured in step 1:\n\n ```\n aws logs describe-metric-filters --log-group-name <trail-log-group-name>\n ```\n\n3. Ensure the output from the above command contains the following:\n\n ```\n \"filterPattern\": \"{ ($.eventName = CreateVpc) || ($.eventName = DeleteVpc) || ($.eventName = ModifyVpcAttribute) || ($.eventName = AcceptVpcPeeringConnection) || ($.eventName = CreateVpcPeeringConnection) || ($.eventName = DeleteVpcPeeringConnection) || ($.eventName = RejectVpcPeeringConnection) || ($.eventName = AttachClassicLinkVpc) || ($.eventName = DetachClassicLinkVpc) || ($.eventName = DisableVpcClassicLink) || ($.eventName = EnableVpcClassicLink) }\"\n ```\n\n4. Note the `<vpc-changes-metric>` value associated with the `filterPattern` from step 3.\n\n5. Get a list of CloudWatch alarms, and filter on the `<vpc-changes-metric>` captured in step 4:\n\n ```\n aws cloudwatch describe-alarms --query 'MetricAlarms[?MetricName==<vpc-changes-metric>]'\n ```\n\n6. Note the `AlarmActions` value; this will provide the SNS topic ARN value.\n\n7. Ensure there is at least one active subscriber to the SNS topic:\n\n ```\n aws sns list-subscriptions-by-topic --topic-arn <sns-topic-arn> \n ```\n\n- At least one subscription should have \"SubscriptionArn\" with a valid AWS ARN.\n\n - Example of valid \"SubscriptionArn\": `arn:aws:sns:<region>:<account-id>:<sns-topic-name>:<subscription-id>`",
    "remediation_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following steps to set up the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on the provided filter pattern that checks for VPC changes and uses the `<trail-log-group-name>` taken from audit step 1:\n\n ```\n aws logs put-metric-filter --log-group-name <trail-log-group-name> --filter-name <vpc-changes-metric> --metric-transformations metricName=<vpc-changes-metric>,metricNamespace='CISBenchmark',metricValue=1 --filter-pattern '{ ($.eventName = CreateVpc) || ($.eventName = DeleteVpc) || ($.eventName = ModifyVpcAttribute) || ($.eventName = AcceptVpcPeeringConnection) || ($.eventName = CreateVpcPeeringConnection) || ($.eventName = DeleteVpcPeeringConnection) || ($.eventName = RejectVpcPeeringConnection) || ($.eventName = AttachClassicLinkVpc) || ($.eventName = DetachClassicLinkVpc) || ($.eventName = DisableVpcClassicLink) || ($.eventName = EnableVpcClassicLink) }'\n ```\n\n **Note**: You can choose your own `metricName` and `metricNamespace` strings. Using the same `metricNamespace` for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify:\n\n ```\n aws sns create-topic --name <sns-topic-name>\n ```\n\n **Note**: You can execute this command once and then reuse the same topic for all monitoring alarms.\n\n **Note**: Capture the `TopicArn` that is displayed when creating the SNS topic in step 2.\n\n3. Create an SNS subscription for the topic created in step 2:\n\n ```\n aws sns subscribe --topic-arn <sns-topic-arn> --protocol <sns-protocol> --notification-endpoint <sns-subscription-endpoints>\n ```\n\n **Note**: You can execute this command once and then reuse the same subscription for all monitoring alarms.\n\n4. Create an alarm that is associated with the CloudWatch Logs metric filter created in step 1 and the SNS topic created in step 2:\n\n ```\n aws cloudwatch put-metric-alarm --alarm-name <vpc-changes-alarm> --metric-name <vpc-changes-metric> --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace 'CISBenchmark' --alarm-actions <sns-topic-arn>\n ```"
  },
  {
    "recommendation_number": "4.15",
    "section": 4.0,
    "title": "Ensure AWS Organizations changes are monitored",
    "profile": "Level 1",
    "assessment_status": "Manual",
    "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs or an external Security Information and Event Management (SIEM) environment, and establishing corresponding metric filters and alarms. \n\nIt is recommended that a metric filter and alarm be established for changes made to AWS Organizations in the master AWS account.",
    "audit_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following to ensure that there is at least one active multi-region CloudTrail trail with the prescribed metric filters and alarms configured:\n\n1. Identify the log group name that is configured for use with the active multi-region CloudTrail trail:\n\n- List all CloudTrail trails: `aws cloudtrail describe-trails`\n\n- Identify multi-region CloudTrail trails: `Trails with \"IsMultiRegionTrail\" set to true`\n\n- Note the value associated with \"Name\":`<trail-name>`\n\n- Note the `<trail-log-group-name>` within the value associated with \"CloudWatchLogsLogGroupArn\"\n\n - Example: `arn:aws:logs:<region>:<account-id>:log-group:<trail-log-group-name>:*`\n\n- Ensure the identified multi-region CloudTrail trail is active:\n\n - `aws cloudtrail get-trail-status --name <trail-name>`\n\n - Ensure `IsLogging` is set to `TRUE`\n\n- Ensure the identified multi-region CloudTrail trail captures all management events:\n\n - `aws cloudtrail get-event-selectors --trail-name <trail-name>`\n\n - Ensure there is at least one `event selector` for a trail with `IncludeManagementEvents` set to `true` and `ReadWriteType` set to `All`\n\n2. Get a list of all associated metric filters for the `<trail-log-group-name>` captured in step 1:\n\n ```\n aws logs describe-metric-filters --log-group-name <trail-log-group-name>\n ```\n\n3. Ensure the output from the above command contains the following:\n\n ```\n \"filterPattern\": \"{ ($.eventSource = organizations.amazonaws.com) && (($.eventName = \"AcceptHandshake\") || ($.eventName = \"AttachPolicy\") || ($.eventName = \"CreateAccount\") || ($.eventName = \"CreateOrganizationalUnit\") || ($.eventName = \"CreatePolicy\") || ($.eventName = \"DeclineHandshake\") || ($.eventName = \"DeleteOrganization\") || ($.eventName = \"DeleteOrganizationalUnit\") || ($.eventName = \"DeletePolicy\") || ($.eventName = \"DetachPolicy\") || ($.eventName = \"DisablePolicyType\") || ($.eventName = \"EnablePolicyType\") || ($.eventName = \"InviteAccountToOrganization\") || ($.eventName = \"LeaveOrganization\") || ($.eventName = \"MoveAccount\") || ($.eventName = \"RemoveAccountFromOrganization\") || ($.eventName = \"UpdatePolicy\") || ($.eventName = \"UpdateOrganizationalUnit\")) }\"\n ```\n\n4. Note the `<organizations-changes>` value associated with the `filterPattern` from step 3.\n\n5. Get a list of CloudWatch alarms, and filter on the `<organizations-changes>` captured in step 4:\n\n ```\n aws cloudwatch describe-alarms --query 'MetricAlarms[?MetricName==<organizations-changes>]'\n ```\n\n6. Note the `AlarmActions` value; this will provide the SNS topic ARN value.\n\n7. Ensure there is at least one active subscriber to the SNS topic:\n\n ```\n aws sns list-subscriptions-by-topic --topic-arn <sns-topic-arn> \n ```\n\n- At least one subscription should have \"SubscriptionArn\" with a valid AWS ARN.\n\n - Example of valid \"SubscriptionArn\": `arn:aws:sns:<region>:<account-id>:<sns-topic-name>:<subscription-id>`",
    "remediation_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following steps to set up the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on the provided filter pattern that checks for AWS Organizations changes and uses the `<trail-log-group-name>` taken from audit step 1:\n\n ```\n aws logs put-metric-filter --log-group-name <trail-log-group-name> --filter-name <organizations-changes> --metric-transformations metricName=<organizations-changes>,metricNamespace='CISBenchmark',metricValue=1 --filter-pattern '{ ($.eventSource = organizations.amazonaws.com) && (($.eventName = \"AcceptHandshake\") || ($.eventName = \"AttachPolicy\") || ($.eventName = \"CreateAccount\") || ($.eventName = \"CreateOrganizationalUnit\") || ($.eventName = \"CreatePolicy\") || ($.eventName = \"DeclineHandshake\") || ($.eventName = \"DeleteOrganization\") || ($.eventName = \"DeleteOrganizationalUnit\") || ($.eventName = \"DeletePolicy\") || ($.eventName = \"DetachPolicy\") || ($.eventName = \"DisablePolicyType\") || ($.eventName = \"EnablePolicyType\") || ($.eventName = \"InviteAccountToOrganization\") || ($.eventName = \"LeaveOrganization\") || ($.eventName = \"MoveAccount\") || ($.eventName = \"RemoveAccountFromOrganization\") || ($.eventName = \"UpdatePolicy\") || ($.eventName = \"UpdateOrganizationalUnit\")) }'\n ```\n\n **Note**: You can choose your own `metricName` and `metricNamespace` strings. Using the same `metricNamespace` for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify:\n\n ```\n aws sns create-topic --name <sns-topic-name>\n ```\n\n **Note**: You can execute this command once and then reuse the same topic for all monitoring alarms.\n\n **Note**: Capture the `TopicArn` that is displayed when creating the SNS topic in step 2.\n\n3. Create an SNS subscription for the topic created in step 2:\n\n ```\n aws sns subscribe --topic-arn <sns-topic-arn> --protocol <sns-protocol> --notification-endpoint <sns-subscription-endpoints>\n ```\n\n **Note**: You can execute this command once and then reuse the same subscription for all monitoring alarms.\n\n4. Create an alarm that is associated with the CloudWatch Logs metric filter created in step 1 and the SNS topic created in step 2:\n\n ```\n aws cloudwatch put-metric-alarm --alarm-name <organizations-changes> --metric-name <organizations-changes> --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace 'CISBenchmark' --alarm-actions <sns-topic-arn>\n ```"
  },
  {
    "recommendation_number": "4.16",
    "section": 4.0,
    "title": "Ensure AWS Security Hub is enabled",
    "profile": "Level 2",
    "assessment_status": "Automated",
    "description": "Security Hub collects security data from various AWS accounts, services, and supported third-party partner products, helping you analyze your security trends and identify the highest-priority security issues. When you enable Security Hub, it begins to consume, aggregate, organize, and prioritize findings from the AWS services that you have enabled, such as Amazon GuardDuty, Amazon Inspector, and Amazon Macie. You can also enable integrations with AWS partner security products.",
    "audit_procedure": "Follow this process to evaluate AWS Security Hub configuration per region:\n\n**From Console:**\n\n1. Sign in to the AWS Management Console and open the AWS Security Hub console at https://console.aws.amazon.com/securityhub/.\n2. On the top right of the console, select the target Region.\n3. If the Security Hub > Summary page is displayed, then Security Hub is set up for the selected region.\n4. If presented with \"Setup Security Hub\" or \"Get Started With Security Hub,\" refer to the remediation steps.\n5. Repeat steps 2 to 4 for each region.\n\n**From Command Line:**\n\nRun the following command to verify the Security Hub status:\n\n```\naws securityhub describe-hub\n```\n\nThis will list the Security Hub status by region. Check for a 'SubscribedAt' value.\n\nExample output:\n\n```\n{\n \"HubArn\": \"<security-hub-arn>\",\n \"SubscribedAt\": \"2022-08-19T17:06:42.398Z\",\n \"AutoEnableControls\": true\n}\n```\n\nAn error will be returned if Security Hub is not enabled.\n\nExample error:\n\n```\nAn error occurred (InvalidAccessException) when calling the DescribeHub operation: Account <Account ID> is not subscribed to AWS Security Hub\n```",
    "remediation_procedure": "To grant the permissions required to enable Security Hub, attach the Security Hub managed policy `AWSSecurityHubFullAccess` to an IAM user, group, or role.\n\nEnabling Security Hub:\n\n**From Console:**\n\n1. Use the credentials of the IAM identity to sign in to the Security Hub console.\n2. When you open the Security Hub console for the first time, choose `Go to Security Hub`.\n3. The `Security standards` section on the welcome page lists supported security standards. Check the box for a standard to enable it.\n3. Choose `Enable Security Hub`.\n\n**From Command Line:**\n\n1. Run the `enable-security-hub` command, including `--enable-default-standards` to enable the default standards:\n\n```\naws securityhub enable-security-hub --enable-default-standards\n```\n\n2. To enable Security Hub without the default standards, include `--no-enable-default-standards`:\n```\naws securityhub enable-security-hub --no-enable-default-standards\n```"
  },
  {
    "recommendation_number": "4.2",
    "section": 4.0,
    "title": "Ensure management console sign-in without MFA is monitored",
    "profile": "Level 1",
    "assessment_status": "Manual",
    "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs or an external Security Information and Event Management (SIEM) environment, and establishing corresponding metric filters and alarms. \n\nIt is recommended that a metric filter and alarm be established for console logins that are not protected by multi-factor authentication (MFA).",
    "audit_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following to ensure that there is at least one active multi-region CloudTrail trail with the prescribed metric filters and alarms configured:\n\n1. Identify the log group name that is configured for use with the active multi-region CloudTrail trail:\n\n- List all CloudTrail trails:\n\n ```\n aws cloudtrail describe-trails\n ```\n\n- Identify multi-region CloudTrail trails: `Trails with \"IsMultiRegionTrail\" set to true`\n\n- Note the value associated with \"Name\":`<trail-name>`\n\n- Note the `<trail-log-group-name>` within the value associated with \"CloudWatchLogsLogGroupArn\"\n\n - Example: `arn:aws:logs:<region>:<account-id>:log-group:<trail-log-group-name>:*`\n\n- Ensure the identified multi-region CloudTrail trail is active:\n\n ```\n aws cloudtrail get-trail-status --name <trail-name>\n ```\n\n - ensure `IsLogging` is set to `TRUE`\n\n- Ensure the identified multi-region CloudTrail trail captures all management events:\n\n ```\n aws cloudtrail get-event-selectors --trail-name <trail-name>\n ```\n\n - Ensure there is at least one `event selector` for a trail with `IncludeManagementEvents` set to `true` and `ReadWriteType` set to `All`\n\n2. Get a list of all associated metric filters for the `<trail-log-group-name>` captured in step 1:\n\n ```\n aws logs describe-metric-filters --log-group-name <trail-log-group-name>\n ```\n\n3. Ensure the output from the above command contains the following:\n\n ```\n \"filterPattern\": \"{ ($.eventName = \"ConsoleLogin\") && ($.additionalEventData.MFAUsed != \"Yes\") }\"\n ```\n\n Or, to reduce false positives in case Single Sign-On (SSO) is used in the organization:\n\n ```\n \"filterPattern\": \"{ ($.eventName = \"ConsoleLogin\") && ($.additionalEventData.MFAUsed != \"Yes\") && ($.userIdentity.type = \"IAMUser\") && ($.responseElements.ConsoleLogin = \"Success\") }\"\n ```\n\n4. Note the `<no-mfa-console-signin-metric>` value associated with the `filterPattern` from step 3.\n\n5. Get a list of CloudWatch alarms, and filter on the `<no-mfa-console-signin-metric>` captured in step 4.\n\n ```\n aws cloudwatch describe-alarms --query 'MetricAlarms[?MetricName== <no-mfa-console-signin-metric>]'\n ```\n\n6. Note the `AlarmActions` value; this will provide the SNS topic ARN value.\n\n7. Ensure there is at least one active subscriber to the SNS topic:\n\n ```\n aws sns list-subscriptions-by-topic --topic-arn <sns-topic-arn> \n ```\n- At least one subscription should have \"SubscriptionArn\" with a valid AWS ARN.\n - Example of valid \"SubscriptionArn\": `arn:aws:sns:<region>:<account-id>:<sns-topic-name>:<subscription-id>`",
    "remediation_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following steps to set up the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on the provided filter pattern that checks for AWS Management Console sign-ins without MFA and uses the `<trail-log-group-name>` taken from audit step 1.\n\n ```\n aws logs put-metric-filter --log-group-name <trail-log-group-name> --filter-name `<no-mfa-console-signin-metric>` --metric-transformations metricName= `<no-mfa-console-signin-metric>`,metricNamespace='CISBenchmark',metricValue=1 --filter-pattern '{ ($.eventName = \"ConsoleLogin\") && ($.additionalEventData.MFAUsed != \"Yes\") }'\n ```\n\n Or, to reduce false positives in case Single Sign-On (SSO) is used in the organization:\n\n ```\n aws logs put-metric-filter --log-group-name <trail-log-group-name> --filter-name `<no-mfa-console-signin-metric>` --metric-transformations metricName= `<no-mfa-console-signin-metric>`,metricNamespace='CISBenchmark',metricValue=1 --filter-pattern '{ ($.eventName = \"ConsoleLogin\") && ($.additionalEventData.MFAUsed != \"Yes\") && ($.userIdentity.type = \"IAMUser\") && ($.responseElements.ConsoleLogin = \"Success\") }'\n ```\n\n **Note**: You can choose your own `metricName` and `metricNamespace` strings. Using the same `metricNamespace` for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify:\n\n ```\n aws sns create-topic --name <sns-topic-name>\n ```\n\n **Note**: You can execute this command once and then reuse the same topic for all monitoring alarms.\n\n **Note**: Capture the `TopicArn` that is displayed when creating the SNS topic in step 2.\n\n3. Create an SNS subscription for the topic created in step 2:\n\n ```\n aws sns subscribe --topic-arn <sns-topic-arn> --protocol <sns-protocol> --notification-endpoint <sns-subscription-endpoints>\n ```\n\n **Note**: You can execute this command once and then reuse the same subscription for all monitoring alarms.\n\n4. Create an alarm that is associated with the CloudWatch Logs metric filter created in step 1 and the SNS topic created in step 2:\n\n ```\n aws cloudwatch put-metric-alarm --alarm-name `<no-mfa-console-signin-alarm>` --metric-name `<no-mfa-console-signin-metric>` --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace 'CISBenchmark' --alarm-actions <sns-topic-arn>\n ```"
  },
  {
    "recommendation_number": "4.3",
    "section": 4.0,
    "title": "Ensure usage of the 'root' account is monitored",
    "profile": "Level 1",
    "assessment_status": "Manual",
    "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs or an external Security Information and Event Management (SIEM) environment, and establishing corresponding metric filters and alarms. \n\nIt is recommended that a metric filter and alarm be established for 'root' login attempts to detect unauthorized use or attempts to use the root account.",
    "audit_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following to ensure that there is at least one active multi-region CloudTrail trail with the prescribed metric filters and alarms configured:\n\n1. Identify the log group name that is configured for use with the active multi-region CloudTrail trail:\n\n- List all CloudTrail trails:\n\n ```\n aws cloudtrail describe-trails\n ```\n\n- Identify multi-region CloudTrail trails: `Trails with \"IsMultiRegionTrail\" set to true`\n\n- Note the value associated with \"Name\":`<trail-name>`\n\n- Note the `<trail-log-group-name>` within the value associated with \"CloudWatchLogsLogGroupArn\"\n\n - Example: `arn:aws:logs:<region>:<account-id>:log-group:<trail-log-group-name>:*`\n\n- Ensure the identified multi-region CloudTrail trail is active:\n\n ```\n aws cloudtrail get-trail-status --name <trail-name>\n ```\n\n - Ensure `IsLogging` is set to `TRUE`\n\n- Ensure the identified multi-region CloudTrail trail captures all management events:\n\n ```\n aws cloudtrail get-event-selectors --trail-name <trail-name>\n ```\n\n - Ensure there is at least one `event selector` for a trail with `IncludeManagementEvents` set to `true` and `ReadWriteType` set to `All`\n\n2. Get a list of all associated metric filters for the `<trail-log-group-name>` captured in step 1:\n\n ```\n aws logs describe-metric-filters --log-group-name <trail-log-group-name>\n ```\n\n3. Ensure the output from the above command contains the following:\n\n ```\n \"filterPattern\": \"{ $.userIdentity.type = \"Root\" && $.userIdentity.invokedBy NOT EXISTS && $.eventType != \"AwsServiceEvent\" }\"\n ```\n\n4. Note the `<root-usage-metric>` value associated with the `filterPattern` from step 3.\n\n5. Get a list of CloudWatch alarms, and filter on the `<root-usage-metric>` captured in step 4:\n\n ```\n aws cloudwatch describe-alarms --query 'MetricAlarms[?MetricName==<root-usage-metric>]'\n ```\n\n6. Note the `AlarmActions` value; this will provide the SNS topic ARN value.\n\n7. Ensure there is at least one active subscriber to the SNS topic:\n\n ```\n aws sns list-subscriptions-by-topic --topic-arn <sns-topic-arn> \n ```\n- At least one subscription should have \"SubscriptionArn\" with a valid AWS ARN.\n\n - Example of valid \"SubscriptionArn\": `arn:aws:sns:<region>:<account-id>:<sns-topic-name>:<subscription-id>`",
    "remediation_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following steps to set up the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on the provided filter pattern that checks for 'root' account usage and uses the `<trail-log-group-name>` taken from audit step 1:\n\n ```\n aws logs put-metric-filter --log-group-name `<trail-log-group-name>` --filter-name `<root-usage-metric>` --metric-transformations metricName= `<root-usage-metric>` ,metricNamespace='CISBenchmark',metricValue=1 --filter-pattern '{ $.userIdentity.type = \"Root\" && $.userIdentity.invokedBy NOT EXISTS && $.eventType != \"AwsServiceEvent\" }'\n ```\n\n **Note**: You can choose your own `metricName` and `metricNamespace` strings. Using the same `metricNamespace` for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify:\n\n ```\n aws sns create-topic --name <sns-topic-name>\n ```\n\n **Note**: You can execute this command once and then reuse the same topic for all monitoring alarms.\n\n **Note**: Capture the `TopicArn` that is displayed when creating the SNS topic in step 2.\n\n3. Create an SNS subscription for the topic created in step 2:\n\n ```\n aws sns subscribe --topic-arn <sns-topic-arn> --protocol <sns-protocol> --notification-endpoint <sns-subscription-endpoints>\n ```\n\n **Note**: You can execute this command once and then reuse the same subscription for all monitoring alarms.\n\n4. Create an alarm that is associated with the CloudWatch Logs metric filter created in step 1 and the SNS topic created in step 2:\n\n ```\n aws cloudwatch put-metric-alarm --alarm-name `<root-usage-alarm>` --metric-name `<root-usage-metric>` --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace 'CISBenchmark' --alarm-actions <sns_topic_arn>\n ```"
  },
  {
    "recommendation_number": "4.4",
    "section": 4.0,
    "title": "Ensure IAM policy changes are monitored",
    "profile": "Level 1",
    "assessment_status": "Manual",
    "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs or an external Security Information and Event Management (SIEM) environment, and establishing corresponding metric filters and alarms.\n\nIt is recommended that a metric filter and alarm be established for changes made to Identity and Access Management (IAM) policies.",
    "audit_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following to ensure that there is at least one active multi-region CloudTrail trail with the prescribed metric filters and alarms configured:\n\n1. Identify the log group name that is configured for use with the active multi-region CloudTrail trail:\n\n- List all CloudTrails:\n\n ```\n aws cloudtrail describe-trails\n ```\n\n- Identify multi-region CloudTrail trails: `Trails with \"IsMultiRegionTrail\" set to true`\n\n- Note the value associated with \"Name\":`<trail-name>`\n\n- Note the `<trail-log-group-name>` within the value associated with \"CloudWatchLogsLogGroupArn\"\n\n - Example: `arn:aws:logs:<region>:<account-id>:log-group:<trail-log-group-name>:*`\n\n- Ensure the identified multi-region CloudTrail trail is active:\n\n ```\n aws cloudtrail get-trail-status --name <trail-name>\n ```\n\n - Ensure `IsLogging` is set to `TRUE`\n\n- Ensure the identified multi-region CloudTrail trail captures all management events:\n\n ```\n aws cloudtrail get-event-selectors --trail-name <trail-name>\n ```\n\n - Ensure there is at least one `event selector` for a trail with `IncludeManagementEvents` set to `true` and `ReadWriteType` set to `All`\n\n2. Get a list of all associated metric filters for the `<trail-log-group-name>` captured in step 1:\n\n ```\n aws logs describe-metric-filters --log-group-name <trail-log-group-name>\n ```\n\n3. Ensure the output from the above command contains the following:\n\n ```\n \"filterPattern\": \"{($.eventName=DeleteGroupPolicy)||($.eventName=DeleteRolePolicy)||($.eventName=DeleteUserPolicy)||($.eventName=PutGroupPolicy)||($.eventName=PutRolePolicy)||($.eventName=PutUserPolicy)||($.eventName=CreatePolicy)||($.eventName=DeletePolicy)||($.eventName=CreatePolicyVersion)||($.eventName=DeletePolicyVersion)||($.eventName=AttachRolePolicy)||($.eventName=DetachRolePolicy)||($.eventName=AttachUserPolicy)||($.eventName=DetachUserPolicy)||($.eventName=AttachGroupPolicy)||($.eventName=DetachGroupPolicy)}\"\n ```\n\n4. Note the `<iam-changes-metric>` value associated with the `filterPattern` from step 3.\n\n5. Get a list of CloudWatch alarms, and filter on the `<iam-change-metric>` captured in step 4:\n\n ```\n aws cloudwatch describe-alarms --query 'MetricAlarms[?MetricName==<iam-changes-metric>]'\n ```\n\n6. Note the `AlarmActions` value; this will provide the SNS topic ARN value.\n\n7. Ensure there is at least one active subscriber to the SNS topic:\n\n ```\n aws sns list-subscriptions-by-topic --topic-arn <sns-topic-arn> \n ```\n\n- At least one subscription should have \"SubscriptionArn\" with a valid AWS ARN.\n\n - Example of valid \"SubscriptionArn\": `arn:aws:sns:<region>:<account-id>:<sns-topic-name>:<subscription-id>`",
    "remediation_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following steps to set up the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on the provided filter pattern that checks for IAM policy changes and the `<trail-log-group-name>` taken from audit step 1:\n\n ```\n aws logs put-metric-filter --log-group-name `<trail-log-group-name>` --filter-name `<iam-changes-metric>` --metric-transformations metricName= `<iam-changes-metric>`,metricNamespace='CISBenchmark',metricValue=1 --filter-pattern '{($.eventName=DeleteGroupPolicy)||($.eventName=DeleteRolePolicy)||($.eventName=DeleteUserPolicy)||($.eventName=PutGroupPolicy)||($.eventName=PutRolePolicy)||($.eventName=PutUserPolicy)||($.eventName=CreatePolicy)||($.eventName=DeletePolicy)||($.eventName=CreatePolicyVersion)||($.eventName=DeletePolicyVersion)||($.eventName=AttachRolePolicy)||($.eventName=DetachRolePolicy)||($.eventName=AttachUserPolicy)||($.eventName=DetachUserPolicy)||($.eventName=AttachGroupPolicy)||($.eventName=DetachGroupPolicy)}'\n ```\n\n **Note**: You can choose your own `metricName` and `metricNamespace` strings. Using the same `metricNamespace` for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify:\n\n ```\n aws sns create-topic --name <sns-topic-name>\n ```\n\n **Note**: You can execute this command once and then reuse the same topic for all monitoring alarms.\n\n **Note**: Capture the `TopicArn` that is displayed when creating the SNS topic in step 2.\n\n3. Create an SNS subscription for the topic created in step 2:\n\n ```\n aws sns subscribe --topic-arn <sns-topic-arn> --protocol <sns-protocol> --notification-endpoint <sns-subscription-endpoints>\n ```\n\n **Note**: You can execute this command once and then reuse the same subscription for all monitoring alarms.\n\n4. Create an alarm that is associated with the CloudWatch Logs metric filter created in step 1 and the SNS topic created in step 2:\n\n ```\n aws cloudwatch put-metric-alarm --alarm-name `<iam-changes-alarm>` --metric-name `<iam-changes-metric>` --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace 'CISBenchmark' --alarm-actions <sns-topic-arn>\n ```"
  },
  {
    "recommendation_number": "4.5",
    "section": 4.0,
    "title": "Ensure CloudTrail configuration changes are monitored",
    "profile": "Level 1",
    "assessment_status": "Manual",
    "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs or an external Security Information and Event Management (SIEM) environment, and establishing corresponding metric filters and alarms. \n\nIt is recommended that a metric filter and alarm be used to detect changes to CloudTrail's configurations.",
    "audit_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following to ensure that there is at least one active multi-region CloudTrail trail with the prescribed metric filters and alarms configured:\n\n1. Identify the log group name that is configured for use with the active multi-region CloudTrail trail:\n\n- List all CloudTrail trails: `aws cloudtrail describe-trails`\n\n- Identify multi-region CloudTrail trails: `Trails with \"IsMultiRegionTrail\" set to true`\n\n- Note the value associated with \"Name\":`<trail-name>`\n\n- Note the `<trail-log-group-name>` within the value associated with \"CloudWatchLogsLogGroupArn\"\n\n - Example: `arn:aws:logs:<region>:<account-id>:log-group:<trail-log-group-name>:*`\n\n- Ensure the identified multi-region CloudTrail trail is active:\n\n - `aws cloudtrail get-trail-status --name <trail-name>`\n\n - Ensure `IsLogging` is set to `TRUE`\n\n- Ensure the identified multi-region CloudTrail trail captures all management events:\n\n - `aws cloudtrail get-event-selectors --trail-name <trail-name>`\n\n - Ensure there is at least one `event selector` for a trail with `IncludeManagementEvents` set to `true` and `ReadWriteType` set to `All`\n\n2. Get a list of all associated metric filters for the `<trail-log-group-name>` captured in step 1:\n\n ```\n aws logs describe-metric-filters --log-group-name <trail-log-group-name>\n ```\n\n3. Ensure the output from the above command contains the following:\n\n ```\n \"filterPattern\": \"{ ($.eventName = CreateTrail) || ($.eventName = UpdateTrail) || ($.eventName = DeleteTrail) || ($.eventName = StartLogging) || ($.eventName = StopLogging) }\"\n ```\n\n4. Note the `<cloudtrail-cfg-changes-metric>` value associated with the `filterPattern` from step 3.\n\n5. Get a list of CloudWatch alarms, and filter on the `<cloudtrail-cfg-changes-metric>` captured in step 4:\n\n ```\n aws cloudwatch describe-alarms --query 'MetricAlarms[?MetricName==<cloudtrail-cfg-changes-metric>]'\n ```\n\n6. Note the `AlarmActions` value; this will provide the SNS topic ARN value.\n\n7. Ensure there is at least one active subscriber to the SNS topic:\n\n ```\n aws sns list-subscriptions-by-topic --topic-arn <sns-topic-arn> \n ```\n\n- At least one subscription should have \"SubscriptionArn\" with a valid AWS ARN.\n\n - Example of valid \"SubscriptionArn\": `arn:aws:sns:<region>:<account-id>:<sns-topic-name>:<subscription-id>`",
    "remediation_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following steps to set up the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on the provided filter pattern that checks for CloudTrail configuration changes and the `<trail-log-group-name>` taken from audit step 1:\n\n ```\n aws logs put-metric-filter --log-group-name <trail-log-group-name> --filter-name <cloudtrail-cfg-changes-metric> --metric-transformations metricName=<cloudtrail-cfg-changes-metric>,metricNamespace='CISBenchmark',metricValue=1 --filter-pattern '{ ($.eventName = CreateTrail) || ($.eventName = UpdateTrail) || ($.eventName = DeleteTrail) || ($.eventName = StartLogging) || ($.eventName = StopLogging) }'\n ```\n\n **Note**: You can choose your own `metricName` and `metricNamespace` strings. Using the same `metricNamespace` for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify:\n\n ```\n aws sns create-topic --name <sns-topic-name>\n ```\n\n **Note**: You can execute this command once and then reuse the same topic for all monitoring alarms.\n\n **Note**: Capture the `TopicArn` that is displayed when creating the SNS topic in step 2.\n\n3. Create an SNS subscription for the topic created in step 2:\n\n ```\n aws sns subscribe --topic-arn <sns-topic-arn> --protocol <sns-protocol> --notification-endpoint <sns-subscription-endpoints>\n ```\n\n **Note**: You can execute this command once and then reuse the same subscription for all monitoring alarms.\n\n4. Create an alarm that is associated with the CloudWatch Logs metric filter created in step 1 and the SNS topic created in step 2:\n\n ```\n aws cloudwatch put-metric-alarm --alarm-name <cloudtrail-cfg-changes-alarm> --metric-name <cloudtrail-cfg-changes-metric> --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace 'CISBenchmark' --alarm-actions <sns-topic-arn>\n ```"
  },
  {
    "recommendation_number": "4.6",
    "section": 4.0,
    "title": "Ensure AWS Management Console authentication failures are monitored",
    "profile": "Level 2",
    "assessment_status": "Manual",
    "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs or an external Security Information and Event Management (SIEM) environment, and establishing corresponding metric filters and alarms. \n\nIt is recommended that a metric filter and alarm be established for failed console authentication attempts.",
    "audit_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following to ensure that there is at least one active multi-region CloudTrail trail with the prescribed metric filters and alarms configured:\n\n1. Identify the log group name that is configured for use with the active multi-region CloudTrail trail:\n\n- List all CloudTrail trails: `aws cloudtrail describe-trails`\n\n- Identify multi-region CloudTrail trails: `Trails with \"IsMultiRegionTrail\" set to true`\n\n- Note the value associated with \"Name\":`<trail-name>`\n\n- Note the `<trail-log-group-name>` within the value associated with \"CloudWatchLogsLogGroupArn\"\n\n - Example: `arn:aws:logs:<region>:<account-id>:log-group:<trail-log-group-name>:*`\n\n- Ensure the identified multi-region CloudTrail trail is active:\n\n - `aws cloudtrail get-trail-status --name <trail-name>`\n\n - Ensure `IsLogging` is set to `TRUE`\n\n- Ensure the identified multi-region CloudTrail trail captures all management events:\n\n - `aws cloudtrail get-event-selectors --trail-name <trail-name>`\n\n - Ensure there is at least one `event selector` for a trail with `IncludeManagementEvents` set to `true` and `ReadWriteType` set to `All`\n\n2. Get a list of all associated metric filters for the `<trail-log-group-name>` captured in step 1:\n\n ```\n aws logs describe-metric-filters --log-group-name <trail-log-group-name>\n ```\n\n3. Ensure the output from the above command contains the following:\n\n ```\n \"filterPattern\": \"{ ($.eventName = ConsoleLogin) && ($.errorMessage = \"Failed authentication\") }\"\n ```\n\n4. Note the `<console-signin-failure-metric>` value associated with the `filterPattern` from step 3.\n\n5. Get a list of CloudWatch alarms, and filter on the `<console-signin-failure-metric>` captured in step 4:\n\n ```\n aws cloudwatch describe-alarms --query 'MetricAlarms[?MetricName==<console-signin-failure-metric>]'\n ```\n\n6. Note the `AlarmActions` value; this will provide the SNS topic ARN value.\n\n7. Ensure there is at least one active subscriber to the SNS topic:\n\n ```\n aws sns list-subscriptions-by-topic --topic-arn <sns-topic-arn> \n ```\n\n- At least one subscription should have \"SubscriptionArn\" with a valid AWS ARN.\n\n - Example of valid \"SubscriptionArn\": `arn:aws:sns:<region>:<account-id>:<sns-topic-name>:<subscription-id>`",
    "remediation_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following steps to set up the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on the provided filter pattern that checks for AWS management Console login failures and uses the `<trail-log-group-name>` taken from audit step 1:\n\n ```\n aws logs put-metric-filter --log-group-name <trail-log-group-name> --filter-name <console-signin-failure-metric> --metric-transformations metricName=<console-signin-failure-metric>,metricNamespace='CISBenchmark',metricValue=1 --filter-pattern '{ ($.eventName = ConsoleLogin) && ($.errorMessage = \"Failed authentication\") }'\n ```\n\n **Note**: You can choose your own `metricName` and `metricNamespace` strings. Using the same `metricNamespace` for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify:\n\n ```\n aws sns create-topic --name <sns-topic-name>\n ```\n\n **Note**: You can execute this command once and then reuse the same topic for all monitoring alarms.\n\n **Note**: Capture the `TopicArn` that is displayed when creating the SNS topic in step 2.\n\n3. Create an SNS subscription for the topic created in step 2:\n\n ```\n aws sns subscribe --topic-arn <sns-topic-arn> --protocol <sns-protocol> --notification-endpoint <sns-subscription-endpoints>\n ```\n\n **Note**: You can execute this command once and then reuse the same subscription for all monitoring alarms.\n\n4. Create an alarm that is associated with the CloudWatch Logs metric filter created in step 1 and the SNS topic created in step 2:\n\n ```\n aws cloudwatch put-metric-alarm --alarm-name <console-signin-failure-alarm> --metric-name <console-signin-failure-metric> --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace 'CISBenchmark' --alarm-actions <sns-topic-arn>\n ```"
  },
  {
    "recommendation_number": "4.7",
    "section": 4.0,
    "title": "Ensure disabling or scheduled deletion of customer created CMKs is monitored",
    "profile": "Level 2",
    "assessment_status": "Manual",
    "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs or an external Security Information and Event Management (SIEM) environment, and establishing corresponding metric filters and alarms. \n\nIt is recommended that a metric filter and alarm be established for customer-created CMKs that have changed state to disabled or are scheduled for deletion.",
    "audit_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following to ensure that there is at least one active multi-region CloudTrail trail with the prescribed metric filters and alarms configured:\n\n1. Identify the log group name that is configured for use with the active multi-region CloudTrail trail:\n\n- List all CloudTrail trails: `aws cloudtrail describe-trails`\n\n- Identify multi-region CloudTrail trails: `Trails with \"IsMultiRegionTrail\" set to true`\n\n- Note the value associated with \"Name\":`<trail-name>`\n\n- Note the `<trail-log-group-name>` within the value associated with \"CloudWatchLogsLogGroupArn\"\n\n - Example: `arn:aws:logs:<region>:<account-id>:log-group:<trail-log-group-name>:*`\n\n- Ensure the identified multi-region CloudTrail trail is active:\n\n - `aws cloudtrail get-trail-status --name <trail-name>`\n\n - Ensure `IsLogging` is set to `TRUE`\n\n- Ensure the identified multi-region CloudTrail trail captures all management events:\n\n - `aws cloudtrail get-event-selectors --trail-name <trail-name>`\n\n - Ensure there is at least one `event selector` for a trail with `IncludeManagementEvents` set to `true` and `ReadWriteType` set to `All`\n\n2. Get a list of all associated metric filters for the `<trail-log-group-name>` captured in step 1:\n\n ```\n aws logs describe-metric-filters --log-group-name <trail-log-group-name>\n ```\n\n3. Ensure the output from the above command contains the following:\n\n ```\n \"filterPattern\": \"{($.eventSource = kms.amazonaws.com) && (($.eventName=DisableKey)||($.eventName=ScheduleKeyDeletion)) }\"\n ```\n\n4. Note the `<disable-or-delete-cmk-changes-metric>` value associated with the `filterPattern` from step 3.\n\n5. Get a list of CloudWatch alarms, and filter on the `<disable-or-delete-cmk-changes-metric>` captured in step 4:\n\n ```\n aws cloudwatch describe-alarms --query 'MetricAlarms[?MetricName==<disable-or-delete-cmk-changes-metric>]'\n ```\n\n6. Note the `AlarmActions` value; this will provide the SNS topic ARN value.\n\n7. Ensure there is at least one active subscriber to the SNS topic:\n\n ```\n aws sns list-subscriptions-by-topic --topic-arn <sns-topic-arn> \n ```\n\n- At least one subscription should have \"SubscriptionArn\" with a valid AWS ARN.\n\n - Example of valid \"SubscriptionArn\": `arn:aws:sns:<region>:<account-id>:<sns-topic-name>:<subscription-id>`",
    "remediation_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following steps to set up the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on the provided filter pattern that checks for CMKs that have been disabled or scheduled for deletion and uses the `<trail-log-group-name>` taken from audit step 1:\n\n ```\n aws logs put-metric-filter --log-group-name <trail-log-group-name> --filter-name <disable-or-delete-cmk-changes-metric> --metric-transformations metricName=<disable-or-delete-cmk-changes-metric>,metricNamespace='CISBenchmark',metricValue=1 --filter-pattern '{($.eventSource = kms.amazonaws.com) && (($.eventName=DisableKey)||($.eventName=ScheduleKeyDeletion)) }'\n ```\n\n **Note**: You can choose your own `metricName` and `metricNamespace` strings. Using the same `metricNamespace` for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify:\n\n ```\n aws sns create-topic --name <sns-topic-name>\n ```\n\n **Note**: You can execute this command once and then reuse the same topic for all monitoring alarms.\n\n **Note**: Capture the `TopicArn` that is displayed when creating the SNS topic in step 2.\n\n3. Create an SNS subscription for the topic created in step 2:\n\n ```\n aws sns subscribe --topic-arn <sns-topic-arn> --protocol <sns-protocol> --notification-endpoint <sns-subscription-endpoints>\n ```\n\n **Note**: You can execute this command once and then reuse the same subscription for all monitoring alarms.\n\n4. Create an alarm that is associated with the CloudWatch Logs metric filter created in step 1 and the SNS topic created in step 2:\n\n ```\n aws cloudwatch put-metric-alarm --alarm-name <disable-or-delete-cmk-changes-alarm> --metric-name <disable-or-delete-cmk-changes-metric> --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace 'CISBenchmark' --alarm-actions <sns-topic-arn>\n ```"
  },
  {
    "recommendation_number": "4.8",
    "section": 4.0,
    "title": "Ensure S3 bucket policy changes are monitored",
    "profile": "Level 1",
    "assessment_status": "Manual",
    "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs or an external Security Information and Event Management (SIEM) environment, and establishing corresponding metric filters and alarms. \n\nIt is recommended that a metric filter and alarm be established for changes to S3 bucket policies.",
    "audit_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following to ensure that there is at least one active multi-region CloudTrail trail with the prescribed metric filters and alarms configured:\n\n1. Identify the log group name that is configured for use with the active multi-region CloudTrail trail:\n\n- List all CloudTrail trails: `aws cloudtrail describe-trails`\n\n- Identify multi-region CloudTrail trails: `Trails with \"IsMultiRegionTrail\" set to true`\n\n- Note the value associated with \"Name\":`<trail-name>`\n\n- Note the `<trail-log-group-name>` within the value associated with \"CloudWatchLogsLogGroupArn\"\n\n - Example: `arn:aws:logs:<region>:<account-id>:log-group:<trail-log-group-name>:*`\n\n- Ensure the identified multi-region CloudTrail trail is active:\n\n - `aws cloudtrail get-trail-status --name <trail-name>`\n\n - Ensure `IsLogging` is set to `TRUE`\n\n- Ensure the identified multi-region CloudTrail trail captures all management events:\n\n - `aws cloudtrail get-event-selectors --trail-name <trail-name>`\n\n - Ensure there is at least one `event selector` for a trail with `IncludeManagementEvents` set to `true` and `ReadWriteType` set to `All`\n\n2. Get a list of all associated metric filters for the `<trail-log-group-name>` captured in step 1:\n\n ```\n aws logs describe-metric-filters --log-group-name <trail-log-group-name>\n ```\n\n3. Ensure the output from the above command contains the following:\n\n ```\n \"filterPattern\": \"{ ($.eventSource = s3.amazonaws.com) && (($.eventName = PutBucketAcl) || ($.eventName = PutBucketPolicy) || ($.eventName = PutBucketCors) || ($.eventName = PutBucketLifecycle) || ($.eventName = PutBucketReplication) || ($.eventName = DeleteBucketPolicy) || ($.eventName = DeleteBucketCors) || ($.eventName = DeleteBucketLifecycle) || ($.eventName = DeleteBucketReplication)) }\"\n ```\n\n4. Note the `<s3-bucket-policy-changes-metric>` value associated with the `filterPattern` from step 3.\n\n5. Get a list of CloudWatch alarms, and filter on the `<s3-bucket-policy-changes-metric>` captured in step 4:\n\n ```\n aws cloudwatch describe-alarms --query 'MetricAlarms[?MetricName==<s3-bucket-policy-changes-metric>]'\n ```\n\n6. Note the `AlarmActions` value; this will provide the SNS topic ARN value.\n\n7. Ensure there is at least one active subscriber to the SNS topic:\n\n ```\n aws sns list-subscriptions-by-topic --topic-arn <sns-topic-arn> \n ```\n\n- At least one subscription should have \"SubscriptionArn\" with a valid AWS ARN.\n\n - Example of valid \"SubscriptionArn\": `arn:aws:sns:<region>:<account-id>:<sns-topic-name>:<subscription-id>`",
    "remediation_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following steps to set up the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on the provided filter pattern that checks for changes to S3 bucket policies and uses the `<trail-log-group-name>` taken from audit step 1:\n\n ```\n aws logs put-metric-filter --log-group-name <trail-log-group-name> --filter-name <s3-bucket-policy-changes-metric> --metric-transformations metricName=<s3-bucket-policy-changes-metric>,metricNamespace='CISBenchmark',metricValue=1 --filter-pattern '{ ($.eventSource = s3.amazonaws.com) && (($.eventName = PutBucketAcl) || ($.eventName = PutBucketPolicy) || ($.eventName = PutBucketCors) || ($.eventName = PutBucketLifecycle) || ($.eventName = PutBucketReplication) || ($.eventName = DeleteBucketPolicy) || ($.eventName = DeleteBucketCors) || ($.eventName = DeleteBucketLifecycle) || ($.eventName = DeleteBucketReplication)) }'\n ```\n\n **Note**: You can choose your own `metricName` and `metricNamespace` strings. Using the same `metricNamespace` for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify:\n\n ```\n aws sns create-topic --name <sns-topic-name>\n ```\n\n **Note**: You can execute this command once and then reuse the same topic for all monitoring alarms.\n\n **Note**: Capture the `TopicArn` that is displayed when creating the SNS topic in step 2.\n\n3. Create an SNS subscription for the topic created in step 2:\n\n ```\n aws sns subscribe --topic-arn <sns-topic-arn> --protocol <sns-protocol> --notification-endpoint <sns-subscription-endpoints>\n ```\n\n **Note**: You can execute this command once and then reuse the same subscription for all monitoring alarms.\n\n4. Create an alarm that is associated with the CloudWatch Logs metric filter created in step 1 and the SNS topic created in step 2:\n\n ```\n aws cloudwatch put-metric-alarm --alarm-name <s3-bucket-policy-changes-alarm> --metric-name <s3-bucket-policy-changes-metric> --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace 'CISBenchmark' --alarm-actions <sns-topic-arn>\n ```"
  },
  {
    "recommendation_number": "4.9",
    "section": 4.0,
    "title": "Ensure AWS Config configuration changes are monitored",
    "profile": "Level 2",
    "assessment_status": "Manual",
    "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs or an external Security Information and Event Management (SIEM) environment, and establishing corresponding metric filters and alarms. \n\nIt is recommended that a metric filter and alarm be established for detecting changes to AWS Config's configurations.",
    "audit_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following to ensure that there is at least one active multi-region CloudTrail trail with the prescribed metric filters and alarms configured:\n\n1. Identify the log group name that is configured for use with the active multi-region CloudTrail trail:\n\n- List all CloudTrail trails: `aws cloudtrail describe-trails`\n\n- Identify multi-region CloudTrail trails: `Trails with \"IsMultiRegionTrail\" set to true`\n\n- Note the value associated with \"Name\":`<trail-name>`\n\n- Note the `<trail-log-group-name>` within the value associated with \"CloudWatchLogsLogGroupArn\"\n\n - Example: `arn:aws:logs:<region>:<account-id>:log-group:<trail-log-group-name>:*`\n\n- Ensure the identified multi-region CloudTrail trail is active:\n\n - `aws cloudtrail get-trail-status --name <trail-name>`\n\n - Ensure `IsLogging` is set to `TRUE`\n\n- Ensure the identified multi-region CloudTrail trail captures all management events:\n\n - `aws cloudtrail get-event-selectors --trail-name <trail-name>`\n\n - Ensure there is at least one `event selector` for a trail with `IncludeManagementEvents` set to `true` and `ReadWriteType` set to `All`\n\n2. Get a list of all associated metric filters for the `<trail-log-group-name>` captured in step 1:\n\n ```\n aws logs describe-metric-filters --log-group-name <trail-log-group-name>\n ```\n\n3. Ensure the output from the above command contains the following:\n\n ```\n \"filterPattern\": \"{ ($.eventSource = config.amazonaws.com) && (($.eventName=StopConfigurationRecorder)||($.eventName=DeleteDeliveryChannel)||($.eventName=PutDeliveryChannel)||($.eventName=PutConfigurationRecorder)) }\"\n ```\n\n4. Note the `<aws-config-changes-metric>` value associated with the `filterPattern` from step 3.\n\n5. Get a list of CloudWatch alarms, and filter on the `<aws-config-changes-metric>` captured in step 4:\n\n ```\n aws cloudwatch describe-alarms --query 'MetricAlarms[?MetricName==<aws-config-changes-metric>]'\n ```\n\n6. Note the `AlarmActions` value; this will provide the SNS topic ARN value.\n\n7. Ensure there is at least one active subscriber to the SNS topic:\n\n ```\n aws sns list-subscriptions-by-topic --topic-arn <sns-topic-arn> \n ```\n\n- At least one subscription should have \"SubscriptionArn\" with a valid AWS ARN.\n\n - Example of valid \"SubscriptionArn\": `arn:aws:sns:<region>:<account-id>:<sns-topic-name>:<subscription-id>`",
    "remediation_procedure": "If you are using CloudTrail trails and CloudWatch, perform the following steps to set up the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on the provided filter pattern that checks for AWS Configuration changes and uses the `<trail-log-group-name>` taken from audit step 1:\n\n ```\n aws logs put-metric-filter --log-group-name <trail-log-group-name> --filter-name <aws-config-changes-metric> --metric-transformations metricName=<aws-config-changes-metric>,metricNamespace='CISBenchmark',metricValue=1 --filter-pattern '{ ($.eventSource = config.amazonaws.com) && (($.eventName=StopConfigurationRecorder)||($.eventName=DeleteDeliveryChannel)||($.eventName=PutDeliveryChannel)||($.eventName=PutConfigurationRecorder)) }'\n ```\n\n **Note**: You can choose your own `metricName` and `metricNamespace` strings. Using the same `metricNamespace` for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify:\n\n ```\n aws sns create-topic --name <sns-topic-name>\n ```\n\n **Note**: You can execute this command once and then reuse the same topic for all monitoring alarms.\n\n **Note**: Capture the `TopicArn` that is displayed when creating the SNS topic in step 2.\n\n3. Create an SNS subscription for the topic created in step 2:\n\n ```\n aws sns subscribe --topic-arn <sns-topic-arn> --protocol <sns-protocol> --notification-endpoint <sns-subscription-endpoints>\n ```\n\n **Note**: You can execute this command once and then reuse the same subscription for all monitoring alarms.\n\n4. Create an alarm that is associated with the CloudWatch Logs metric filter created in step 1 and the SNS topic created in step 2:\n\n ```\n aws cloudwatch put-metric-alarm --alarm-name <aws-config-changes-alarm> --metric-name <aws-config-changes-metric> --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace 'CISBenchmark' --alarm-actions <sns-topic-arn>\n ```"
  },
  {
    "recommendation_number": "5.1.1",
    "section": 5.1,
    "title": "Ensure EBS volume encryption is enabled in all regions",
    "profile": "Level 1",
    "assessment_status": "Automated",
    "description": "Elastic Compute Cloud (EC2) supports encryption at rest when using the Elastic Block Store (EBS) service. While disabled by default, forcing encryption at EBS volume creation is supported.",
    "audit_procedure": "**From Console:**\n\n1. Login to the AWS Management Console and open the Amazon EC2 console using https://console.aws.amazon.com/ec2/.\n2. Under `Settings`, click `EBS encryption`.\n3. Verify `Always encrypt new EBS volumes` displays `Enabled`.\n4. Repeat for each region in use.\n\n**Note:** EBS volume encryption is configured per region.\n\n**From Command Line:**\n\n1. Run the following command:\n\n```\naws --region <region> ec2 get-ebs-encryption-by-default\n```\n\n2. Verify that `\"EbsEncryptionByDefault\": true` is displayed.\n3. Repeat for each region in use.\n\n**Note:** EBS volume encryption is configured per region.",
    "remediation_procedure": "**From Console:**\n\n1. Login to the AWS Management Console and open the Amazon EC2 console using https://console.aws.amazon.com/ec2/.\n2. Under `Account attributes`, click `EBS encryption`.\n3. Click `Manage`.\n4. Check the `Enable` box.\n5. Click `Update EBS encryption`.\n6. Repeat for each region in which EBS volume encryption is not enabled by default.\n\n**Note:** EBS volume encryption is configured per region.\n\n**From Command Line:**\n\n1. Run the following command:\n\n```\naws --region <region> ec2 enable-ebs-encryption-by-default\n```\n\n2. Verify that `\"EbsEncryptionByDefault\": true` is displayed.\n3. Repeat for each region in which EBS volume encryption is not enabled by default.\n\n**Note:** EBS volume encryption is configured per region."
  },
  {
    "recommendation_number": "5.1.2",
    "section": 5.1,
    "title": "Ensure CIFS access is restricted to trusted networks to prevent unauthorized access",
    "profile": "Level 1",
    "assessment_status": "Automated",
    "description": "Common Internet File System (CIFS) is a network file-sharing protocol that allows systems to share files over a network. However, unrestricted CIFS access can expose your data to unauthorized users, leading to potential security risks. It is important to restrict CIFS access to only trusted networks and users to prevent unauthorized access and data breaches.",
    "audit_procedure": "**From Console:**\n\n1. Login to the AWS Management Console.\n2. Navigate to the EC2 Dashboard and select the Security Groups section under `Network & Security`.\n3. Identify the security groups associated with instances or resources that may be using CIFS.\n4. Review the inbound rules of each security group to check for rules that allow unrestricted access on port 445 (the port used by CIFS).\n - Specifically, look for inbound rules that allow access from `0.0.0.0/0` or `::/0` on port 445.\n5. Document any instances where unrestricted access is allowed and verify whether it is necessary for the specific use case.\n\n**From Command Line:**\n\n1. Run the following command to list all security groups and identify those associated with CIFS:\n ```\n aws ec2 describe-security-groups --region <region-name> --query 'SecurityGroups[*].GroupId'\n ```\n2. Check for any inbound rules that allow unrestricted access on port 445 using the following command:\n ```\n aws ec2 describe-security-groups --region <region-name> --group-ids <security-group-id> --query 'SecurityGroups[*].IpPermissions[?ToPort==`445`].{CIDR:IpRanges[*].CidrIp,Port:ToPort}'\n ```\n - Look for `0.0.0.0/0` or `::/0` in the output, which indicates unrestricted access.\n\n3. Repeat the audit for other regions and security groups as necessary.",
    "remediation_procedure": "**From Console:**\n\n1. Login to the AWS Management Console.\n2. Navigate to the EC2 Dashboard and select the Security Groups section under `Network & Security`.\n3. Identify the security group that allows unrestricted ingress on port 445.\n4. Select the security group and click the `Edit Inbound Rules` button.\n5. Locate the rule allowing unrestricted access on port 445 (typically listed as `0.0.0.0/0` or `::/0`).\n6. Modify the rule to restrict access to specific IP ranges or trusted networks only.\n7. Save the changes to the security group.\n\n**From Command Line:**\n\n1. Run the following command to remove or modify the unrestricted rule for CIFS access:\n ```\n aws ec2 revoke-security-group-ingress --region <region-name> --group-id <security-group-id> --protocol tcp --port 445 --cidr 0.0.0.0/0\n ```\n - Optionally, run the `authorise-security-group-ingress` command to create a new rule, specifying a trusted CIDR range instead of `0.0.0.0/0`.\n\n2. Confirm the changes by describing the security group again and ensuring the unrestricted access rule has been removed or appropriately restricted:\n ```\n aws ec2 describe-security-groups --region <region-name> --group-ids <security-group-id> --query 'SecurityGroups[*].IpPermissions[?ToPort==`445`].{CIDR:IpRanges[*].CidrIp,Port:ToPort}'\n ```\n\n3. Repeat the remediation for other security groups and regions as necessary."
  },
  {
    "recommendation_number": "5.2",
    "section": 5.0,
    "title": "Ensure no Network ACLs allow ingress from 0.0.0.0/0 to remote server administration ports",
    "profile": "Level 1",
    "assessment_status": "Automated",
    "description": "The Network Access Control List (NACL) function provides stateless filtering of ingress and egress network traffic to AWS resources. It is recommended that no NACL allows unrestricted ingress access to remote server administration ports, such as SSH on port `22` and RDP on port `3389`, using either the TCP (6), UDP (17), or ALL (-1) protocols.",
    "audit_procedure": "**From Console:**\n\nPerform the following steps to determine if the account is configured as prescribed:\n\n1. Login to the AWS VPC Console at https://console.aws.amazon.com/vpc/home.\n2. In the left pane, click `Network ACLs`.\n3. For each network ACL, perform the following:\n - Select the network ACL.\n - Click the `Inbound Rules` tab.\n - Ensure that no rule exists which has a port range that includes port `22` or `3389`, uses the protocols TCP (6), UDP (17), or ALL (-1), or other remote server administration ports for your environment, has a `Source` of `0.0.0.0/0`, and shows `ALLOW`.\n\n**Note:** A port value of `ALL` or a port range such as `0-3389` includes port `22`, `3389`, and potentially other remote server administration ports.",
    "remediation_procedure": "**From Console:**\n\nPerform the following steps to remediate a network ACL:\n\n1. Login to the AWS VPC Console at https://console.aws.amazon.com/vpc/home.\n2. In the left pane, click `Network ACLs`.\n3. For each network ACL that needs remediation, perform the following:\n - Select the network ACL.\n - Click the `Inbound Rules` tab.\n - Click `Edit inbound rules`.\n - Either A) update the Source field to a range other than 0.0.0.0/0, or B) click `Delete` to remove the offending inbound rule.\n - Click `Save`."
  },
  {
    "recommendation_number": "5.3",
    "section": 5.0,
    "title": "Ensure no security groups allow ingress from 0.0.0.0/0 to remote server administration ports",
    "profile": "Level 1",
    "assessment_status": "Automated",
    "description": "Security groups provide stateful filtering of ingress and egress network traffic to AWS resources. It is recommended that no security group allows unrestricted ingress access to remote server administration ports, such as SSH on port `22` and RDP on port `3389`, using either the TCP (6), UDP (17), or ALL (-1) protocols.",
    "audit_procedure": "Perform the following to determine if the account is configured as prescribed:\n\n1. Login to the AWS VPC Console at [https://console.aws.amazon.com/vpc/home](https://console.aws.amazon.com/vpc/home).\n2. In the left pane, click `Security Groups`.\n3. For each security group, perform the following:\n - Select the security group.\n - Click the `Inbound Rules` tab.\n - Ensure that no rule exists which has a port range including port `22` or `3389`, uses the protocols TCP (6), UDP (17), or ALL (-1), or other remote server administration ports for your environment, and has a `Source` of `0.0.0.0/0`.\n\n**Note:** A port value of `ALL` or a port range such as `0-3389` includes port `22`, `3389`, and potentially other remote server administration ports.",
    "remediation_procedure": "Perform the following to implement the prescribed state:\n\n1. Login to the AWS VPC Console at [https://console.aws.amazon.com/vpc/home](https://console.aws.amazon.com/vpc/home).\n2. In the left pane, click `Security Groups`.\n3. For each security group, perform the following:\n - Select the security group.\n - Click the `Inbound Rules` tab.\n - Click the `Edit inbound rules` button.\n - Identify the rules to be edited or removed.\n - Either A) update the Source field to a range other than 0.0.0.0/0, or B) click `Delete` to remove the offending inbound rule.\n - Click `Save rules`."
  },
  {
    "recommendation_number": "5.4",
    "section": 5.0,
    "title": "Ensure no security groups allow ingress from ::/0 to remote server administration ports",
    "profile": "Level 1",
    "assessment_status": "Automated",
    "description": "Security groups provide stateful filtering of ingress and egress network traffic to AWS resources. It is recommended that no security group allows unrestricted ingress access to remote server administration ports, such as SSH on port `22` and RDP on port `3389`.",
    "audit_procedure": "Perform the following to determine if the account is configured as prescribed:\n\n1. Login to the AWS VPC Console at [https://console.aws.amazon.com/vpc/home](https://console.aws.amazon.com/vpc/home).\n2. In the left pane, click `Security Groups`.\n3. For each security group, perform the following:\n - Select the security group.\n - Click the `Inbound Rules` tab.\n - Ensure that no rule exists which has a port range including port `22`, `3389`, or other remote server administration ports for your environment, and has a `Source` of `::/0`.\n\n**Note:** A port value of `ALL` or a port range such as `0-3389` includes port `22`, `3389`, and potentially other remote server administration ports.",
    "remediation_procedure": "Perform the following to implement the prescribed state:\n\n1. Login to the AWS VPC Console at [https://console.aws.amazon.com/vpc/home](https://console.aws.amazon.com/vpc/home).\n2. In the left pane, click `Security Groups`.\n3. For each security group, perform the following:\n - Select the security group.\n - Click the `Inbound Rules` tab.\n - Click the `Edit inbound rules` button.\n - Identify the rules to be edited or removed.\n - Either A) update the Source field to a range other than ::/0, or B) Click `Delete` to remove the offending inbound rule.\n - Click `Save rules`."
  },
  {
    "recommendation_number": "5.5",
    "section": 5.0,
    "title": "Ensure the default security group of every VPC restricts all traffic",
    "profile": "Level 2",
    "assessment_status": "Automated",
    "description": "A VPC comes with a default security group whose initial settings deny all inbound traffic, allow all outbound traffic, and allow all traffic between instances assigned to the security group. If a security group is not specified when an instance is launched, it is automatically assigned to this default security group. Security groups provide stateful filtering of ingress/egress network traffic to AWS resources. It is recommended that the default security group restrict all traffic, both inbound and outbound.\n\nThe default VPC in every region should have its default security group updated to comply with the following:\n\n - No inbound rules.\n - No outbound rules.\n\nAny newly created VPCs will automatically contain a default security group that will need remediation to comply with this recommendation.\n\n**Note:** When implementing this recommendation, VPC flow logging is invaluable in determining the least privilege port access required by systems to work properly, as it can log all packet acceptances and rejections occurring under the current security groups. This dramatically reduces the primary barrier to least privilege engineering by discovering the minimum ports required by systems in the environment. Even if the VPC flow logging recommendation in this benchmark is not adopted as a permanent security measure, it should be used during any period of discovery and engineering for least privileged security groups.",
    "audit_procedure": "Perform the following to determine if the account is configured as prescribed:\n\n**Security Group State**\n\n1. Login to the AWS VPC Console at [https://console.aws.amazon.com/vpc/home](https://console.aws.amazon.com/vpc/home).\n2. Repeat the following steps for all VPCs, including the default VPC in each AWS region:\n3. In the left pane, click `Security Groups`.\n4. For each default security group, perform the following:\n - Select the `default` security group.\n - Click the `Inbound Rules` tab and ensure no rules exist.\n - Click the `Outbound Rules` tab and ensure no rules exist.\n\n**Security Group Members**\n\n1. Login to the AWS VPC Console at [https://console.aws.amazon.com/vpc/home](https://console.aws.amazon.com/vpc/home).\n2. Repeat the following steps for all default groups in all VPCs, including the default VPC in each AWS region:\n3. In the left pane, click `Security Groups`.\n4. Copy the ID of the default security group.\n5. Change to the EC2 Management Console at https://console.aws.amazon.com/ec2/v2/home.\n6. In the filter column type `Security Group ID : <security-group-id-from-step-4>`.",
    "remediation_procedure": "Perform the following to implement the prescribed state:\n\n**Security Group Members**\n\n1. Identify AWS resources that exist within the default security group.\n2. Create a set of least-privilege security groups for those resources.\n3. Place the resources in those security groups, removing the resources noted in step 1 from the default security group.\n\n**Security Group State**\n\n1. Login to the AWS VPC Console at [https://console.aws.amazon.com/vpc/home](https://console.aws.amazon.com/vpc/home).\n2. Repeat the following steps for all VPCs, including the default VPC in each AWS region:\n3. In the left pane, click `Security Groups`.\n4. For each default security group, perform the following:\n - Select the `default` security group.\n - Click the `Inbound Rules` tab.\n - Remove any inbound rules.\n - Click the `Outbound Rules` tab.\n - Remove any Outbound rules.\n\n**Recommended**\n\nIAM groups allow you to edit the \"name\" field. After remediating default group rules for all VPCs in all regions, edit this field to add text similar to \"DO NOT USE. DO NOT ADD RULES.\""
  },
  {
    "recommendation_number": "5.6",
    "section": 5.0,
    "title": "Ensure routing tables for VPC peering are \"least access\"",
    "profile": "Level 2",
    "assessment_status": "Manual",
    "description": "Once a VPC peering connection is established, routing tables must be updated to enable any connections between the peered VPCs. These routes can be as specific as desired, even allowing for the peering of a VPC to only a single host on the other side of the connection.",
    "audit_procedure": "Review the routing tables of peered VPCs to determine whether they route all subnets of each VPC and whether this is necessary to accomplish the intended purposes of peering the VPCs.\n\n**From Command Line:**\n\n1. List all the route tables from a VPC and check if the \"GatewayId\" is pointing to a `<peering-connection-id>` (e.g., pcx-1a2b3c4d) and if the \"DestinationCidrBlock\" is as specific as desired:\n\n```\naws ec2 describe-route-tables --filter \"Name=vpc-id,Values=<vpc-id>\" --query \"RouteTables[*].{RouteTableId:RouteTableId, VpcId:VpcId, Routes:Routes, AssociatedSubnets:Associations[*].SubnetId}\"\n```",
    "remediation_procedure": "Remove and add route table entries to ensure that the least number of subnets or hosts required to accomplish the purpose of peering are routable.\n\n**From Command Line:**\n\n1. For each `<route-table-id>` that contains routes that are non-compliant with your routing policy (granting more access than desired), delete the non-compliant route:\n\n```\naws ec2 delete-route --route-table-id <route-table-id> --destination-cidr-block <non-compliant-destination-cidr>\n```\n\n2. Create a new compliant route:\n\n```\naws ec2 create-route --route-table-id <route-table-id> --destination-cidr-block <compliant-destination-cidr> --vpc-peering-connection-id <peering-connection-id>\n```"
  },
  {
    "recommendation_number": "5.7",
    "section": 5.0,
    "title": "Ensure that the EC2 Metadata Service only allows IMDSv2",
    "profile": "Level 1",
    "assessment_status": "Automated",
    "description": "When enabling the Metadata Service on AWS EC2 instances, users have the option of using either Instance Metadata Service Version 1 (IMDSv1; a request/response method) or Instance Metadata Service Version 2 (IMDSv2; a session-oriented method).",
    "audit_procedure": "From Console:\n\n1. Sign in to the AWS Management Console and navigate to the EC2 dashboard at https://console.aws.amazon.com/ec2/.\n2. In the left navigation panel, under the `INSTANCES` section, choose `Instances`.\n3. Select the EC2 instance that you want to examine.\n4. Check the `IMDSv2` status, and ensure that it is set to `Required`.\n\nFrom Command Line:\n\n1. Run the `describe-instances` command using appropriate filters to list the IDs of all existing EC2 instances currently available in the selected region:\n\n ```\n aws ec2 describe-instances --region <region-name> --output table --query \"Reservations[*].Instances[*].InstanceId\"\n ```\n\n2. The command output should return a table with the requested instance IDs.\n3. Run the `describe-instances` command using the instance ID returned in the previous step and apply custom filtering to determine whether the selected instance is using IMDSv2:\n\n ```\n aws ec2 describe-instances --region <region-name> --instance-ids <instance-id> --query \"Reservations[*].Instances[*].MetadataOptions\" --output table\n ```\n\n4. Ensure that for all EC2 instances, `HttpTokens` is set to `required` and `State` is set to `applied`.\n5. Repeat steps 3 and 4 to verify the other EC2 instances provisioned within the current region.\n6. Repeat steps 1â€“5 to perform the audit process for other AWS regions.",
    "remediation_procedure": "From Console:\n\n1. Sign in to the AWS Management Console and navigate to the EC2 dashboard at [https://console.aws.amazon.com/ec2/](https://console.aws.amazon.com/ec2/).\n2. In the left navigation panel, under the `INSTANCES` section, choose `Instances`.\n3. Select the EC2 instance that you want to examine.\n4. Choose `Actions > Instance Settings > Modify instance metadata options`.\n5. Set `Instance metadata service` to `Enable`.\n6. Set `IMDSv2` to `Required`.\n7. Repeat steps 1-6 to perform the remediation process for other EC2 instances in all applicable AWS region(s).\n\nFrom Command Line:\n\n1. Run the `describe-instances` command, applying the appropriate filters to list the IDs of all existing EC2 instances currently available in the selected region:\n\n ``` \n aws ec2 describe-instances --region <region-name> --output table --query \"Reservations[*].Instances[*].InstanceId\"\n ```\n\n2. The command output should return a table with the requested instance IDs.\n3. Run the `modify-instance-metadata-options` command with an instance ID obtained from the previous step to update the Instance Metadata Version:\n\n ```\n aws ec2 modify-instance-metadata-options --instance-id <instance-id> --http-tokens required --region <region-name>\n ```\n\n4. Repeat steps 1-3 to perform the remediation process for other EC2 instances in the same AWS region.\n5. Change the region by updating `--region` and repeat the process for other regions."
  }
]